Summary: Spark images are based of Python 3.8 which is soon EOL
Issue key: SPARK-48092
Issue id: 13577964
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Blocker
Resolution: 
Assignee: 
Reporter: mayurmadnani
Creator: mayurmadnani
Created: 5/2/24 15:29
Updated: 5/10/24 14:11
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.0, 3.4.1, 3.4.2, 3.5.0, 3.5.1
Fix Version/s: 
Component/s: Spark Docker
Due Date: 
Votes: 0
Labels: 
Description: Python 3.8 will be EOL in Oct 2024 and all the Spark docker images are based on Python 3.8 as of now.

I am proposing to use Python 3.10 as default. Let me know if I can pick this up to make the changes in [spark-docker|[https://github.com/apache/spark-docker]]

Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 02/May/24 15:31;mayurmadnani;Screenshot 2024-05-02 at 21.00.18.png;https://issues.apache.org/jira/secure/attachment/13068601/Screenshot+2024-05-02+at+21.00.18.png, 02/May/24 15:31;mayurmadnani;Screenshot 2024-05-02 at 21.00.48.png;https://issues.apache.org/jira/secure/attachment/13068602/Screenshot+2024-05-02+at+21.00.48.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 2
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri May 10 14:11:12 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ozyg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 10/May/24 14:11;schilukoori;[~mayurmadnani] I'm looking for opportunities to start contributing to Spark, could I assist you in updating the images?

Thank you.;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.4.2
Affects Version/s.3: 3.5.0
Affects Version/s.4: 3.5.1
Comment.1:

Summary: Inaccurate Decimal multiplication and division results
Issue key: SPARK-45786
Issue id: 13556766
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Blocker
Resolution: Fixed
Assignee: kazuyukitanimura
Reporter: kazuyukitanimura
Creator: kazuyukitanimura
Created: 11/4/23 0:35
Updated: 2/2/24 17:07
Last Viewed: 7/17/24 20:45
Resolved: 11/7/23 17:07
Affects Version/s: 3.2.4, 3.3.3, 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.4.2, 3.5.1, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: correctness, pull-request-available
Description: Decimal multiplication and division results may be inaccurate due to rounding issues.
h2. Multiplication:
{code:scala}
scala> sql("select  -14120025096157587712113961295153.858047 * -0.4652").show(truncate=false)
+----------------------------------------------------+                          
|(-14120025096157587712113961295153.858047 * -0.4652)|
+----------------------------------------------------+
|6568635674732509803675414794505.574764              |
+----------------------------------------------------+
{code}
The correct answer is
{quote}6568635674732509803675414794505.574763
{quote}

Please note that the last digit is 3 instead of 4 as

 
{code:scala}
scala> java.math.BigDecimal("-14120025096157587712113961295153.858047").multiply(java.math.BigDecimal("-0.4652"))
val res21: java.math.BigDecimal = 6568635674732509803675414794505.5747634644
{code}
Since the factional part .574763 is followed by 4644, it should not be rounded up.
h2. Division:
{code:scala}
scala> sql("select -0.172787979 / 533704665545018957788294905796.5").show(truncate=false)
+-------------------------------------------------+
|(-0.172787979 / 533704665545018957788294905796.5)|
+-------------------------------------------------+
|-3.237521E-31                                    |
+-------------------------------------------------+
{code}
The correct answer is
{quote}-3.237520E-31
{quote}

Please note that the last digit is 0 instead of 1 as

 
{code:scala}
scala> java.math.BigDecimal("-0.172787979").divide(java.math.BigDecimal("533704665545018957788294905796.5"), 100, java.math.RoundingMode.DOWN)
val res22: java.math.BigDecimal = -3.237520489418037889998826491401059986665344697406144511563561222578738E-31
{code}
Since the factional part .237520 is followed by 4894..., it should not be rounded up.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Feb 02 17:07:58 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1legw:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 3.4.2
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 07/Nov/23 17:05;dongjoon;Thank you, [~kazuyukitanimura] .

As a release manager of Apache Spark 3.4.2, I added a `correctness` label and raises the priority to `Blocker` for Apache Spark 3.4.2.;;;, 07/Nov/23 17:07;dongjoon;This is resolved via [https://github.com/apache/spark/pull/43678];;;, 02/Feb/24 17:07;nchammas;[~kazuyukitanimura] - I'm just curious: How did you find this bug? Was it something you stumbled on by accident or did you search for it using something like a fuzzer?;;;
Affects Version/s.1: 3.3.3
Affects Version/s.2: 3.4.1
Affects Version/s.3: 3.5.0
Affects Version/s.4: 4.0.0
Comment.1: 07/Nov/23 17:07;dongjoon;This is resolved via [https://github.com/apache/spark/pull/43678];;;

Summary: Join loses records for cached datasets
Issue key: SPARK-45282
Issue id: 13551692
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Blocker
Resolution: Fixed
Assignee: eejbyfeldt
Reporter: koert
Creator: koert
Created: 9/22/23 17:13
Updated: 1/18/24 23:04
Last Viewed: 7/17/24 20:45
Resolved: 11/12/23 21:54
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 3.4.2
Component/s: SQL
Due Date: 
Votes: 0
Labels: correctness, CorrectnessBug, pull-request-available
Description: we observed this issue on spark 3.4.1 but it is also present on 3.5.0. it is not present on spark 3.3.1.

it only shows up in distributed environment. i cannot replicate in unit test. however i did get it to show up on hadoop cluster, kubernetes, and on databricks 13.3

the issue is that records are dropped when two cached dataframes are joined. it seems in spark 3.4.1 in queryplan some Exchanges are dropped as an optimization while in spark 3.3.1 these Exhanges are still present. it seems to be an issue with AQE with canChangeCachedPlanOutputPartitioning=true.

to reproduce on distributed cluster these settings needed are:
{code:java}
spark.sql.adaptive.advisoryPartitionSizeInBytes 33554432
spark.sql.adaptive.coalescePartitions.parallelismFirst false
spark.sql.adaptive.enabled true
spark.sql.optimizer.canChangeCachedPlanOutputPartitioning true {code}
code using scala to reproduce is:
{code:java}
import java.util.UUID
import org.apache.spark.sql.functions.col

import spark.implicits._

val data = (1 to 1000000).toDS().map(i => UUID.randomUUID().toString).persist()

val left = data.map(k => (k, 1))
val right = data.map(k => (k, k)) // if i change this to k => (k, 1) it works!
println("number of left " + left.count())
println("number of right " + right.count())
println("number of (left join right) " +
  left.toDF("key", "value1").join(right.toDF("key", "value2"), "key").count()
)

val left1 = left
  .toDF("key", "value1")
  .repartition(col("key")) // comment out this line to make it work
  .persist()
println("number of left1 " + left1.count())

val right1 = right
  .toDF("key", "value2")
  .repartition(col("key")) // comment out this line to make it work
  .persist()
println("number of right1 " + right1.count())

println("number of (left1 join right1) " +  left1.join(right1, "key").count()) // this gives incorrect result{code}
this produces the following output:
{code:java}
number of left 1000000
number of right 1000000
number of (left join right) 1000000
number of left1 1000000
number of right1 1000000
number of (left1 join right1) 859531 {code}
note that the last number (the incorrect one) actually varies depending on settings and cluster size etc.

 
Environment: spark 3.4.1 on apache hadoop 3.3.6 or kubernetes 1.26 or databricks 13.3
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): SPARK-41048
Outward issue link (Problem/Incident): 
Inward issue link (Reference): SPARK-45592
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Jan 18 23:04:12 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kj74:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 3.4.2, 3.5.1
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 22/Sep/23 18:40;koert;after reverting SPARK-41048 the issue went away.;;;, 24/Sep/23 14:46;yumwang;cc [~ulysses] [~cloud_fan];;;, 27/Sep/23 01:36;ulysses;I can not re-produce this issue in master branch (4.0.0), [~koert] have you tried master branch ?;;;, 28/Sep/23 04:05;koert;yes i can reproduce it.

master branch on commit:
{code:java}
commit 7e8aafd2c0f1f6fcd03a69afe2b85fd3fda95d20 (HEAD -> master, upstream/master)
Author: lanmengran1 <lanmengran1@jd.com>
Date:   Tue Sep 26 21:01:02 2023 -0500    [SPARK-45334][SQL] Remove misleading comment in parquetSchemaConverter {code}
i build spark for k8s using:
{code:java}
$ dev/make-distribution.sh --name kubernetes --tgz -Pkubernetes -Phadoop-cloud {code}
created docker container using Dockerfile provided in resource-managers/kubernetes/docker/src/main/dockerfiles/spark/Dockerfile

launch pod and shell inside:
{code:java}
185@proxy:~/work-dir$ export SPARK_LOCAL_HOSTNAME=$(hostname -i
185@proxy:~/work-dir$ export SPARK_PUBLIC_DNS=$(hostname -i)                                                                                              185@proxy:~/work-dir$ /opt/spark/bin/spark-shell --master k8s://https://kubernetes.default:443 --deploy-mode client --num-executors 4 --executor-memory 2G --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.kubernetes.namespace=default --conf spark.sql.adaptive.coalescePartitions.parallelismFirst=false --conf spark.sql.adaptive.enabled=true --conf spark.sql.adaptive.advisoryPartitionSizeInBytes=33554432 --conf spark.sql.optimizer.canChangeCachedPlanOutputPartitioning=true --conf spark.kubernetes.container.image=111111111111.dkr.ecr.us-east-1.amazonaws.com/spark:4.0.0-SNAPSHOT
23/09/28 03:44:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 4.0.0-SNAPSHOT
      /_/
         
Using Scala version 2.13.11 (OpenJDK 64-Bit Server VM, Java 21)
Type in expressions to have them evaluated.
Type :help for more information.
Spark context Web UI available at http://10.177.71.94:4040
Spark context available as 'sc' (master = k8s://https://kubernetes.default:443, app id = spark-5ab0957571944828866a2f23068ff180).
Spark session available as 'spark'.scala> :paste
// Entering paste mode (ctrl-D to finish)import java.util.UUID
import org.apache.spark.sql.functions.col
import spark.implicits._

val data = (1 to 1000000).toDS().map(i => UUID.randomUUID().toString).persist()
val left = data.map(k => (k, 1))
val right = data.map(k => (k, k)) // if i change this to k => (k, 1) it works!
println("number of left " + left.count())
println("number of right " + right.count())
println("number of (left join right) " +
  left.toDF("key", "vertex").join(right.toDF("key", "state"), "key").count()
)

val left1 = left
  .toDF("key", "vertex")
  .repartition(col("key")) // comment out this line to make it work
  .persist()
println("number of left1 " + left1.count())
val right1 = right
  .toDF("key", "state")
  .repartition(col("key")) // comment out this line to make it work
  .persist()
println("number of right1 " + right1.count())
println("number of (left1 join right1) " +  left1.join(right1, "key").count()) // this gives incorrect result
// Exiting paste mode, now interpreting.
23/09/28 03:45:30 WARN TaskSetManager: Stage 0 contains a task of very large size (6631 KiB). The maximum recommended task size is 1000 KiB.
23/09/28 03:45:34 WARN TaskSetManager: Stage 1 contains a task of very large size (6631 KiB). The maximum recommended task size is 1000 KiB.
number of left 1000000                                                          
23/09/28 03:45:36 WARN TaskSetManager: Stage 4 contains a task of very large size (6631 KiB). The maximum recommended task size is 1000 KiB.
number of right 1000000
23/09/28 03:45:39 WARN TaskSetManager: Stage 7 contains a task of very large size (6631 KiB). The maximum recommended task size is 1000 KiB.
23/09/28 03:45:40 WARN TaskSetManager: Stage 8 contains a task of very large size (6631 KiB). The maximum recommended task size is 1000 KiB.
number of (left join right) 1000000                                             
23/09/28 03:45:45 WARN TaskSetManager: Stage 16 contains a task of very large size (6631 KiB). The maximum recommended task size is 1000 KiB.
number of left1 1000000                                                         
23/09/28 03:45:48 WARN TaskSetManager: Stage 24 contains a task of very large size (6631 KiB). The maximum recommended task size is 1000 KiB.
number of right1 1000000                                                        
number of (left1 join right1) 850735                                            
import java.util.UUID
import org.apache.spark.sql.functions.col
import spark.implicits._
val data: org.apache.spark.sql.Dataset[String] = [value: string]
val left: org.apache.spark.sql.Dataset[(String, Int)] = [_1: string, _2: int]
val right: org.apache.spark.sql.Dataset[(String, String)] = [_1: string, _2: string]
val left1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [key: string, vertex: int]
val right1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [key: string, state: string]

scala>   {code}
 ;;;, 31/Oct/23 00:00;dongjoon;Hi, All
Is this correctness issue still valid in branch-3.4/3.5/master? Or, I'm wondering if this exists in the reported platform, Databricks 13.3?;;;, 31/Oct/23 00:01;dongjoon;Let me increase the priority to `Blocker` for now.;;;, 31/Oct/23 00:26;koert;last time i checked this issue was still present in 3.4/3.5/master


;;;, 31/Oct/23 16:47;dongjoon;Thank you for sharing, [~koert].;;;, 08/Nov/23 16:09;eejbyfeldt;The code reproducing the bug looks quite similar to https://issues.apache.org/jira/browse/SPARK-45592 I wonder if the fix for that might also have solved this bug as I could not reproduce this issue on a build from the master branch.;;;, 08/Nov/23 16:20;koert;it does look like same issue

and partitioning being the cause makes sense too


;;;, 09/Nov/23 08:40;eejbyfeldt;Created this [https://github.com/apache/spark/pull/43729] to backport the fix to 3.4 from my manual test it solved the reproduction in this ticket.;;;, 12/Nov/23 21:54;dongjoon;Issue resolved by pull request 43729
[https://github.com/apache/spark/pull/43729];;;, 18/Jan/24 23:04;rrusso2007;Is it possible that this also affects spark 3.3.2? I have an application that has been running on spark 3.3.2 and with AQE enabled. When I upgraded to 3.5.0 I immediately ran into the issue in this ticket. However when I started looking more closely I found that for 1 particular type of report the issue was still present even after rolling back to 3.3.2 with AQE enabled.

Either way on 3.3.2 or 3.5.0, disabling AQE fixed the problem.;;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 24/Sep/23 14:46;yumwang;cc [~ulysses] [~cloud_fan];;;, 09/Nov/23 08:40;eejbyfeldt;Created this [https://github.com/apache/spark/pull/43729] to backport the fix to 3.4 from my manual test it solved the reproduction in this ticket.;;;, 12/Nov/23 21:54;dongjoon;Issue resolved by pull request 43729
[https://github.com/apache/spark/pull/43729];;;, 18/Jan/24 23:04;rrusso2007;Is it possible that this also affects spark 3.3.2? I have an application that has been running on spark 3.3.2 and with AQE enabled. When I upgraded to 3.5.0 I immediately ran into the issue in this ticket. However when I started looking more closely I found that for 1 particular type of report the issue was still present even after rolling back to 3.3.2 with AQE enabled.

Either way on 3.3.2 or 3.5.0, disabling AQE fixed the problem.;;;

Summary: AQE and InMemoryTableScanExec correctness bug
Issue key: SPARK-45592
Issue id: 13554580
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Blocker
Resolution: Fixed
Assignee: eejbyfeldt
Reporter: eejbyfeldt
Creator: eejbyfeldt
Created: 10/18/23 13:34
Updated: 1/12/24 5:39
Last Viewed: 7/17/24 20:45
Resolved: 10/31/23 3:23
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 3.4.2, 3.5.1, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: correctness, pull-request-available
Description: The following query should return 1000000
{code:java}
import org.apache.spark.storage.StorageLevel

val df = spark.range(0, 1000000, 1, 5).map(l => (l, l))
val ee = df.select($"_1".as("src"), $"_2".as("dst"))
  .persist(StorageLevel.MEMORY_AND_DISK)

ee.count()
val minNbrs1 = ee
  .groupBy("src").agg(min(col("dst")).as("min_number"))
  .persist(StorageLevel.MEMORY_AND_DISK)
val join = ee.join(minNbrs1, "src")
join.count(){code}
but on spark 3.5.0 there is a correctness bug causing it to return `104800` or some other smaller value.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): SPARK-45282
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Oct 31 03:23:45 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1l0zk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 3.4.2
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 30/Oct/23 05:48;dongjoon;Thank you, [~eejbyfeldt]. I added a label, `correctness`, and raised the priority to `Blocker`.;;;, 31/Oct/23 03:23;cloud_fan;Issue resolved by pull request 43435
[https://github.com/apache/spark/pull/43435];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 31/Oct/23 03:23;cloud_fan;Issue resolved by pull request 43435
[https://github.com/apache/spark/pull/43435];;;

Summary: Subquery changes the output schema of the outer query
Issue key: SPARK-45580
Issue id: 13554466
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Blocker
Resolution: Fixed
Assignee: bersprockets
Reporter: bersprockets
Creator: bersprockets
Created: 10/17/23 21:13
Updated: 12/7/23 3:24
Last Viewed: 7/17/24 20:45
Resolved: 12/6/23 19:02
Affects Version/s: 3.3.3, 3.4.1, 3.5.0
Fix Version/s: 3.3.4, 3.4.3, 3.5.1, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: correctness, pull-request-available
Description: A query can have an incorrect output schema because of a subquery.

Assume this data:
{noformat}
create or replace temp view t1(a) as values (1), (2), (3), (7);
create or replace temp view t2(c1) as values (1), (2), (3);
create or replace temp view t3(col1) as values (3), (9);
cache table t1;
cache table t2;
cache table t3;
{noformat}
When run in {{spark-sql}}, the following query has a superfluous boolean column:
{noformat}
select *
from t1
where exists (
  select c1
  from t2
  where a = c1
  or a in (select col1 from t3)
);

1	false
2	false
3	true
{noformat}
The result should be:
{noformat}
1
2
3
{noformat}
When executed via the {{Dataset}} API, you don't see the incorrect result, because the Dataset API truncates the right-side of the rows based on the analyzed plan's schema (it's the optimized plan's schema that goes wrong).

However, even with the {{Dataset}} API, this query goes wrong:
{noformat}
select (
  select *
  from t1
  where exists (
    select c1
    from t2
    where a = c1
    or a in (select col1 from t3)
  )
  limit 1
)
from range(1);

java.lang.AssertionError: assertion failed: Expects 1 field, but got 2; something went wrong in analysis
	at scala.Predef$.assert(Predef.scala:279)
	at org.apache.spark.sql.execution.ScalarSubquery.updateResult(subquery.scala:88)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$waitForSubqueries$1(SparkPlan.scala:276)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$waitForSubqueries$1$adapted(SparkPlan.scala:275)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:576)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:574)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:933)
        ...
{noformat}
Other queries that have the wrong schema:
{noformat}
select *
from t1
where a in (
  select c1
  from t2
  where a in (select col1 from t3)
);
{noformat}
and
{noformat}
select *
from t1
where not exists (
  select c1
  from t2
  where a = c1
  or a in (select col1 from t3)
);
{noformat}

Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Dec 06 18:53:53 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1l0a8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 3.3.4
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 17/Oct/23 21:38;bersprockets;I'll make a PR in the coming days.;;;, 06/Dec/23 18:53;dongjoon;Thank you, [~bersprockets].;;;, 06/Dec/23 18:53;dongjoon;I raised this issue to the blocker for Apache Spark 3.3.4.;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 06/Dec/23 18:53;dongjoon;Thank you, [~bersprockets].;;;

Summary: SPJ: Results duplicated when SPJ partial-cluster and pushdown enabled but conditions unmet
Issue key: SPARK-44641
Issue id: 13545904
Parent id: 13412655
Issue Type: Sub-task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Blocker
Resolution: Fixed
Assignee: csun
Reporter: szehon
Creator: szehon
Created: 8/2/23 18:53
Updated: 11/24/23 23:05
Last Viewed: 7/17/24 20:45
Resolved: 8/8/23 2:21
Affects Version/s: 3.4.0, 3.4.1
Fix Version/s: 3.4.2, 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: correctness
Description: Adding the following test case in KeyGroupedPartitionSuite demonstrates the problem.

 
{code:java}
test("test join key is the second partition key and a transform") {
  val items_partitions = Array(bucket(8, "id"), days("arrive_time"))
  createTable(items, items_schema, items_partitions)
  sql(s"INSERT INTO testcat.ns.$items VALUES " +
    s"(1, 'aa', 40.0, cast('2020-01-01' as timestamp)), " +
    s"(1, 'aa', 41.0, cast('2020-01-15' as timestamp)), " +
    s"(2, 'bb', 10.0, cast('2020-01-01' as timestamp)), " +
    s"(2, 'bb', 10.5, cast('2020-01-01' as timestamp)), " +
    s"(3, 'cc', 15.5, cast('2020-02-01' as timestamp))")

  val purchases_partitions = Array(bucket(8, "item_id"), days("time"))
  createTable(purchases, purchases_schema, purchases_partitions)
  sql(s"INSERT INTO testcat.ns.$purchases VALUES " +
    s"(1, 42.0, cast('2020-01-01' as timestamp)), " +
    s"(1, 44.0, cast('2020-01-15' as timestamp)), " +
    s"(1, 45.0, cast('2020-01-15' as timestamp)), " +
    s"(2, 11.0, cast('2020-01-01' as timestamp)), " +
    s"(3, 19.5, cast('2020-02-01' as timestamp))")

  withSQLConf(
    SQLConf.REQUIRE_ALL_CLUSTER_KEYS_FOR_CO_PARTITION.key -> "false",
    SQLConf.V2_BUCKETING_PUSH_PART_VALUES_ENABLED.key -> "true",
    SQLConf.V2_BUCKETING_PARTIALLY_CLUSTERED_DISTRIBUTION_ENABLED.key ->
      "true") {
    val df = sql("SELECT id, name, i.price as purchase_price, " +
      "p.item_id, p.price as sale_price " +
      s"FROM testcat.ns.$items i JOIN testcat.ns.$purchases p " +
      "ON i.arrive_time = p.time " +
      "ORDER BY id, purchase_price, p.item_id, sale_price")

    val shuffles = collectShuffles(df.queryExecution.executedPlan)
    assert(!shuffles.isEmpty, "should not perform SPJ as not all join keys are partition keys")
    checkAnswer(df,
      Seq(
        Row(1, "aa", 40.0, 1, 42.0),
        Row(1, "aa", 40.0, 2, 11.0),
        Row(1, "aa", 41.0, 1, 44.0),
        Row(1, "aa", 41.0, 1, 45.0),
        Row(2, "bb", 10.0, 1, 42.0),
        Row(2, "bb", 10.0, 2, 11.0),
        Row(2, "bb", 10.5, 1, 42.0),
        Row(2, "bb", 10.5, 2, 11.0),
        Row(3, "cc", 15.5, 3, 19.5)
      )
    )
  }
}{code}
 

Note: this tests has setup the datasourceV2 to return multiple splits for same partition.

In this case, SPJ is not triggered (because join key does not match partition key), but the following code in DSV2Scan:

[https://github.com/apache/spark/blob/v3.4.1/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/v2/BatchScanExec.scala#L194]

intended to fill the empty partition for 'pushdown-vallue' will still iterate through non-grouped partition and lookup from grouped partition to fill the map, resulting in some duplicate input data fed into the join.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 53:49.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jjug:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Numerical output of MulticlassClassificationEvaluator does not coincide with expected output
Issue key: SPARK-45910
Issue id: 13557796
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Critical
Resolution: 
Assignee: 
Reporter: airwoz
Creator: airwoz
Created: 11/13/23 22:02
Updated: 7/6/24 20:16
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 
Component/s: ML
Due Date: 
Votes: 0
Labels: 
Description: To show an example of MulticlassClassificationEvaluator generating a numerical output, which does not coincide with the expected output consider the following code:
{code:java}
from pyspark.ml.classification import LinearSVC
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

train_data = [(0, 1.0, 2.0, 3.0), (1, 4.0, 5.0, 6.0), (0, 7.0, 8.0, 9.0)]
valid_data = [(1, 2.0, 3.0, 4.0), (0, 5.0, 6.0, 7.0), (1, 8.0, 9.0, 10.0)]

schema = ["label", "feature1", "feature2", "feature3"]

train = spark.createDataFrame(train_data, schema=schema)
valid = spark.createDataFrame(valid_data, schema=schema)

feature_columns = ["feature1", "feature2", "feature3"]
assembler = VectorAssembler(inputCols=feature_columns, outputCol="features")
train = assembler.transform(train)
valid = assembler.transform(valid)

svm = LinearSVC(maxIter=10, regParam=0.1)
model = svm.fit(train)
predictions = model.transform(valid)

recallByLabel = MulticlassClassificationEvaluator(metricName="recallByLabel")
weightedRecall = MulticlassClassificationEvaluator(metricName="weightedRecall")

print(f"Recall by label: {recallByLabel.evaluate(predictions)}")
print(f"Weighted recall: {weightedRecall.evaluate(predictions)}") {code}
It produces:
{code:java}
Recall by label: 1.0
Weighted recall: 0.3333333333333333{code}
but predictions.show() implies the following hand calculated confusion matrix:
{code:java}
 -----------
|  0  |  0  |
|  2  |  1  |
 -----------{code}
where the recall is 0, i.e., 0 / (0 + 2).

What is the nature of this discrepancy? Also, note that it is not restricted to recall; and other classifiers, which include a probability column in predictions, behave similarly.

 

Furthermore, the translation of the example to Scala, namely:
{code:java}
import org.apache.spark.ml.classification.LinearSVC
import org.apache.spark.ml.feature.VectorAssembler
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator
import org.apache.spark.sql.DataFrame

val trainData = Seq((0, 1.0, 2.0, 3.0), (1, 4.0, 5.0, 6.0), (0, 7.0, 8.0, 9.0))
val validData = Seq((1, 2.0, 3.0, 4.0), (0, 5.0, 6.0, 7.0), (1, 8.0, 9.0, 10.0))

val schema = Seq("label", "feature1", "feature2", "feature3")

val train: DataFrame = spark.createDataFrame(trainData).toDF(schema: _*)
val valid: DataFrame = spark.createDataFrame(validData).toDF(schema: _*)

val featureColumns = Array("feature1", "feature2", "feature3")
val assembler = new VectorAssembler()
  .setInputCols(featureColumns)
  .setOutputCol("features")

val trainAssembled = assembler.transform(train)
val validAssembled = assembler.transform(valid)

val svm = new LinearSVC()
  .setMaxIter(10)
  .setRegParam(0.1)

val model = svm.fit(trainAssembled)
val predictions = model.transform(validAssembled)

val recallByLabel = new MulticlassClassificationEvaluator()
  .setMetricName("recallByLabel")
val weightedRecall = new MulticlassClassificationEvaluator()
  .setMetricName("weightedRecall")

println(s"Recall by label: ${recallByLabel.evaluate(predictions)}")
println(s"Weighted recall: ${weightedRecall.evaluate(predictions)}"){code}
produces the same recall by label and weighted recall, as described above.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 13/Nov/23 22:03;airwoz;predictions_dot_show.png;https://issues.apache.org/jira/secure/attachment/13064376/predictions_dot_show.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 1
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): pyspark, Python3, Scala
Custom field (Last public comment date): Sat Jul 06 20:16:16 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lktk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 06/Jul/24 20:16;psyren99;Would like to take on this issue if there is no one else working on it.;;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Spark UI: A stage is still active even when all of it's tasks are succeeded
Issue key: SPARK-45101
Issue id: 13549936
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Critical
Resolution: 
Assignee: 
Reporter: rickyma
Creator: rickyma
Created: 9/7/23 14:00
Updated: 6/4/24 11:57
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: In the stage UI, we can see all the tasks' statuses are SUCCESS.

But the stage is still marked as active.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 07/Sep/23 14:03;rickyma;1.png;https://issues.apache.org/jira/secure/attachment/13062748/1.png, 07/Sep/23 14:03;rickyma;2.png;https://issues.apache.org/jira/secure/attachment/13062747/2.png, 07/Sep/23 14:03;rickyma;3.png;https://issues.apache.org/jira/secure/attachment/13062749/3.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 3
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Jun 04 11:57:07 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k8d4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 23/Feb/24 19:22;bjornjorgensen;did you use spark.stop()  ;;;, 04/Jun/24 11:57;rickyma;No. It's just a Spark SQL.;;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 4.0.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 04/Jun/24 11:57;rickyma;No. It's just a Spark SQL.;;;

Summary: Data is silently lost in Tab separated CSV with empty (whitespace) rows
Issue key: SPARK-46876
Issue id: 13566285
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Critical
Resolution: 
Assignee: 
Reporter: martinitus
Creator: martinitus
Created: 1/26/24 10:31
Updated: 6/2/24 0:22
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Input/Output
Due Date: 
Votes: 0
Labels: pull-request-available
Description: When reading a tab separated file that contains lines that only contain tabs (i.e. empty strings as values of the columns for that row), then these rows will silently be skipped (as empty lines) and the resulting dataframe will have less rows than expected.

This behavior is inconsistent with the behavior for e.g. semicolon separated files, where the resulting dataframe will have a row with only empty string values.

A minimal reproducible example would look like:

A minimal reproducible example: A file containing this
{code:java}
a\tb\tc\r\n
\t\t\r\n
1\t2\t3{code}
will create a dataframe with one row (a=1,b=2,c=3)
whereas this
{code:java}
a;b;c\r\n
;;\r\n
1;2;3{code}
will read as two rows (first row contains empty strings)

I used the following pyspark command to read the dataframes
{code:java}
 spark.read.option("header","true").option("sep","\t").csv("<tabseparated file>").collect()
spark.read.option("header","true").option("sep",";").csv("<semicolon file>").collect()
{code}
I ran into this particularly on databricks (I assume they use the same reader), but [this stack overflow post|https://stackoverflow.com/questions/47823858/replacing-empty-lines-with-characters-when-reading-csv-using-spark#comment137288546_47823858] indicates, that this is an old issue that may have been taken over from databricks when their csv reader was adopted in SPARK-12420

I recommend to at least add a respective test case to the CSV reader.

 

Why is this behaviour a problem:
 * It violates some of the core assumptions
 ** a properly configured roundtrip via csv write/read should result in the same set of rows
 ** changing the csv separator (when everything is properly esacped) should have no effect

Potential resolutions:
 * When the configured delimiter consists of only whitespace
 ** deactivate the "skip empty line feature"
 ** or skip only lines that are completely empty (only a (carriage return) newline)
 * Change the skip empty line feature to only skip if the line is completely empty (only contains a newlin)
 ** this may break some user code that relies on the current behaviour
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Mar 14 15:16:22 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1n0uw:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 26/Jan/24 10:43;martinitus;Any resolution of this should probaly consider the mode. I.e. when using FAILFAST, i would assume, that a line that is only a newline could be ignored, but a line with only three tabs where the header indicates 5 columns should cause an error.;;;, 30/Jan/24 01:24;doki;{{The reason is that before parsing the csv lines spark calls `CSVExprUtils.filterCommentAndEmpty` to filter `empty` lines which only contains characters those <= ' '. I doubt that if it's neccessary to do this, because they may be exactly data itself. I've learnt that apache/commons-csv does trim for every column instead of whole line before parsing and trim is an option.}};;;, 15/Feb/24 11:35;martinitus;ping.

Can someone review the PR? I had a quick look and it looks ok, but I don't really understand scala....;;;, 12/Mar/24 13:53;martinitus;ping. The PR is open, the issue could be closed since 2 weeks already. Can someone with commit rights please have a look at the PR and either provide feedback or merge it?;;;, 14/Mar/24 15:16;martinitus;[~doki] any chance to make progress on this?;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 30/Jan/24 01:24;doki;{{The reason is that before parsing the csv lines spark calls `CSVExprUtils.filterCommentAndEmpty` to filter `empty` lines which only contains characters those <= ' '. I doubt that if it's neccessary to do this, because they may be exactly data itself. I've learnt that apache/commons-csv does trim for every column instead of whole line before parsing and trim is an option.}};;;

Summary: DeepSpeed Distributor
Issue key: SPARK-44264
Issue id: 13542146
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Critical
Resolution: Fixed
Assignee: 
Reporter: lu.DB
Creator: lu.DB
Created: 6/30/23 20:01
Updated: 5/2/24 6:56
Last Viewed: 7/17/24 20:45
Resolved: 7/11/23 22:37
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: ML, PySpark
Due Date: 
Votes: 0
Labels: pull-request-available
Description: To make it easier for Pyspark users to run distributed training and inference with DeepSpeed on spark clusters using PySpark. This was a project determined by the Databricks ML Training Team.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 19/Jul/23 02:13;erithwik;Trying to Run Deepspeed Funcs.html;https://issues.apache.org/jira/secure/attachment/13061411/Trying+to+Run+Deepspeed+Funcs.html
Custom field (Affects version (Component)): 
Custom field (Attachment count): 1
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Jul 26 17:59:44 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1iwq8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): gurwls223
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 11/Jul/23 22:37;gurwls223;Issue resolved by pull request 41770
[https://github.com/apache/spark/pull/41770];;;, 14/Jul/23 21:19;XinrongM;Issue resolved by pull request https://github.com/apache/spark/pull/41946;;;, 19/Jul/23 02:18;hudson;User 'mathewjacob1002' has created a pull request for this issue:
https://github.com/apache/spark/pull/42067;;;, 26/Jul/23 17:59;ignitetcbot;User 'mathewjacob1002' has created a pull request for this issue:
https://github.com/apache/spark/pull/42118;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 14/Jul/23 21:19;XinrongM;Issue resolved by pull request https://github.com/apache/spark/pull/41946;;;

Summary: Got fetch failed exception when new executor reused same ip address from a previously killed executor
Issue key: SPARK-47678
Issue id: 13574203
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Critical
Resolution: 
Assignee: 
Reporter: bobyangbo
Creator: bobyangbo
Created: 4/2/24 0:40
Updated: 4/15/24 22:46
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.0, 3.4.1, 3.4.2, 3.5.0, 3.5.1
Fix Version/s: 
Component/s: Shuffle
Due Date: 
Votes: 0
Labels: pull-request-available
Description: This is an edge case which caused Spark on Kubernetes getting fetch failed exception when new executor reused same ip address from a previously killed executor.

The new executor checks shuffle block ip address and compares it with its own host address. If the two ip addresses are the same, the new executor will assume the block on its own local disk and try to read it locally. This causes failure since the block is actually on the previously killed executor which happened to have same ip address.
Environment: This only happens on Kubernetes, where same ip address can be re-used for new executor pod.
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 40:14.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1od80:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.4.2
Affects Version/s.3: 3.5.0
Affects Version/s.4: 3.5.1
Comment.1:

Summary: Recover -1 and 0 case for spark.sql.execution.arrow.maxRecordsPerBatch
Issue key: SPARK-47068
Issue id: 13568665
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Critical
Resolution: Fixed
Assignee: gurwls223
Reporter: gurwls223
Creator: gurwls223
Created: 2/16/24 1:16
Updated: 4/2/24 3:48
Last Viewed: 7/17/24 20:45
Resolved: 4/2/24 3:48
Affects Version/s: 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.4.3, 3.5.2, 4.0.0
Component/s: PySpark
Due Date: 
Votes: 0
Labels: pull-request-available
Description: {code}
import pandas as pd
spark.conf.set("spark.sql.execution.arrow.pyspark.enabled", "true")
spark.conf.set("spark.sql.execution.arrow.maxRecordsPerBatch", 0)
spark.conf.set("spark.sql.execution.arrow.pyspark.fallback.enabled", False)
spark.createDataFrame(pd.DataFrame({'a': [123]})).toPandas()

spark.conf.set("spark.sql.execution.arrow.maxRecordsPerBatch", -1)
spark.createDataFrame(pd.DataFrame({'a': [123]})).toPandas()
{code}

{code}
/.../spark/python/pyspark/sql/pandas/conversion.py:371: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true, but has reached the error below and will not continue because automatic fallback with 'spark.sql.execution.arrow.pyspark.fallback.enabled' has been set to false.
  range() arg 3 must not be zero
  warn(msg)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/.../spark/python/pyspark/sql/session.py", line 1483, in createDataFrame
    return super(SparkSession, self).createDataFrame(  # type: ignore[call-overload]
  File "/.../spark/python/pyspark/sql/pandas/conversion.py", line 351, in createDataFrame
    return self._create_from_pandas_with_arrow(data, schema, timezone)
  File "/.../spark/python/pyspark/sql/pandas/conversion.py", line 633, in _create_from_pandas_with_arrow
    pdf_slices = (pdf.iloc[start : start + step] for start in range(0, len(pdf), step))
ValueError: range() arg 3 must not be zero
{code}

{code}
Empty DataFrame
Columns: [a]
Index: []
{code}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Apr 02 03:48:55 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1nfjk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 02/Apr/24 03:48;joshrosen;Marking this issue as fixed.;;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 4.0.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: PruneFilters incorrectly tags isStreaming flag when replacing child of Filter with LocalRelation
Issue key: SPARK-47305
Issue id: 13570978
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Critical
Resolution: Fixed
Assignee: kabhwan
Reporter: kabhwan
Creator: kabhwan
Created: 3/6/24 12:59
Updated: 3/8/24 8:46
Last Viewed: 7/17/24 20:45
Resolved: 3/7/24 6:12
Affects Version/s: 3.4.0, 3.4.1, 3.4.2, 3.5.0, 3.5.1, 4.0.0
Fix Version/s: 3.4.3, 3.5.2, 4.0.0
Component/s: Structured Streaming
Due Date: 
Votes: 0
Labels: pull-request-available
Description: This seems to be a very old bug in optimizer. Related ticket:  https://issues.apache.org/jira/browse/SPARK-21765

When filter is evaluated to be always false, PruneFilters replaces the filter with empty LocalRelation, which effectively prunes filter. The logic cares about migration of the isStreaming flag, but incorrectly migrated in some case, via picking up the value of isStreaming flag from root node rather than filter (or child).

isStreaming flag is true if the value of isStreaming flag from any of children is true. Flipping the coin, some children might have isStreaming flag as "false". If the filter being pruned is a descendant to such children (in other word, ancestor of streaming node), LocalRelation is incorrectly tagged as streaming where it should be batch.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Mar 07 06:12:09 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ntbs:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 07/Mar/24 06:12;kabhwan;Issue resolved by pull request 45406
[https://github.com/apache/spark/pull/45406];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.4.2
Affects Version/s.3: 3.5.0
Affects Version/s.4: 3.5.1
Comment.1:

Summary: Spark Container doesn't have spark group or spark user created
Issue key: SPARK-47105
Issue id: 13569235
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Critical
Resolution: 
Assignee: 
Reporter: albertatcelerdata
Creator: albertatcelerdata
Created: 2/20/24 18:08
Updated: 2/20/24 19:59
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Kubernetes, Spark Docker
Due Date: 
Votes: 0
Labels: 
Description: I see that [https://github.com/apache/spark-docker/blob/431aa516ba58985c902bf2d2a07bf0eaa1df6740/3.4.1/scala2.12-java11-ubuntu/Dockerfile#L19] is supposed to have a spark user and spark group created but checking the container, it doesn't have those uid and gid created.  Both should have 185 uid and 185 gid.

I have no name!@spark-hudi:/opt/spark/bin$ cat /etc/group
root:x:0:
daemon:x:1:
bin:x:2:
sys:x:3:
adm:x:4:
tty:x:5:
disk:x:6:
lp:x:7:
mail:x:8:
news:x:9:
uucp:x:10:
man:x:12:
proxy:x:13:
kmem:x:15:
dialout:x:20:
fax:x:21:
voice:x:22:
cdrom:x:24:
floppy:x:25:
tape:x:26:
sudo:x:27:
audio:x:29:
dip:x:30:
www-data:x:33:
backup:x:34:
operator:x:37:
list:x:38:
irc:x:39:
src:x:40:
gnats:x:41:
shadow:x:42:
utmp:x:43:
video:x:44:
sasl:x:45:
plugdev:x:46:
staff:x:50:
games:x:60:
users:x:100:
nogroup:x:65534:
I have no name!@spark-hudi:/opt/spark/bin$ cat /etc/passwd
root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
bin:x:2:2:bin:/bin:/usr/sbin/nologin
sys:x:3:3:sys:/dev:/usr/sbin/nologin
sync:x:4:65534:sync:/bin:/bin/sync
games:x:5:60:games:/usr/games:/usr/sbin/nologin
man:x:6:12:man:/var/cache/man:/usr/sbin/nologin
lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin
mail:x:8:8:mail:/var/mail:/usr/sbin/nologin
news:x:9:9:news:/var/spool/news:/usr/sbin/nologin
uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:x:13:13:proxy:/bin:/usr/sbin/nologin
www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin
backup:x:34:34:backup:/var/backups:/usr/sbin/nologin
list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:x:39:39:ircd:/run/ircd:/usr/sbin/nologin
gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin
_apt:x:100:65534::/nonexistent:/usr/sbin/nologin

I have no name!@spark-hudi:/opt/spark/bin$ cat /etc/passwd
root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
bin:x:2:2:bin:/bin:/usr/sbin/nologin
sys:x:3:3:sys:/dev:/usr/sbin/nologin
sync:x:4:65534:sync:/bin:/bin/sync
games:x:5:60:games:/usr/games:/usr/sbin/nologin
man:x:6:12:man:/var/cache/man:/usr/sbin/nologin
lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin
mail:x:8:8:mail:/var/mail:/usr/sbin/nologin
news:x:9:9:news:/var/spool/news:/usr/sbin/nologin
uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:x:13:13:proxy:/bin:/usr/sbin/nologin
www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin
backup:x:34:34:backup:/var/backups:/usr/sbin/nologin
list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:x:39:39:ircd:/run/ircd:/usr/sbin/nologin
gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin
_apt:x:100:65534::/nonexistent:/usr/sbin/nologin
Environment: Using container apache/spark-py:latest
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Feb 20 19:59:31 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1nikg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): gurwls223
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 20/Feb/24 19:59;albertatcelerdata;Related: https://issues.apache.org/jira/browse/SPARK-45557;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: CSV reader reads data inconsistently depending on column position
Issue key: SPARK-46959
Issue id: 13567182
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Critical
Resolution: 
Assignee: 
Reporter: martinitus
Creator: martinitus
Created: 2/2/24 12:09
Updated: 2/5/24 12:45
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: Reading the following CSV
{code:java}
"a";"b";"c";"d"
10;100,00;"Some;String";"ok"
20;200,00;"";"still ok"
30;300,00;"also ok";""
40;400,00;"";"" {code}
with these options
{code:java}
spark.read
        .option("header","true")
        .option("sep",";")
        .option("encoding","ISO-8859-1")
        .option("lineSep","\r\n")
        .option("nullValue","")
        .option("quote",'"')
        .option("escape","") {code}
results in the followin inconsistent dataframe

 
||a||b||c||d||
|10|100,00|Some;String|ok|
|20|200,00|<null>|still ok|
|30|300,00|also ok|"|
|40|400,00|<null>|"|

As one can see, the quoted empty fields of the last column are not correctly read as null but instead contain a single double quote. It works for column c.

If I recall correctly, this only happens when the "escape" option is set to an empty string. Not setting it to "" (defaults to "\") seems to not cause this bug.

I observed this on databricks spark runtime 13.2 (think that is spark 3.4.1).
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Feb 05 12:45:57 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1n6e8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 05/Feb/24 12:45;martinitus;Is there an option to disable escaping?

A potential fix for this would be to not allow an empty string as escape: raise exception when this option value is specified.

Quietly reading in garbage is kind of the worst case scenario (at least when mode="FAILFAST").;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Unable to read from JDBC data sources when using custom schema containing varchar
Issue key: SPARK-44638
Issue id: 13545889
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Critical
Resolution: 
Assignee: 
Reporter: michaelsaid
Creator: michaelsaid
Created: 8/2/23 16:33
Updated: 1/11/24 11:03
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.1.0, 3.2.4, 3.3.2, 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: When querying the data from JDBC databases with custom schema containing varchar I got this error :
{code:java}
[23/07/14 06:12:19 WARN TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1) ( executor 1): java.sql.SQLException: Unsupported type varchar(100) at org.apache.spark.sql.errors.QueryExecutionErrors$.unsupportedJdbcTypeError(QueryExecutionErrors.scala:818) 23/07/14 06:12:21 INFO TaskSetManager: Lost task 0.1 in stage 1.0 (TID 2) on , executor 0: java.sql.SQLException (Unsupported type varchar(100)){code}
Code example: 
{code:java}
CUSTOM_SCHEMA="ID Integer, NAME VARCHAR(100)"
df = spark.read.format("jdbc")
.option("url", "jdbc:oracle:thin:@0.0.0.0:1521:db")
.option("driver", "oracle.jdbc.OracleDriver")
.option("dbtable", "table")
.option("customSchema", CUSTOM_SCHEMA)
.option("user", "user")
.option("password", "password")
.load()
df.show(){code}
I tried to set {{spark.sql.legacy.charVarcharAsString = true}} to restore the behavior before Spark 3.1 but it doesn't help.
The issue occurs in version 3.1.0 and above. I believe that this issue is caused by https://issues.apache.org/jira/browse/SPARK-33480
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Jan 11 11:03:19 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jjr4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 11/Jan/24 11:03;yao;Can you reproduce this issue on 3.5.0 or master branch?;;;
Affects Version/s.1: 3.2.4
Affects Version/s.2: 3.3.2
Affects Version/s.3: 3.4.1
Affects Version/s.4: 
Comment.1:

Summary: Pyspark DecisionTreeClassifier: results and tree structure in spark3 very different from that of the spark2 version on the same data and with the same hyperparameters.
Issue key: SPARK-45154
Issue id: 13550538
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Critical
Resolution: 
Assignee: 
Reporter: oumarnour
Creator: oumarnour
Created: 9/13/23 13:39
Updated: 12/12/23 12:34
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.0.0, 3.2.4, 3.3.1, 3.3.2, 3.3.3, 3.4.0, 3.4.1
Fix Version/s: 
Component/s: ML, MLlib, PySpark, Spark Core
Due Date: 
Votes: 0
Labels: decisiontree, pyspark3, spark2, spark3
Description: Hello,
I have an engine running on spark2 using a DecisionTreeClassifier model using the CrossValidator. 

 
{code:java}
dt  = DecisionTreeClassifier(maxBins=10000, seed=0)   
cv_dt_evaluator = BinaryClassificationEvaluator(
            metricName="", 
            rawPredictionCol="probability")

# Create param grid and cross validator for model selection
dt_grid = ParamGridBuilder()\
            .addGrid(
                dt.minInstancesPerNode, [100]
        )\
            .addGrid(
                dt.maxDepth, [10]
        )\
            .build()
cv = CrossValidator(
            estimator=dt, estimatorParamMaps=dt_grid, evaluator=cv_dt_evaluator,
            parallelism=4
            numFolds=4
        ){code}
 

I want to {*}migrate from spark2  to spark3{*}. I've run *DecisionTreeClassifier* on the same data with the same parameter values. But unfortunately my results are {*}completely different, especially in terms of tree structure{*}. I have trees with less depth and fewer splits on spark3. I've tried to read the documentation but I haven't found an answer to my question.

 

Can you help me find a solution to this problem?

Thanks in advance for your help 

        

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): pyspark, Python3, Spark2, spark3
Custom field (Last public comment date): Tue Dec 12 12:34:22 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kc2o:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 12/Dec/23 12:34;apeng;[~oumarnour] I think you need to set the _seed_ param of CrossValidator.;;;
Affects Version/s.1: 3.2.4
Affects Version/s.2: 3.3.1
Affects Version/s.3: 3.3.2
Affects Version/s.4: 3.3.3
Comment.1:

Summary: Fix PERCENTILE_DISC behaviour
Issue key: SPARK-44871
Issue id: 13547866
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Critical
Resolution: Fixed
Assignee: petertoth
Reporter: petertoth
Creator: petertoth
Created: 8/18/23 12:54
Updated: 11/24/23 22:24
Last Viewed: 7/17/24 20:45
Resolved: 8/22/23 16:27
Affects Version/s: 3.3.0, 3.3.1, 3.3.2, 3.3.3, 3.4.0, 3.4.1
Fix Version/s: 3.3.4, 3.4.2, 3.5.0, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: correctness
Description: Currently {{percentile_disc()}} returns incorrect results in some cases:

E.g.:
{code:java}
SELECT
  percentile_disc(0.0) WITHIN GROUP (ORDER BY a) as p0,
  percentile_disc(0.1) WITHIN GROUP (ORDER BY a) as p1,
  percentile_disc(0.2) WITHIN GROUP (ORDER BY a) as p2,
  percentile_disc(0.3) WITHIN GROUP (ORDER BY a) as p3,
  percentile_disc(0.4) WITHIN GROUP (ORDER BY a) as p4,
  percentile_disc(0.5) WITHIN GROUP (ORDER BY a) as p5,
  percentile_disc(0.6) WITHIN GROUP (ORDER BY a) as p6,
  percentile_disc(0.7) WITHIN GROUP (ORDER BY a) as p7,
  percentile_disc(0.8) WITHIN GROUP (ORDER BY a) as p8,
  percentile_disc(0.9) WITHIN GROUP (ORDER BY a) as p9,
  percentile_disc(1.0) WITHIN GROUP (ORDER BY a) as p10
FROM VALUES (0), (1), (2), (3), (4) AS v(a)
{code}
returns:
{code:java}
+---+---+---+---+---+---+---+---+---+---+---+
| p0| p1| p2| p3| p4| p5| p6| p7| p8| p9|p10|
+---+---+---+---+---+---+---+---+---+---+---+
|0.0|0.0|0.0|1.0|1.0|2.0|2.0|2.0|3.0|3.0|4.0|
+---+---+---+---+---+---+---+---+---+---+---+
{code}
but it should return:
{noformat}
+---+---+---+---+---+---+---+---+---+---+---+
| p0| p1| p2| p3| p4| p5| p6| p7| p8| p9|p10|
+---+---+---+---+---+---+---+---+---+---+---+
|0.0|0.0|0.0|1.0|1.0|2.0|2.0|3.0|3.0|4.0|4.0|
+---+---+---+---+---+---+---+---+---+---+---+
{noformat}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Aug 22 16:27:35 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jvlc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 18/Aug/23 17:44;tgraves;Can you add a description to this please;;;, 18/Aug/23 18:37;petertoth;[~tgraves], sure, I've just updated it.

It looks like my PR didn't get linked here automatically, so here it is: https://github.com/apache/spark/pull/42559;;;, 22/Aug/23 16:27;maxgekk;Issue resolved by pull request 42610
[https://github.com/apache/spark/pull/42610];;;
Affects Version/s.1: 3.3.1
Affects Version/s.2: 3.3.2
Affects Version/s.3: 3.3.3
Affects Version/s.4: 3.4.0
Comment.1: 18/Aug/23 18:37;petertoth;[~tgraves], sure, I've just updated it.

It looks like my PR didn't get linked here automatically, so here it is: https://github.com/apache/spark/pull/42559;;;

Summary: Parquet INT64 (TIMESTAMP(NANOS,false)) throwing Illegal Parquet type
Issue key: SPARK-44988
Issue id: 13548859
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Critical
Resolution: 
Assignee: 
Reporter: flavioodas
Creator: flavioodas
Created: 8/28/23 15:47
Updated: 10/9/23 9:56
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.0, 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 4
Labels: 
Description: This bug seems similar to https://issues.apache.org/jira/browse/SPARK-40819, except that it's a problem with INT64 (TIMESTAMP(NANOS,false)), instead of INT64 (TIMESTAMP(NANOS,true)).

The error happens whenever I'm trying to read:
{code:java}
org.apache.spark.sql.AnalysisException: Illegal Parquet type: INT64 (TIMESTAMP(NANOS,false)).
	at org.apache.spark.sql.errors.QueryCompilationErrors$.illegalParquetTypeError(QueryCompilationErrors.scala:1762)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetToSparkSchemaConverter.illegalType$1(ParquetSchemaConverter.scala:206)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetToSparkSchemaConverter.$anonfun$convertPrimitiveField$2(ParquetSchemaConverter.scala:283)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetToSparkSchemaConverter.convertPrimitiveField(ParquetSchemaConverter.scala:224)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetToSparkSchemaConverter.convertField(ParquetSchemaConverter.scala:187)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetToSparkSchemaConverter.$anonfun$convertInternal$3(ParquetSchemaConverter.scala:147)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetToSparkSchemaConverter.$anonfun$convertInternal$3$adapted(ParquetSchemaConverter.scala:117)
	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
	at scala.collection.immutable.Range.foreach(Range.scala:158)
	at scala.collection.TraversableLike.map(TraversableLike.scala:286)
	at scala.collection.TraversableLike.map$(TraversableLike.scala:279)
	at scala.collection.AbstractTraversable.map(Traversable.scala:108)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetToSparkSchemaConverter.convertInternal(ParquetSchemaConverter.scala:117)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetToSparkSchemaConverter.convert(ParquetSchemaConverter.scala:87)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$readSchemaFromFooter$2(ParquetFileFormat.scala:493)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.readSchemaFromFooter(ParquetFileFormat.scala:493)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$2(ParquetFileFormat.scala:473)
	at scala.collection.immutable.Stream.map(Stream.scala:418)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1(ParquetFileFormat.scala:473)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.$anonfun$mergeSchemasInParallel$1$adapted(ParquetFileFormat.scala:464)
	at org.apache.spark.sql.execution.datasources.SchemaMergeUtils$.$anonfun$mergeSchemasInParallel$2(SchemaMergeUtils.scala:79)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:853)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:853)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:139)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557) {code}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Oct 09 09:56:14 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k1ps:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 31/Aug/23 13:27;fanjia;Have you tried setting spark.sql.legacy.parquet.nanosAsLong to true？;;;, 09/Oct/23 09:56;milesgranger;[~fanjia]that "worked" for me, but then of course need to cast the resulting bigint to a timestamp, which I feel is error prone. Would be nice if spark supported timestamp[ns] though.;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 09/Oct/23 09:56;milesgranger;[~fanjia]that "worked" for me, but then of course need to cast the resulting bigint to a timestamp, which I feel is error prone. Would be nice if spark supported timestamp[ns] though.;;;

Summary: Migrated shuffle blocks are encrypted multiple times when io.encryption is enabled 
Issue key: SPARK-44588
Issue id: 13545325
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Critical
Resolution: Fixed
Assignee: henrymai
Reporter: henrymai
Creator: henrymai
Created: 7/28/23 15:55
Updated: 8/2/23 4:08
Last Viewed: 7/17/24 20:45
Resolved: 8/1/23 21:41
Affects Version/s: 3.1.0, 3.1.1, 3.1.2, 3.1.3, 3.2.0, 3.2.1, 3.2.2, 3.2.3, 3.2.4, 3.3.0, 3.3.1, 3.3.2, 3.4.0, 3.4.1
Fix Version/s: 3.3.3, 3.4.2, 3.5.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: Shuffle blocks upon migration are wrapped for encryption again when being written out to a file on the receiver side.

 

Pull request to fix this: https://github.com/apache/spark/pull/42214

 

Details:

Sender/Read side:

BlockManagerDecommissioner:run()
    blocks = bm.migratableResolver.getMigrationBlocks()
        *dataFile = IndexShuffleBlockResolver:getDataFile(...)*
       buffer = FileSegmentManagedBuffer(..., dataFile)
                       *^ This reads straight from disk without decryption*
    blocks.foreach((blockId, buffer) => bm.blockTransferService.uploadBlockSync(..., buffer, ...))
        -> uploadBlockSync() -> uploadBlock(..., buffer, ...)
            -> client.uploadStream(UploadBlockStream, buffer, ...)
 - Notice that there is no decryption here on the sender/read side.

Receiver/Write side:

NettyBlockRpcServer:receiveStream() <--- This is the UploadBlockStream handler
    putBlockDataAsStream()
        migratableResolver.putShuffleBlockAsStream()
            *-> file = IndexShuffleBlockResolver:getDataFile(...)*
            -> tmpFile = (file + .<uuid> extension)
            *-> Creates an encrypting writable channel to a tmpFile using serializerManager.wrapStream()*
            -> onData() writes the data into the channel
            -> onComplete() renames the tmpFile to the file
 - Notice:

 * Both getMigrationBlocks()[read] and putShuffleBlockAsStream()[write] target IndexShuffleBlockResolver:getDataFile()
 * The read path does not decrypt but the write path encrypts.
 * As a thought exercise: if this cycle happens more than once (where this receiver is now a sender) even if we assume that the shuffle blocks are initially unencrypted*, then bytes in the file will just have more and more layers of encryption applied to it each time it gets migrated.
 * *In practice, the shuffle blocks are encrypted on disk to begin with, this is just a thought exercise
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): SPARK-20629
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 55:04.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jg9s:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.1.1, 3.3.1, 3.3.2, 3.4.0, 3.4.1
Affects Version/s.2: 3.1.2
Affects Version/s.3: 3.1.3
Affects Version/s.4: 3.2.0
Comment.1:

Summary: Fix catalog.listCatalogs in PySpark
Issue key: SPARK-43527
Issue id: 13536410
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Critical
Resolution: Fixed
Assignee: podongfeng
Reporter: podongfeng
Creator: podongfeng
Created: 5/16/23 13:27
Updated: 5/16/23 23:31
Last Viewed: 7/17/24 20:45
Resolved: 5/16/23 23:31
Affects Version/s: 3.4.0, 3.4.1, 3.5.0
Fix Version/s: 3.4.1, 3.5.0
Component/s: PySpark
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue May 16 23:31:48 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1hxfk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 16/May/23 23:31;gurwls223;Issue resolved by pull request 41186
[https://github.com/apache/spark/pull/41186];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: High On-heap memory usage is detected while doing parquet-file reading with Off-Heap memory mode enabled on spark
Issue key: SPARK-44718
Issue id: 13546525
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: majdyz
Reporter: majdyz
Creator: majdyz
Created: 8/8/23 11:55
Updated: 7/2/24 17:06
Last Viewed: 7/17/24 20:45
Resolved: 8/15/23 10:10
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: Spark Core, SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: I see the high use of on-heap memory usage while doing the parquet file reading when the off-heap memory mode is enabled. This is caused by the memory-mode for the column vector for the vectorized reader is configured by different flag, and the default value is always set to On-Heap.

Conf to reproduce the issue:

{{spark.memory.offHeap.size 1000000}}
{{spark.memory.offHeap.enabled true}}

Enabling these configurations only will not change the memory mode used for parquet-reading by the vectorized reader to Off-Heap.

 

Proposed PR: https://github.com/apache/spark/pull/42394
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): Patch
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Aug 15 10:10:39 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jnog:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 09/Aug/23 04:18;snoot;User 'majdyz' has created a pull request for this issue:
https://github.com/apache/spark/pull/42394;;;, 15/Aug/23 10:10;cloud_fan;Issue resolved by pull request 42394
[https://github.com/apache/spark/pull/42394];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 15/Aug/23 10:10;cloud_fan;Issue resolved by pull request 42394
[https://github.com/apache/spark/pull/42394];;;

Summary: Writing to JDBC Temporary View Failed
Issue key: SPARK-48562
Issue id: 13581892
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: jackylee
Creator: jackylee
Created: 6/7/24 7:15
Updated: 6/12/24 3:00
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.0, 3.4.1, 3.4.2, 3.4.3, 3.5.0, 3.5.1, 4.0.0
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: When creating a JDBC temporary view, *ApplyCharTypePadding* would add a Project before LogicalRelation if CHAR/VARCHAR column exists and Spark would save it as a view plan. Then if we try to write this view, Spark would put this view plan to *InsertintoStatement* in *ResolveRelations* which would fall {*}PrewriteCheck{*}.

Adding the following code to *JDBCTableCatalogSuite* would meet this problem.
{code:java}
test("test writing temporary jdbc view") {
    withConnection { conn =>
      conn.prepareStatement("""CREATE TABLE "test"."to_drop" (id CHAR)""").executeUpdate()
    }
    sql(
      s"""
        CREATE TEMPORARY TABLE jdbcTable
        USING jdbc
        OPTIONS (
          url='$url',
          dbtable='"test"."to_drop"');""")
    sql("INSERT INTO jdbcTable values(1),(2)")
    sql("select * from test.to_drop").show()
    withConnection { conn =>
      conn.prepareStatement("""DROP TABLE "test"."to_drop"""").executeUpdate()
    }
  } {code}
 

Then we would get the following error.
{code:java}
[UNSUPPORTED_INSERT.RDD_BASED] Can't insert into the target. An RDD-based table is not allowed. SQLSTATE: 42809;
'InsertIntoStatement Project [staticinvoke(class org.apache.spark.sql.catalyst.util.CharVarcharCodegenUtils, StringType, readSidePadding, ID#0, 1, true, false, true) AS ID#1], false, false, false
+- LocalRelation [col1#3] {code}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Jun 12 03:00:10 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1po54:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 11/Jun/24 07:02;jackylee;[~cloud_fan] Maybe we need to move *{color:#172b4d}ApplyCharTypePaddin{color}{{{}g{}}}* from *Anlyzer* to *Planer* to solve this bug.

The *ApplyCharTypePadding* is currently defined in the *Analyzer* layer, it conflicts with other ResolveRule rules in the {*}Analyzer{*}, as other ResolveRule rules are one-to-one modification rules, while *ApplyCharTypePadding* exhibits different behavior.

Therefore, we need to consider refactoring the *ApplyCharTypePadding* rule and moving it to the *Planner* layer. This can avoid inconsistent behavior in the Analyzer layer without affecting other logic.

 

Correct me if I'm wrong. Or maybe any better idea to solve this problem?

also cc [~yao] ;;;, 11/Jun/24 15:19;cloud_fan;writing to a temp view is an ill pattern IMO...;;;, 12/Jun/24 03:00;jackylee;Thanks for your reply. Since we do not restrict writes to views, users have the flexibility to utilize them in their scenarios. Additionally, temporary tables serve various purposes, such as mitigating data conflicts and minimizing metadata impact. Therefore, I believe it is essential to maintain support for this behavior unless a specific rule is implemented to explicitly prohibit such operations.;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.4.2
Affects Version/s.3: 3.4.3
Affects Version/s.4: 3.5.0
Comment.1: 11/Jun/24 15:19;cloud_fan;writing to a temp view is an ill pattern IMO...;;;

Summary: Overwriting the same partition of a partitioned table multiple times with empty data yields non-idempotent results
Issue key: SPARK-44473
Issue id: 13543899
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: ychris
Creator: ychris
Created: 7/18/23 8:03
Updated: 6/5/24 2:59
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.1.3, 3.2.4, 3.3.2, 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description:  

Preparation:
Create a simple partition table using spark version 3.x, for example:

 
{code:java}
spark-sql> create table test1 (a int) partitioned by (dt string);
Time taken: 0.219 seconds{code}
 

 
 * Overwrite a new partition with empty data, and you can see that the partition information and the corresponding HDFS path are generated , for example:

{code:java}

spark-sql> insert overwrite table test1 partition(dt='20230702') select 2 where 1 <> 1;
Time taken: 0.992 seconds
spark-sql> dfs -ls /user/hive/warehouse/test1;
Found 2 items
-rw-r--r-- 2 hadoop hadoop 0 2023-07-18 14:41 /user/hive/warehouse/test1/_SUCCESS
drwxrwxrwx- hadoop hadoop 0 2023-07-18 14:41 /user/hive/warehouse/test1/dt=20230702
spark-sql> show partitions test1;
dt=20230702
Time taken: 0.162 seconds, Fetched 1 row(s)
{code}
 * When re-running the insert overwrite statement, you can see that the HDFS path corresponding to this partition does not exist.

 
{code:java}
spark-sql> insert overwrite table test1 partition(dt='20230702') select 2 where 1 <> 1;
Time taken: 0.706 seconds
spark-sql> dfs -ls /user/hive/warehouse/test1;
Found 1 items
-rw-r--r--   2 hadoop hadoop          0 2023-07-18 14:45 /user/hive/warehouse/test1/_SUCCESS
spark-sql> show partitions test1;
dt=20230702
Time taken: 0.183 seconds, Fetched 1 row(s){code}
For subsequent tasks that need to use this HDFS path, an exception that the path does not exist will be thrown, which caused us trouble.

 

I was expecting to execute the same statement multiple times to get the same result, {*}not non-idempotent{*}. thanks.
Environment: spark : 3.x
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): Patch
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 03:07.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j7hk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.2.4
Affects Version/s.2: 3.3.2
Affects Version/s.3: 3.4.1
Affects Version/s.4: 
Comment.1:

Summary: batch-read parquet files written by streaming returns non-nullable fields in schema
Issue key: SPARK-48492
Issue id: 13581205
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: JulienPeloton
Creator: JulienPeloton
Created: 5/31/24 19:16
Updated: 6/3/24 11:03
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Structured Streaming
Due Date: 
Votes: 0
Labels: 
Description: Hello,

In the documentation, it is stated that

> When reading Parquet files, all columns are automatically converted to be nullable for compatibility reasons.

While this seems correct for static DataFrames, I have a counter example for streaming ones:

 
{code:java}
from pyspark.sql import SparkSession
from pyspark.sql import Row
import pyspark.sql.functions as F

spark = SparkSession.builder.getOrCreate()
spark.sparkContext.setLogLevel("WARN")

df = spark.createDataFrame(
    [
        Row(a=1, b=2.0, c="toto"),
        Row(a=3, b=4.0, c="titi"),
        Row(a=10, b=11.0, c="tutu"),
    ]
)

# add a non-nullable column
df = df.withColumn('d', F.lit(1.0))

print("Original dataframe")
df.printSchema()

# Write this on disk
df.write.parquet('static.parquet')

# Now load a stream
df_stream = (
    spark.readStream.format("parquet")
    .schema(df.schema)
    .option("path", "static.parquet")
    .option("latestFirst", False)
    .load()
)

# add a non-nullable column
df_stream = df_stream.withColumn('e', F.lit("error"))

print("Streaming dataframe")
df_stream.printSchema()

# Now write the dataframe using writestream
query = (
    df_stream.writeStream.outputMode("append")
    .format("parquet")
    .option("checkpointLocation", 'test_parquet_checkpoint')
    .option("path", 'test_parquet')
    .trigger(availableNow=True)
    .start()
)

spark.streams.awaitAnyTermination()

# Now read back
df_stream_2 = spark.read.format("parquet").load("test_parquet")

print("Static dataframe from the streaming job (read)")
df_stream_2.printSchema() 

# Now load a stream
df_stream_3 = (
    spark.readStream.format("parquet")
    .schema(df_stream_2.schema)
    .option("path", "test_parquet")
    .option("latestFirst", False)
    .load()
)

print("Streaming dataframe from the streaming job (readStream)")
df_stream_3.printSchema(){code}
 

 

which outputs:
{noformat}
Original dataframe
root
 |-- a: long (nullable = true)
 |-- b: double (nullable = true)
 |-- c: string (nullable = true)
 |-- d: double (nullable = false)

Streaming dataframe
root
 |-- a: long (nullable = true)
 |-- b: double (nullable = true)
 |-- c: string (nullable = true)
 |-- d: double (nullable = true)
 |-- e: string (nullable = false)

Static dataframe from the streaming job (read)
root
 |-- a: long (nullable = true)
 |-- b: double (nullable = true)
 |-- c: string (nullable = true)
 |-- d: double (nullable = true)
 |-- e: string (nullable = false)

Streaming dataframe from the streaming job (readStream)
root
 |-- a: long (nullable = true)
 |-- b: double (nullable = true)
 |-- c: string (nullable = true)
 |-- d: double (nullable = true)
 |-- e: string (nullable = true){noformat}
 

So the column `d` is correctly set to `nullable = true` (expected), but in the case of the column `e`, it stays non-nullable if it is read using the `read` method and it is correctly set to `nullable = true` if read with `readStream`. Is that expected? According to this old issue, https://issues.apache.org/jira/browse/SPARK-28651, it was supposed to be resolved. Any ideas?
Environment: python --version
Python 3.9.13

 

spark-submit --version
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 3.4.1
      /_/
                        
Using Scala version 2.12.17, OpenJDK 64-Bit Server VM, 1.8.0_302
Branch HEAD
Compiled by user centos on 2023-06-19T23:01:01Z
Revision 6b1ff22dde1ead51cbf370be6e48a802daae58b6
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 16:35.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1pjwo:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Add to_varchar alias for to_char SQL function
Issue key: SPARK-43815
Issue id: 13537827
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: ryu796
Reporter: ryu796
Creator: ryu796
Created: 5/26/23 15:44
Updated: 5/24/24 2:37
Last Viewed: 7/17/24 20:45
Resolved: 5/30/23 18:48
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: We want to add the alias to_varchar for the function to_char. 

For users who are migrating to Spark SQL such that the SQL engine they formerly used supported to_varchar instead of to_char, this change would minimize the number of changes to their application to ensure it is compatible with Spark SQL syntax and support.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue May 30 18:48:22 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1i660:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 26/May/23 18:06;maxgekk;[~ryu796] Let's focus on the first item, and create separate JIRAs for other items.;;;, 30/May/23 18:48;maxgekk;Issue resolved by pull request 41319
[https://github.com/apache/spark/pull/41319];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 30/May/23 18:48;maxgekk;Issue resolved by pull request 41319
[https://github.com/apache/spark/pull/41319];;;

Summary: Kryo serialization issue with push-based shuffle
Issue key: SPARK-48043
Issue id: 13577567
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: romainardiet
Creator: romainardiet
Created: 4/29/24 11:02
Updated: 5/13/24 13:06
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Shuffle
Due Date: 
Votes: 0
Labels: 
Description: I'm running a spark job on AWS EMR. I wanted to test the new push-based shuffle introduced in Spark 3.2 but it's failing with a kryo exception when I'm enabling it.

The issue is happening when Executor starts, during 
KryoSerializerInstance.getAutoReset() check:
{code:java}
24/04/24 15:36:22 ERROR YarnCoarseGrainedExecutorBackend: Executor self-exiting due to : Unable to create executor due to Failed to register classes with Kryo
org.apache.spark.SparkException: Failed to register classes with Kryo
    at org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$5(KryoSerializer.scala:186) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]
    at org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:241) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.serializer.KryoSerializer.newKryo(KryoSerializer.scala:174) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.serializer.KryoSerializer$$anon$1.create(KryoSerializer.scala:105) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at com.esotericsoftware.kryo.pool.KryoPoolQueueImpl.borrow(KryoPoolQueueImpl.java:48) ~[kryo-shaded-4.0.2.jar:?]
    at org.apache.spark.serializer.KryoSerializer$PoolWrapper.borrow(KryoSerializer.scala:112) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.serializer.KryoSerializerInstance.borrowKryo(KryoSerializer.scala:352) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.serializer.KryoSerializerInstance.getAutoReset(KryoSerializer.scala:452) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.serializer.KryoSerializer.supportsRelocationOfSerializedObjects$lzycompute(KryoSerializer.scala:259) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.serializer.KryoSerializer.supportsRelocationOfSerializedObjects(KryoSerializer.scala:255) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.util.Utils$.serializerIsSupported$lzycompute$1(Utils.scala:2721) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.util.Utils$.serializerIsSupported$1(Utils.scala:2716) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.util.Utils$.isPushBasedShuffleEnabled(Utils.scala:2730) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.storage.BlockManager.initialize(BlockManager.scala:554) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.executor.Executor.<init>(Executor.scala:143) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1.applyOrElse(CoarseGrainedExecutorBackend.scala:190) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_402]
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_402]
    at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_402]
Caused by: java.lang.ClassNotFoundException: com.analytics.AnalyticsEventWrapper
    at java.net.URLClassLoader.findClass(URLClassLoader.java:387) ~[?:1.8.0_402]
    at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[?:1.8.0_402]
    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352) ~[?:1.8.0_402]
    at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[?:1.8.0_402]
    at java.lang.Class.forName0(Native Method) ~[?:1.8.0_402]
    at java.lang.Class.forName(Class.java:348) ~[?:1.8.0_402]
    at org.apache.spark.util.Utils$.classForName(Utils.scala:228) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$6(KryoSerializer.scala:177) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62) ~[scala-library-2.12.15.jar:?]
    at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55) ~[scala-library-2.12.15.jar:?]
    at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49) ~[scala-library-2.12.15.jar:?]
    at org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$5(KryoSerializer.scala:176) ~[spark-core_2.12-3.4.1-amzn-1.jar:3.4.1-amzn-1]
    ... 24 more
24/04/24 15:36:22 INFO YarnCoarseGrainedExecutorBackend: Driver commanded a shutdown
24/04/24 15:36:22 ERROR Utils: Uncaught exception in thread shutdown-hook-0
 {code}
My job code is the following:
{code:java}
package com.analytics.spark;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.function.MapFunction;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Encoders;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

import com.analytics.archive.AnalyticsEventWrapperRowMapper;
import com.analytics.AnalyticsEventWrapper;

public class ProcessAnalyticsEventJob {
  public static void main(String[] args) throws Exception {
    SparkConf sparkConf = new SparkConf()
        .setMaster("yarn")
        .registerKryoClasses(AnalyticsEventWrapper.class);
        
    SparkSession spark = SparkSession.builder().config(sparkConf).getOrCreate();
        
    MapFunction<Row, AnalyticsEventWrapper> mapAsAnalyticsEventWrapper = AnalyticsEventWrapperRowMapper::map;
    Dataset<AnalyticsEventWrapper> inputDataset = spark.read()
        .parquet("s3://bucket/path/to/events")
        .map(mapAsAnalyticsEventWrapper, Encoders.kryo(AnalyticsEventWrapper.class));
        
    // rest of the job (shuffle aggregation and output write)
  }
} {code}
AnalyticsEventWrapperRowMapper.java
{code:java}
package com.analytics.archive;

import org.apache.spark.sql.Row;
import com.analytics.AnalyticsEventWrapper;

public class AnalyticsEventWrapperRowMapper {
    public static AnalyticsEventWrapper map(Row r) {
        AnalyticsEventWrapper analyticsEventWrapper = new AnalyticsEventWrapper();
        analyticsEventWrapper.setId(r.getAs("id"));
        analyticsEventWrapper.setTimestamp(r.getAs("timestamp"));
        analyticsEventWrapper.setType(r.getAs("type"));
        analyticsEventWrapper.setTopic(r.getAs("topic"));
        return analyticsEventWrapper;
    }
} {code}
AnalyticsEventWrapper.java
{code:java}
package com.analytics;

public class AnalyticsEventWrapper {
    private String id;
    private Long timestamp;
    private String type;
    private String topic;
    
    public String getId() {
        return id;
    }
    
    public void setId(String id) {
        this.id = id;
    }
    
    public Long getTimestamp() {
        return timestamp;
    }
    
    public void setTimestamp(Long timestamp) {
        this.timestamp = timestamp;
    }
    
    public String getType() {
        return type;
    }
    
    public void setType(String type) {
        this.type = type;
    }
    
    public String getTopic() {
        return topic;
    }
    
    public void setTopic(String topic) {
        this.topic = topic;
    }
} {code}
the job is launched on EMR with spark-submit command (all application code is packaged in application.jar with maven shade plugin):
{code:java}
// work
spark-submit --class com.analytics.spark.ProcessAnalyticsEventJob \
  /tmp/application.jar \
  --deploy-mode cluster \
  --verbose

// kryo issue
spark-submit --class com.analytics.spark.ProcessAnalyticsEventJob \
  /tmp/application.jar \
  --deploy-mode cluster \
  --verbose \
  --conf "spark.shuffle.push.enabled=true"

// yarn-site.xml of Node Managers
<property>
  <name>spark.shuffle.push.server.mergedShuffleFileManagerImpl</name>
  <value>org.apache.spark.network.shuffle.RemoteBlockPushResolver</value>
</property>  {code}
Environment: AWS EMR 6.14 (Spark 3.4.1)
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 02:44.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1oxio:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Invalid previous reader checks in Vectorized DELTA_BYTE_ARRAY parquet decoder
Issue key: SPARK-48234
Issue id: 13578869
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: yutsareva
Creator: yutsareva
Created: 5/10/24 12:31
Updated: 5/10/24 14:57
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.2.0, 3.2.1, 3.2.2, 3.2.3, 3.2.4, 3.3.0, 3.3.1, 3.3.2, 3.3.3, 3.3.4, 3.4.0, 3.4.1, 3.4.2, 3.4.3, 3.5.0, 3.5.1
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: The vectorized DELTA_BYTE_ARRAY Parquet decoder can cause read failures when reading columns with varying page encodings and if some pages are encoded using DELTA_BYTE_ARRAY.

Same bug existed in parquet-mr reader but was fixed 3 months ago. There is no separate bug fix commit, it was silently fixed along with other changes. https://github.com/apache/parquet-mr/blob/c241170d9bc2cd8415b04e06ecea40ed3d80f64d/parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderBase.java#L732
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 31:28.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1p5iw:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.2.1, 3.4.0, 3.4.1, 3.4.2, 3.4.3, 3.5.0, 3.5.1
Affects Version/s.2: 3.2.2
Affects Version/s.3: 3.2.3
Affects Version/s.4: 3.2.4
Comment.1:

Summary: ExecutorPodsAllocator doesn't create new executors if no pod snapshot captured pod creation
Issue key: SPARK-44609
Issue id: 13545545
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: alibiyeslambek
Creator: alibiyeslambek
Created: 7/31/23 13:01
Updated: 5/10/24 0:19
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Kubernetes, Scheduler
Due Date: 
Votes: 0
Labels: pull-request-available
Description: There’s a following race condition in ExecutorPodsAllocator when running a spark application with static allocation on kubernetes with numExecutors >= 1:
 * Driver requests an executor
 * exec-1 gets created and registers with driver
 * exec-1 is moved from {{newlyCreatedExecutors}} to {{schedulerKnownNewlyCreatedExecs}}
 * exec-1 got deleted very quickly (~1-30 sec) after registration
 * {{ExecutorPodsWatchSnapshotSource}} fails to catch the creation of the pod (e.g. websocket connection was reset, k8s-apiserver was down, etc.)
 * {{ExecutorPodsPollingSnapshotSource}} fails to catch the creation because it runs every 30 secs, but executor was removed much quicker after creation
 * exec-1 is never removed from {{schedulerKnownNewlyCreatedExecs}}
 * {{ExecutorPodsAllocator}} will never request new executor because it’s slot is occupied by exec-1, due to {{schedulerKnownNewlyCreatedExecs}} never being cleared.

 

Put up a fix here https://github.com/apache/spark/pull/42297
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 01:56.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jhmo:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Add ProducedRowCount to SparkListenerConnectOperationFinished
Issue key: SPARK-44776
Issue id: 13546987
Parent id: 
Issue Type: Task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: lingkai2
Reporter: lingkai2
Creator: lingkai2
Created: 8/11/23 14:58
Updated: 5/7/24 4:24
Last Viewed: 7/17/24 20:45
Resolved: 8/22/23 1:07
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0, 4.0.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: pull-request-available
Description: As title
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): SPARK-48163
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Aug 22 01:07:12 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jqj4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 22/Aug/23 01:07;gurwls223;Issue resolved by pull request 42454
[https://github.com/apache/spark/pull/42454];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: TableChange.updateColumnComment does not remove comment entry
Issue key: SPARK-48130
Issue id: 13578168
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: pgrandjean
Creator: pgrandjean
Created: 5/4/24 21:52
Updated: 5/4/24 22:01
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: The function {{TableChange.updateColumnComment}} can be used to add a comment to a column, change it, but not remove the comment entry from the column's metadata.

Moreover, trying to update the column with value {{null}} risks raising a NPE if the function {{TableChange.UpdateColumnComment.equals}} is called.

Examples in Scala:
{code:scala}
TableChange.updateColumnComment(Array("foo"), "foo comment") // adds or changes comment => OK
TableChange.updateColumnComment(Array("foo"), "") // adds or changes comment to empty string, instead of removing comment from metadata => KO
TableChange.updateColumnComment(Array("foo"), null) // adds or changes comment to null, instead of removing comment from metadata => KO
TableChange.updateColumnComment(Array("foo"), "foo comment") == TableChange.updateColumnComment(Array("foo"), null) // raises an NPE => KO
{code}

Solution would be to accept empty string or null as values that remove the {{"comment"}} entry from the metadata, or create a new case {{TableChange.RemoveColumnComment}}.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 52:16.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1p17k:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: DataFrameWriterV2.overwrite fails with invalid plan
Issue key: SPARK-47828
Issue id: 13575589
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: podongfeng
Reporter: podongfeng
Creator: podongfeng
Created: 4/12/24 3:43
Updated: 4/19/24 15:24
Last Viewed: 7/17/24 20:45
Resolved: 4/15/24 4:21
Affects Version/s: 3.4.0, 3.4.1, 3.4.2, 3.4.3, 3.5.1, 4.0.0
Fix Version/s: 3.4.4, 3.5.2, 4.0.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Apr 15 04:21:26 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1oldc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 15/Apr/24 04:21;podongfeng;Issue resolved by pull request 46023
[https://github.com/apache/spark/pull/46023];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.4.2
Affects Version/s.3: 3.4.3
Affects Version/s.4: 3.5.1
Comment.1:

Summary: Enable Process Isolation for streaming python worker
Issue key: SPARK-44461
Issue id: 13543836
Parent id: 
Issue Type: Task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: 
Reporter: rangadi
Creator: rangadi
Created: 7/17/23 19:18
Updated: 4/18/24 23:53
Last Viewed: 7/17/24 20:45
Resolved: 1/23/24 10:30
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Connect, Structured Streaming
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Enable PI for Python worker used for foreachBatch() & streaming listener in Connect.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): SPARK-42938
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Aug 11 23:50:16 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j73k:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 10/Aug/23 03:08;gurwls223;Issue resolved by pull request 42421
[https://github.com/apache/spark/pull/42421];;;, 10/Aug/23 03:55;rangadi;[~gurwls223] could you reopen this? This is about Process isolation for python processes and mistakenly used for another PR. ;;;, 11/Aug/23 03:38;snoot;User 'WweiL' has created a pull request for this issue:
https://github.com/apache/spark/pull/42443;;;, 11/Aug/23 23:50;gurwls223;[~rangadi] can we switch the JIRA by switching the description and title?;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 10/Aug/23 03:55;rangadi;[~gurwls223] could you reopen this? This is about Process isolation for python processes and mistakenly used for another PR. ;;;

Summary: Connect generated proots can't be pickled
Issue key: SPARK-47862
Issue id: 13575934
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: grundprinzip-db
Reporter: grundprinzip-db
Creator: grundprinzip-db
Created: 4/15/24 21:14
Updated: 4/16/24 4:10
Last Viewed: 7/17/24 20:45
Resolved: 4/16/24 4:10
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: pull-request-available
Description: When Spark Connect generates the protobuf files, they're manually adjusted and moved to the right folder. However, we did not fix the package for the descriptor. This breaks serializing them to proto.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Apr 16 04:10:06 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1oni0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 16/Apr/24 04:10;gurwls223;Issue resolved by pull request 46068
[https://github.com/apache/spark/pull/46068];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: [PYTHON] Avoid shadowing python built-ins in python function variable naming
Issue key: SPARK-47854
Issue id: 13575815
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: liucao
Creator: liucao
Created: 4/15/24 7:25
Updated: 4/15/24 7:29
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.3.4, 3.4.1, 3.5.0, 3.5.1
Fix Version/s: 
Component/s: PySpark
Due Date: 
Votes: 0
Labels: 
Description: Given that spark 4.0.0 is upcoming I wonder if we should at least consider renaming certain function variable naming in python. Otherwise, we may need to wait another 4 years to do so.

Example

[https://github.com/apache/spark/blob/e6b7950f553cff5adc02b8b5195e79cffff3c97c/python/pyspark/sql/functions/builtin.py#L12768]

There are 8 uses of `len` and 35 `str` as variable names, both of which are python built-ins. Shadowing `str` is somewhat dangerous in that the following would be nonsensical:
{code:java}
def foo(str: "ColumnOrName", bar: "ColumnOrName"):
    # str is variable now, cannot be used as type
    bar = if lit(bar) if isinstance(bar, str) else bar
{code}
 

Now obviously this would be breaking change for user code if the function is called with kwargs style. If we rename `str` to `src` or `col`, certain old code using kwargs would break:
{code:java}
# breaks:
foo(str="x", bar="y")

# okay:
foo("x", bar="y"){code}
Is this change a possibility for 4.0? Or are we thinking that the kwargs breaking change is too big to make compared to the benefit?

 

 

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): pyspark, python, Python
Custom field (Last public comment date): 25:26.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1omrk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 3.5.1
Affects Version/s.4: 
Comment.1:

Summary: jdbc connect to duckdb with error Unrecognized configuration property "path"
Issue key: SPARK-47853
Issue id: 13575808
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: ZhaoWeiNan
Creator: ZhaoWeiNan
Created: 4/15/24 7:03
Updated: 4/15/24 7:07
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.0, 3.4.1, 3.5.0, 3.5.1
Fix Version/s: 
Component/s: Spark Core, SQL
Due Date: 
Votes: 0
Labels: 
Description: Link issue: _[https://github.com/duckdb/duckdb/issues/11651_]
 # reproduce python code 

```python

from pyspark.sql import SparkSession

if {_}{{_}}name{{_}}{_} == '{_}{{_}}main{{_}}{_}':
    spark = SparkSession.builder \
        .appName("Example Application") \
        .config("spark.master", "local") \
        .config("spark.jars.packages",
                "io.delta:delta-core_2.12:2.4.0,org.xerial:sqlite-jdbc:3.45.2.0,org.duckdb:duckdb_jdbc:0.9.2") \
        .getOrCreate()

    spark.sql(
        f"""
            create table default.movies  
            using jdbc
            options (url "jdbc:duckdb:database/duckdb.db" , driver "org.duckdb.DuckDBDriver" , dbtable "duckdb.main.test");
            """
    )

    spark.sql("select * from default.movies").show()

    spark.stop()

```

2. error log

```

16:28:57    Runtime Error in model movies (models/sources/movies.sql)
  An error occurred while calling o40.sql.
  : java.sql.SQLException: Invalid Input Error: Unrecognized configuration property "path"
        at org.duckdb.DuckDBNative.duckdb_jdbc_startup(Native Method)
        at org.duckdb.DuckDBConnection.newConnection(DuckDBConnection.java:48)
        at org.duckdb.DuckDBDriver.connect(DuckDBDriver.java:41)
        at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
    ```

3.  relative spark code

[https://github.com/apache/spark/blob/e6b7950f553cff5adc02b8b5195e79cffff3c97c/sql/core/src/main/scala/org/apache/spark/sql/execution/command/createDataSourceTables.scala#L64]

Why do we need to replicate the `path` into the JDBC connection?

 

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 03:23.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1omq0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 3.5.1
Affects Version/s.4: 
Comment.1:

Summary: pyspark.pandas read_excel implementation at version 3.4.1
Issue key: SPARK-46143
Issue id: 13559770
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: mpavanetti
Creator: mpavanetti
Created: 11/28/23 20:19
Updated: 4/8/24 6:56
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Build
Due Date: 
Votes: 2
Labels: 
Description: Hello, 

I would like to report an issue with pyspark.pandas implementation on read_excel function.

Microsoft Fabric spark environment 1.2 (runtime) uses pyspark 3.4.1 which potentially uses an older version of pandas on it's implementations of pyspark.pandas.

The function read_excel from pandas doesn't expect a parameter called "squeeze" however it's implemented as part of pyspark.pandas and the parameter "squeeze" is being passed to the pandas function.

 

!image-2023-11-28-13-20-40-275.png!

 

I've been digging into it for further investigation into pyspark 3.4.1 documentation

[https://spark.apache.org/docs/3.4.1/api/python/_modules/pyspark/pandas/namespace.html#read_excel|https://mcas-proxyweb.mcas.ms/certificate-checker?login=false&originalUrl=https%3A%2F%2Fspark.apache.org.mcas.ms%2Fdocs%2F3.4.1%2Fapi%2Fpython%2F_modules%2Fpyspark%2Fpandas%2Fnamespace.html%3FMcasTsid%3D20893%23read_excel&McasCSRF=92c0f0a0811f59386edd92fd5f3fcb0ac451ce363b3f2e01ed076f45e2b20500]

 

This is the point I found that "squeeze" parameter is being passed to pandas read_excel function which is not expected.

It seems like it was deprecated as part of pyspark 3.4.0 but still being used in the implementation.

 

!image-2023-11-28-13-20-51-291.png!

 

I believe this is an issue with pyspark implementation 3.4.1 not necessaily with fabric. However fabric uses this version as its 1.2 build.

 

I am able to work around that for now by download the excel from the one lake to the spark driver, loading that to the memory with pandas and then converting to a spark dataframe etc or I made it work downgrading the build

I downloaded the pyspark build 20230713 to my local, made the changes and re-compiled it and it worked locally. So it means that is related to the implementation and they would have to fix or I do a downgrade to older version like 3.3.3 or try the latest 3.5.0 which is not the case for fabric

 

 
Environment: pyspark 3.4.1.5.3 build 20230713.

Running on Microsoft Fabric workspace at runtime 1.2.

Tested the same scenario on a spark 3.4.1 standalone deployment on docker documented at https://github.com/mpavanetti/sparkenv

 

 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 28/Nov/23 20:20;mpavanetti;MicrosoftTeams-image.png;https://issues.apache.org/jira/secure/attachment/13064781/MicrosoftTeams-image.png, 28/Nov/23 20:20;mpavanetti;image-2023-11-28-13-20-40-275.png;https://issues.apache.org/jira/secure/attachment/13064782/image-2023-11-28-13-20-40-275.png, 28/Nov/23 20:20;mpavanetti;image-2023-11-28-13-20-51-291.png;https://issues.apache.org/jira/secure/attachment/13064783/image-2023-11-28-13-20-51-291.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 3
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): Patch
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Apr 08 06:56:06 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lwo0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 3.3.3
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 29/Nov/23 15:59;mpavanetti;Tested the same scenario on a spark 3.4.1 standalone deployment on docker documented at [https://github.com/mpavanetti/sparkenv]

Got the same error.;;;, 05/Apr/24 13:38;ckarras-ext-exo;I have the same issue too. The problem is because the squeeze parameter of read_excel has been deprecated since pandas version 1.4, and has been completely removed in pandas 2.0. But Pyspark's implementation of read_excel keeps passing the squeeze parameter, even though the parameter is also deprecated since pyspark 3.4.

Since there's no version constraint in Pyspark that indicates Pandas 2.0 is not supported, a fix to avoid the need to stay with pandas 1.x could be to detect the pandas version and decide if the squeeze parameter should be passed depending on the pandas version. Also, if the squeeze parameter is passed in the Pyspark function, raise an error if a version of pandas that no longer supports this parameter is installed. This would be a transition solution until the squeeze parameter is also removed completely from Pyspark.

 

Modify pyspark\pandas\namespace.py:
 * Change the squeeze parameter of the read_excel function to be "squeeze: Optional[bool] = None"
 * Modify the nested pd_read_excel function to check for the pandas version and build a dict of arguments it will pass to pd.read_excel based on that version. Also consider if the squeeze parameter was passed by the caller or not. And if the caller specified that argument but a newer version of pandas that doesn't support it, raise an exception

 

Sample code that could implement this solution:
def pd_read_excel(
    io_or_bin: Any,
    sn: Union[str, int, List[Union[str, int]], None], sq: bool   
) -> pd.DataFrame:

    read_excel_args: dict =

{         "io":BytesIO(io_or_bin) if isinstance(io_or_bin, (bytes, bytearray)) else io_or_bin,         "sheet_name":sn,         "header":header,         # TODO other args...,         **kwds     }

    if squeeze is not None:
        pandas_version_major = int(pd.__version__.split(".")[0])
        if pandas_version_major >= 2:
            raise Exception("The squeeze parameter for read_excel is no longer available in pandas 2.x")
       
        read_excel_args["squeeze"] = squeeze
    return pd.read_excel(**read_excel_args)
 ;;;, 08/Apr/24 06:56;comet;voted for this issue.;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 05/Apr/24 13:38;ckarras-ext-exo;I have the same issue too. The problem is because the squeeze parameter of read_excel has been deprecated since pandas version 1.4, and has been completely removed in pandas 2.0. But Pyspark's implementation of read_excel keeps passing the squeeze parameter, even though the parameter is also deprecated since pyspark 3.4.

Since there's no version constraint in Pyspark that indicates Pandas 2.0 is not supported, a fix to avoid the need to stay with pandas 1.x could be to detect the pandas version and decide if the squeeze parameter should be passed depending on the pandas version. Also, if the squeeze parameter is passed in the Pyspark function, raise an error if a version of pandas that no longer supports this parameter is installed. This would be a transition solution until the squeeze parameter is also removed completely from Pyspark.

 

Modify pyspark\pandas\namespace.py:
 * Change the squeeze parameter of the read_excel function to be "squeeze: Optional[bool] = None"
 * Modify the nested pd_read_excel function to check for the pandas version and build a dict of arguments it will pass to pd.read_excel based on that version. Also consider if the squeeze parameter was passed by the caller or not. And if the caller specified that argument but a newer version of pandas that doesn't support it, raise an exception

 

Sample code that could implement this solution:
def pd_read_excel(
    io_or_bin: Any,
    sn: Union[str, int, List[Union[str, int]], None], sq: bool   
) -> pd.DataFrame:

    read_excel_args: dict =

{         "io":BytesIO(io_or_bin) if isinstance(io_or_bin, (bytes, bytearray)) else io_or_bin,         "sheet_name":sn,         "header":header,         # TODO other args...,         **kwds     }

    if squeeze is not None:
        pandas_version_major = int(pd.__version__.split(".")[0])
        if pandas_version_major >= 2:
            raise Exception("The squeeze parameter for read_excel is no longer available in pandas 2.x")
       
        read_excel_args["squeeze"] = squeeze
    return pd.read_excel(**read_excel_args)
 ;;;

Summary: Support Hive tables as a streaming source and sink
Issue key: SPARK-47717
Issue id: 13574490
Parent id: 
Issue Type: New Feature
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: asuresh9
Creator: asuresh9
Created: 4/3/24 15:08
Updated: 4/3/24 15:08
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.3.2, 3.4.1, 3.5.1
Fix Version/s: 3.3.2, 3.4.1, 3.5.1
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: People have data stored in Hive tables. Currently these tables do not support Spark streaming, so customers do not have a good way to natively stream this data in Spark. The current solutions involve an intermediary to track which data has been read and periodically execute batch jobs. This use case should be supported by Spark's in-built streaming mechanism.

 

From doing some research, Hive supports streaming [https://cwiki.apache.org/confluence/display/Hive/Streaming+Data+Ingest+V2] but Spark does not support streaming on tables in Hive format. I don't think it makes sense to start copying Hive server-side code into Spark, but we could copy the relevant logic and wrap it in the DataSourceV2 APIs to enable this feature. To not break backwards compatibility, we would probably want to gate this behind a new Spark property.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 08:21.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1oezk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): asuresh9
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 3.3.2, 3.4.1, 3.5.1
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.1
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Fix NPE when reading mysql bit array as LongType
Issue key: SPARK-47666
Issue id: 13574118
Parent id: 13571633
Issue Type: Sub-task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: yao
Reporter: yao
Creator: yao
Created: 4/1/24 8:21
Updated: 4/2/24 12:49
Last Viewed: 7/17/24 20:45
Resolved: 4/1/24 10:28
Affects Version/s: 3.4.1, 3.5.1, 4.0.0
Fix Version/s: 3.4.3, 3.5.2, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Apr 01 10:29:00 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ocp4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 01/Apr/24 10:29;yao;resolved by https://github.com/apache/spark/pull/45790;;;
Affects Version/s.1: 3.5.1
Affects Version/s.2: 4.0.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Enforce Window partitionSpec is orderable.
Issue key: SPARK-47572
Issue id: 13573383
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: mashplant
Reporter: mashplant
Creator: mashplant
Created: 3/26/24 18:41
Updated: 3/29/24 8:19
Last Viewed: 7/17/24 20:45
Resolved: 3/29/24 8:19
Affects Version/s: 3.3.4, 3.4.1, 3.5.1
Fix Version/s: 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Mar 29 08:19:26 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1o86o:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 29/Mar/24 08:19;cloud_fan;Issue resolved by pull request 45730
[https://github.com/apache/spark/pull/45730];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.1
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: SPJ: Handle empty input partitions after dynamic filtering
Issue key: SPARK-45652
Issue id: 13555374
Parent id: 13412655
Issue Type: Sub-task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: csun
Reporter: csun
Creator: csun
Created: 10/24/23 16:14
Updated: 3/28/24 13:22
Last Viewed: 7/17/24 20:45
Resolved: 10/26/23 15:52
Affects Version/s: 3.4.1
Fix Version/s: 3.4.2, 3.5.1, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: When the number of input partitions become 0 after dynamic filtering, in {{BatchScanExec}}, currently SPJ will fail with error:
{code}
java.util.NoSuchElementException: None.get
	at scala.None$.get(Option.scala:529)
	at scala.None$.get(Option.scala:527)
	at org.apache.spark.sql.execution.datasources.v2.BatchScanExec.filteredPartitions$lzycompute(BatchScanExec.scala:108)
	at org.apache.spark.sql.execution.datasources.v2.BatchScanExec.filteredPartitions(BatchScanExec.scala:65)
	at org.apache.spark.sql.execution.datasources.v2.BatchScanExec.inputRDD$lzycompute(BatchScanExec.scala:136)
	at org.apache.spark.sql.execution.datasources.v2.BatchScanExec.inputRDD(BatchScanExec.scala:135)
{code}

This is because {{groupPartitions}} will return {{None}} for this case.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Oct 26 15:52:31 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1l5w0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 26/Oct/23 15:52;csun;Issue resolved by pull request 43531
[https://github.com/apache/spark/pull/43531];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Aggregate in not causes 
Issue key: SPARK-47287
Issue id: 13570844
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: tedjenks
Creator: tedjenks
Created: 3/5/24 13:58
Updated: 3/28/24 5:21
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description:  

The below snippet is confirmed working with Spark 3.2.1 and broken Spark 3.4.1. i believe this is a bug. 
{code:java}
       Dataset<Row> ds = dummyDataset
                .withColumn("flag", functions.not(functions.coalesce(functions.col("bool1"), functions.lit(false)).equalTo(true)))
                .groupBy("code")
                .agg(functions.max(functions.col("flag")).alias("flag"));
        ds.show(); {code}
It fails with:
{code:java}
Caused by: java.lang.AssertionError: assertion failed
	at scala.Predef$.assert(Predef.scala:208)
	at org.apache.spark.sql.catalyst.util.V2ExpressionBuilder.$anonfun$generateExpression$7(V2ExpressionBuilder.scala:185)
	at scala.Option.map(Option.scala:230)
	at org.apache.spark.sql.catalyst.util.V2ExpressionBuilder.generateExpression(V2ExpressionBuilder.scala:184)
	at org.apache.spark.sql.catalyst.util.V2ExpressionBuilder.build(V2ExpressionBuilder.scala:33)
	at org.apache.spark.sql.execution.datasources.PushableExpression$.unapply(DataSourceStrategy.scala:803)
	at org.apache.spark.sql.catalyst.util.V2ExpressionBuilder.generateAggregateFunc(V2ExpressionBuilder.scala:293)
	at org.apache.spark.sql.catalyst.util.V2ExpressionBuilder.generateExpression(V2ExpressionBuilder.scala:98)
	at org.apache.spark.sql.catalyst.util.V2ExpressionBuilder.build(V2ExpressionBuilder.scala:33)
	at org.apache.spark.sql.execution.datasources.PushableExpression$.unapply(DataSourceStrategy.scala:803)
	at org.apache.spark.sql.execution.datasources.DataSourceStrategy$.translate$1(DataSourceStrategy.scala:700){code}
 

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Mar 28 05:21:19 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1nsi0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 28/Mar/24 05:21;juefeiyan;I tried the code on 3.4 branch, cannot reproduce this problem;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Aggregate + First() Function - ArrayIndexOutOfBoundsException - ColumnPruning?
Issue key: SPARK-47615
Issue id: 13573499
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: schreiber
Creator: schreiber
Created: 3/27/24 9:36
Updated: 3/27/24 9:36
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 
Component/s: Optimizer
Due Date: 
Votes: 0
Labels: 
Description: Currently i`m investigating in upgrade our code base from spark 3.3.0 to 3.5.0 (embedded in dedicated aws emr cluster).
 
I got the following exception if i execute my code on the cluster, if i run local unit tests the code runs as expected without exception.
 
 
{code:java}
24/03/26 19:32:19 INFO RecordServerQueryListener: Cleaning up temp directory - /user/KKQI7VHKTMNQZJQNMMZXKH5KYNRPOHXG/application_1711468652551_0023 Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 4 times, most recent failure: Lost task 0.3 in stage 12.0 (TID 186) (ip-10-1-1-6.eu-central-1.compute.internal executor 2): java.lang.ArrayIndexOutOfBoundsException: Index -1 out of bounds for length 3 at org.apache.spark.sql.vectorized.ColumnarBatch.column(ColumnarBatch.java:95) at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnaraggregatetorow_parquetMax_0$(Unknown Source) at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnaraggregatetorow_nextBatch_0$(Unknown Source) at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithoutKey_0$(Unknown Source) at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source) at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:35) at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hasNext(Unknown Source) at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43) at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460) at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:142) at org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45) at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:68) at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104) at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54) at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) at org.apache.spark.scheduler.Task.run(Task.scala:143) at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:629) at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:95) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:632) at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) at java.base/java.lang.Thread.run(Thread.java:840)   Driver stacktrace: at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:3067) at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:3003) at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:3002) at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62) at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55) at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49) at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:3002) at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1318) at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1318) at scala.Option.foreach(Option.scala:407) at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1318) at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3271) at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3205) at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3194) at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49) at org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.checkNoFailures(AdaptiveExecutor.scala:154) at org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.doRun(AdaptiveExecutor.scala:88) at org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.tryRunningAndGetFuture(AdaptiveExecutor.scala:66) at org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.execute(AdaptiveExecutor.scala:57) at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$1(AdaptiveSparkPlanExec.scala:277) at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.getFinalPhysicalPlan(AdaptiveSparkPlanExec.scala:276) at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:558) at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:520) at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4411) at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3370) at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4401) at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:625) at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4399) at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:108) at org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:255) at org.apache.spark.sql.execution.SQLExecution$.executeQuery$1(SQLExecution.scala:129) at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$9(SQLExecution.scala:165) at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:108) at org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:255) at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$8(SQLExecution.scala:165) at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:276) at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:164) at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:70) at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4399) at org.apache.spark.sql.Dataset.head(Dataset.scala:3370) at org.apache.spark.sql.Dataset.head(Dataset.scala:3377) at org.apache.spark.sql.Dataset.first(Dataset.scala:3384) at de.my.maintained.code.business.transformer.MyMaintainedClass$BusinessForecastNonRecurringTransformer.determineMaxDateId(MyMaintainedClass.scala:56) at de.my.maintained.code.business.transformer.MyMaintainedClass$BusinessForecastNonRecurringTransformer.processInternal(MyMaintainedClass.scala:25) at de.my.maintained.code.business.transformer.MyMaintainedClass$BusinessForecastNonRecurringTransformer.processInternal$(MyMaintainedClass.scala:22) at de.my.maintained.code.common.app.FqmApp$$anon$35.processInternal(FqmApp.scala:112) at de.my.maintained.code.common.transformer.Transformer.process(Transformer.scala:26) at de.my.maintained.code.common.transformer.Transformer.process$(Transformer.scala:24) at de.my.maintained.code.common.app.FqmApp$$anon$35.process(FqmApp.scala:112) at de.my.maintained.code.business.transformer.BusinessForecastTransformerComponent$BusinessForecastTransformer.processInternal(BusinessForecastTransformerComponent.scala:35) at de.my.maintained.code.business.transformer.BusinessForecastTransformerComponent$BusinessForecastTransformer.processInternal$(BusinessForecastTransformerComponent.scala:26) at de.my.maintained.code.common.app.FqmApp$$anon$33.processInternal(FqmApp.scala:110) at de.my.maintained.code.common.transformer.Transformer.process(Transformer.scala:26) at de.my.maintained.code.common.transformer.Transformer.process$(Transformer.scala:24) at de.my.maintained.code.common.app.FqmApp$$anon$33.process(FqmApp.scala:110) at de.my.maintained.code.business.aws.BusinessStage2Forecast$.main(BusinessStage2Forecast.scala:10) at de.my.maintained.code.business.aws.BusinessStage2Forecast.main(BusinessStage2Forecast.scala) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:568) at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52) at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1075) at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194) at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217) at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91) at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1167) at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1176) at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala) Caused by: java.lang.ArrayIndexOutOfBoundsException: Index -1 out of bounds for length 3 at org.apache.spark.sql.vectorized.ColumnarBatch.column(ColumnarBatch.java:95) at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnaraggregatetorow_parquetMax_0$(Unknown Source) at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnaraggregatetorow_nextBatch_0$(Unknown Source) at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hashAgg_doAggregateWithoutKey_0$(Unknown Source) at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source) at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:35) at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.hasNext(Unknown Source) at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43) at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460) at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:142) at org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45) at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:68) at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104) at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54) at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161) at org.apache.spark.scheduler.Task.run(Task.scala:143) at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:629) at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64) at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:95) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:632) at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) at java.base/java.lang.Thread.run(Thread.java:840){code}
 
 
A little earlier in logfile i found the following:
 
24/03/26 19:32:18 INFO DAGScheduler: Submitting 16 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[28] at first at MyMaintainedClass.scala:56) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
 
 
if i jump to the code i found this:
 
 
{code:java}
52: val first_row =
53:  df_usage_current_and_next_month
54:   .filter(args.billingDate.filter_current_month($"year", $"month"))
55:   .withColumn("DATE_ID", $"year" * 10000 + $"month" * 100 + date_format(dateColumn, "dd").cast(IntegerType))
56:   .agg(max("DATE_ID")).first()  {code}
 
The Problem seems to be occur in the last row ".agg(max("DATE_ID")).first()"
 
So next i have identified all placed with this exception. All of them use aggregation (min/max/count) with the call of first() after that.
 
After that i searched all code placed with the first() or head() function in our code base and i found one example without occuring an ArrayIndexOutOfBoundException. The StackOverFlow (link at the bottom), post gave me an hint. Every time we do an spark.read (parquet) with an aggregation and calling first function AND using the same DataFrame after that for other calculations & filterings & writing we got an ArrayIndexOutOfBounds Exception. If we still only do agg and first there is no problem.
 
So there must be something mutable while reading the DataSource and split the executing plan into two ways. (don`t know what there happen exactly). In my opinion, an optimization mechanism intervenes there, which removes certain columns that are supposedly not needed but needed. Unfortunately i`m not able to reproduce it locally, only in AWS EMR Cluster. (maybe there is a different Configuration)
 
Workaround not getting the ArrayIndexOutOfBoundException
 
1. using an explicit spark.read for every agg an first function
OR
2. using an persist() between agg and first function
 
 
#similar problem mentioned on stackoverflow
https://stackoverflow.com/questions/53483406/spark-sql-dataframe-count-gives-java-lang-arrayindexoutofboundsexception
 
 
Versions Tested:
 
Spark
3.3.0 (no problem) (emr 6.11.1)
3.4.1 (ArrayIndexOutOfBoundsException) (emr 6.15.1)
3.5.0 (ArrayIndexOutOfBoundsException) (emr 7.0.0)
 
Environment: Amazon EMR version
emr-7.0.0
Installed applications
Tez 0.10.2, Spark 3.5.0
Amazon Linux release
2023.3.20240312.0
 
1 Master Node m6g.xlarge
2 Core Nodes m6g.2xlarge
 
 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): scala
Custom field (Last public comment date): 36:08.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1o8wg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Issue with Spark Connect on Python 3.12
Issue key: SPARK-47613
Issue id: 13573479
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: KaiRoesner
Creator: KaiRoesner
Created: 3/27/24 7:19
Updated: 3/27/24 7:19
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 
Component/s: PySpark
Due Date: 
Votes: 0
Labels: 
Description: When trying to create a remote Spark session with PySpark on Python 3.12 a {{ModuleNotFoundError: No module named 'distutils'}} excpetion is thrown. In Python 3.12 {{distutils}} was removed from the stdlib. As a workaround we can {{import setuptools}} before creating the session. See also [this question on SOF|https://stackoverflow.com/questions/78207291] and the [answer|https://stackoverflow.com/a/78212125/11474852] by Anderson Bravalheri.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 19:20.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1o8s0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Use MySQL Connector/J for MySQL DB instead of MariaDB Connector/J 
Issue key: SPARK-47537
Issue id: 13573146
Parent id: 13571633
Issue Type: Sub-task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: yao
Reporter: yao
Creator: yao
Created: 3/25/24 3:37
Updated: 3/25/24 15:52
Last Viewed: 7/17/24 20:45
Resolved: 3/25/24 6:05
Affects Version/s: 3.4.1, 3.5.1, 4.0.0
Fix Version/s: 3.4.3, 3.5.2, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Mar 25 06:05:00 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1o6q0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 25/Mar/24 06:05;dongjoon;Issue resolved by pull request 45689
[https://github.com/apache/spark/pull/45689];;;
Affects Version/s.1: 3.5.1
Affects Version/s.2: 4.0.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Use `Utils.tryWithResource` during reading shuffle data from external storage
Issue key: SPARK-47521
Issue id: 13572928
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: maheshk114
Reporter: maheshk114
Creator: maheshk114
Created: 3/22/24 9:23
Updated: 3/23/24 5:53
Last Viewed: 7/17/24 20:45
Resolved: 3/22/24 17:45
Affects Version/s: 3.3.4, 3.4.1, 3.5.0
Fix Version/s: 3.4.3, 3.5.2, 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: In method FallbackStorage.read method, the file handle is not closed if there is a failure during read operation.

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Mar 22 17:52:24 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1o5dk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): dongjoon
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 22/Mar/24 17:45;dongjoon;Issue resolved by pull request 45663
[https://github.com/apache/spark/pull/45663];;;, 22/Mar/24 17:52;dongjoon;FYI, [~maheshk114], `Target Version` field is reserved for the Apache Spark committers. So, please don't set it with your aspiration.
- https://spark.apache.org/contributing.html

{quote}
Do not set the following fields:
Fix Version. This is assigned by committers only when resolved.
Target Version. This is assigned by committers to indicate a PR has been accepted for possible fix by the target version.
{quote};;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 22/Mar/24 17:52;dongjoon;FYI, [~maheshk114], `Target Version` field is reserved for the Apache Spark committers. So, please don't set it with your aspiration.
- https://spark.apache.org/contributing.html

{quote}
Do not set the following fields:
Fix Version. This is assigned by committers only when resolved.
Target Version. This is assigned by committers to indicate a PR has been accepted for possible fix by the target version.
{quote};;;

Summary: Task fraction resource request is not expected
Issue key: SPARK-45527
Issue id: 13553942
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: wbo4958
Reporter: Ngone51
Creator: Ngone51
Created: 10/13/23 1:56
Updated: 3/19/24 13:50
Last Viewed: 7/17/24 20:45
Resolved: 1/4/24 15:21
Affects Version/s: 3.2.1, 3.3.3, 3.4.1, 3.5.0
Fix Version/s: 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description:  
{code:java}
test("SPARK-XXX") {
  import org.apache.spark.resource.{ResourceProfileBuilder, TaskResourceRequests}

  withTempDir { dir =>
    val scriptPath = createTempScriptWithExpectedOutput(dir, "gpuDiscoveryScript",
      """{"name": "gpu","addresses":["0"]}""")

    val conf = new SparkConf()
      .setAppName("test")
      .setMaster("local-cluster[1, 12, 1024]")
      .set("spark.executor.cores", "12")
    conf.set(TASK_GPU_ID.amountConf, "0.08")
    conf.set(WORKER_GPU_ID.amountConf, "1")
    conf.set(WORKER_GPU_ID.discoveryScriptConf, scriptPath)
    conf.set(EXECUTOR_GPU_ID.amountConf, "1")
    sc = new SparkContext(conf)
    val rdd = sc.range(0, 100, 1, 4)
    var rdd1 = rdd.repartition(3)
    val treqs = new TaskResourceRequests().cpus(1).resource("gpu", 1.0)
    val rp = new ResourceProfileBuilder().require(treqs).build
    rdd1 = rdd1.withResources(rp)
    assert(rdd1.collect().size === 100)
  }
} {code}
In the above test, the 3 tasks generated by rdd1 are expected to be executed in sequence as we expect "new TaskResourceRequests().cpus(1).resource("gpu", 1.0)" should override "conf.set(TASK_GPU_ID.amountConf, "0.08")". However, those 3 tasks are run in parallel in fact.

The root cause is that ExecutorData#ExecutorResourceInfo#numParts is static. In this case, the "gpu.numParts" is initialized with 12 (1/0.08) and won't change even if there's a new task resource request (e.g., resource("gpu", 1.0) in this case). Thus, those 3 tasks are able to be executed in parallel.
 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): SPARK-47458
Outward issue link (Reference): 
Inward issue link (Regression): SPARK-39853
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Feb 27 14:55:15 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kx1s:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 13/Oct/23 01:58;Ngone51;cc [~wbo4958]   [~tgraves] ;;;, 13/Oct/23 15:30;tgraves;thanks for filing and digging into this. I assume this is only with the TaskResourceRequests and using the default ExecutorResourceRequests.  seems a bug since that functionality was added.  Either way when we fix should add tests similar if we can.;;;, 16/Oct/23 23:16;wbo4958;Working on a PR to fix it.;;;, 27/Feb/24 14:55;tgraves;Note that this is related to SPARK-39853 which was supposed to implement stage level scheduling with dynamic allocation disabled.  That pr did not properly handle resources (gpu, fpga, etc);;;
Affects Version/s.1: 3.3.3
Affects Version/s.2: 3.4.1
Affects Version/s.3: 3.5.0
Affects Version/s.4: 
Comment.1: 13/Oct/23 15:30;tgraves;thanks for filing and digging into this. I assume this is only with the TaskResourceRequests and using the default ExecutorResourceRequests.  seems a bug since that functionality was added.  Either way when we fix should add tests similar if we can.;;;

Summary: Preserve full principal user name on executor side
Issue key: SPARK-44976
Issue id: 13548705
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: eub
Creator: eub
Created: 8/26/23 2:55
Updated: 3/19/24 0:18
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.2.3, 3.3.3, 3.4.1
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: SPARK-6558 changes the behavior of {{Utils.getCurrentUserName()}} to use shortname instead of full principal name.
Due to this, it doesn't respect {{hadoop.security.auth_to_local}} rule on the side of non-kerberized hdfs namenode.
For example, I use 2 hdfs cluster. One is kerberized, the other one is not kerberized.
I make a rule to add some prefix to username on the non-kerberized cluster if some one access it from the kerberized cluster.


{code}
  <property>
    <name>hadoop.security.auth_to_local</name>
    <value xml:space="preserve">
RULE:[1:$1@$0](.*@EXAMPLE.COM)s/(.+)@.*/_ex_$1/
RULE:[2:$1@$0](.*@EXAMPLE.COM)s/(.+)@.*/_ex_$1/
DEFAULT</value>
  </property>
{code}

However, if I submit spark job with keytab & principal option, hdfs directory and files ownership is not coherent.

(I change some words for privacy.)

{code}
$ hdfs dfs -ls hdfs:///user/eub/some/path/20230510/23
Found 52 items
-rw-rw-rw-   3 _ex_eub hdfs          0 2023-05-11 00:16 hdfs:///user/eub/some/path/20230510/23/_SUCCESS
-rw-r--r--   3 eub      hdfs  134418857 2023-05-11 00:15 hdfs:///user/eub/some/path/20230510/23/part-00000-b781be38-9dbc-41da-8d0e-597a7f343649-c000.txt.gz
-rw-r--r--   3 eub      hdfs  153410049 2023-05-11 00:16 hdfs:///user/eub/some/path/20230510/23/part-00001-b781be38-9dbc-41da-8d0e-597a7f343649-c000.txt.gz
-rw-r--r--   3 eub      hdfs  157260989 2023-05-11 00:16 hdfs:///user/eub/some/path/20230510/23/part-00002-b781be38-9dbc-41da-8d0e-597a7f343649-c000.txt.gz
-rw-r--r--   3 eub      hdfs  156222760 2023-05-11 00:16 hdfs:///user/eub/some/path/20230510/23/part-00003-b781be38-9dbc-41da-8d0e-597a7f343649-c000.txt.gz
{code}

Another interesting point is that if I submit spark job without keytab and principal option but with kerberos authentication with {{kinit}}, it will not follow {{hadoop.security.auth_to_local}} rule completely.

{code}
$ hdfs dfs -ls  hdfs:///user/eub/output/
Found 3 items
-rw-rw-r--+  3 eub hdfs          0 2023-08-25 12:31 hdfs:///user/eub/output/_SUCCESS
-rw-rw-r--+  3 eub hdfs        512 2023-08-25 12:31 hdfs:///user/eub/output/part-00000.gz
-rw-rw-r--+  3 eub hdfs        574 2023-08-25 12:31 hdfs:///user/eub/output/part-00001.gz
{code}


I finally found that if I submit spark job with {{--principal}} and {{--keytab}} option, ugi will be different.
(refer to https://github.com/apache/spark/blob/2583bd2c16a335747895c0843f438d0966f47ecd/resource-managers/yarn/src/main/scala/org/apache/spark/deploy/yarn/ApplicationMaster.scala#L905).

Only file ({{_SUCCESS}}) and output directory created by driver (application master side) will respect {{hadoop.security.auth_to_local}} on the non-kerberized namenode only if {{--principal}} and {{--keytab}] options are provided.

No matter how hdfs files or directory are created by executor or driver, those should respect {{hadoop.security.auth_to_local}} rule and should be the same.


Workaround is to pass additional argument to change {{SPARK_USER}} on the executor side.
e.g. {{--conf spark.executorEnv.SPARK_USER=_ex_eub}}

{{--conf spark.yarn.appMasterEnv.SPARK_USER=_ex_eub}} will make an error. There are some logics to append environment value with {{:}} (colon) as a separator.

- https://github.com/apache/spark/blob/4748d858b4478ea7503b792050d4735eae83b3cd/resource-managers/yarn/src/main/scala/org/apache/spark/deploy/yarn/Client.scala#L893
- https://github.com/apache/spark/blob/4748d858b4478ea7503b792050d4735eae83b3cd/resource-managers/yarn/src/main/scala/org/apache/spark/deploy/yarn/YarnSparkHadoopUtil.scala#L52

Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sat Aug 26 14:25:40 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k0rk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 26/Aug/23 04:54;eub;[https://github.com/apache/spark/pull/44244];;;, 26/Aug/23 14:25;eub;I think it is also related to https://issues.apache.org/jira/browse/SPARK-31551.;;;
Affects Version/s.1: 3.3.3
Affects Version/s.2: 3.4.1
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 26/Aug/23 14:25;eub;I think it is also related to https://issues.apache.org/jira/browse/SPARK-31551.;;;

Summary: Bloom filter is not added for left outer join if the left side table is smaller than broadcast threshold.
Issue key: SPARK-44307
Issue id: 13542476
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: maheshk114
Creator: maheshk114
Created: 7/5/23 5:11
Updated: 3/17/24 0:20
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Optimizer
Due Date: 
Votes: 0
Labels: pull-request-available
Description: In case of left outer join, even if the left side table is small enough to be broadcasted, shuffle join is used. This is because of the property of the left outer join. If the left side is broadcasted in left outer join, the result generated will be wrong. But this is not taken care of in bloom filter. While injecting the bloom filter, if lest side is smaller than broadcast threshold, bloom filter is not added. It assumes that the left side will be broadcast and there is no need for a bloom filter. This causes bloom filter optimization to be missed in case of left outer join with small left side and huge right-side table.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Jul 06 11:50:31 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1iyqw:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 06/Jul/23 11:50;awsthni;User 'maheshk114' has created a pull request for this issue:
https://github.com/apache/spark/pull/41860;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: spark-sql does not recognize expressions in repartition hint
Issue key: SPARK-47425
Issue id: 13572101
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Resolved
Assignee: 
Reporter: mrbrahman
Creator: mrbrahman
Created: 3/15/24 21:02
Updated: 3/16/24 1:36
Last Viewed: 7/17/24 20:45
Resolved: 3/16/24 1:36
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: In Scala, it is possible to do this, to create a bucketed table to not have many small files.

 
{code:scala}
df.repartition(expr("pmod(hash(user_id), 200)"))
  .write
  .mode(SaveMode.Overwrite)
  .bucketBy(200, "user_id")
  .option("path", output_path)
  .saveAsTable("bucketed_table")
{code}
Found [this small trick|https://towardsdatascience.com/best-practices-for-bucketing-in-spark-sql-ea9f23f7dd53] to have the same # files as buckets.

However, the equivalent does not work in spark-sql (using repartition hint)
{code:sql}
create table bucketed_table stored as parquet
clustered by (user_id) into 200 buckets
select /*+ repartition (pmod(hash(user_id),200)) */ * from df_table
{code}
{{REPARTITION Hint parameter should include columns, but 'pmod('hash('user_id), 200) found.}}

When I instead make a virtual column and use that, Spark is not respecting the repartition anymore
{code:sql}
create table bucketed_table stored as parquet
clustered by (user_id) into 200 buckets
select /*+ repartition (bkt) */
*, pmod(hash(user_id),200) as bkt
from df_table
{code}
{code:bash}
$ hdfs dfs -ls -h /user/spark/warehouse/bucket_test.db/bucketed_table| head
Found 101601 items
...
{code}

The same behavior is seen even with DISTRIBUTE BY clause

{code:sql}
create table bucketed_table stored as parquet
clustered by (user_id) into 200 buckets
select *
from df_table
distribute by pmod(hash(user_id),200)
{code}

Can the behavior of repartition hint be changed to work like the Scala/Python equivalent?

Thank you
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sat Mar 16 01:36:56 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1o09s:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 16/Mar/24 01:36;mrbrahman;Nevermind, the problem was in storage specification. I was using the Hive storage clause, while this needed the Spark storage clause.

The below works!
{code:sql}
create table bucketed_table USING parquet
clustered by (user_id) into 200 buckets
select *
from df_table
distribute by pmod(hash(user_id),200) 
{code}

Simple and clean solution without the need for an extra column for the repartition hint.;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Spark 3.3.3 tuple encoders built using Encoders.tuple do not correctly cast null into None for Option values
Issue key: SPARK-46251
Issue id: 13560552
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: willbo
Creator: willbo
Created: 12/4/23 22:28
Updated: 3/14/24 5:40
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.3.3, 3.4.0, 3.4.1, 3.4.2, 3.5.0
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: In Spark {{3.3.2}} encoders created using {{Encoders.tuple(encoder1, encoder2, ..)}} correctly handle casting {{null}} into {{None}} when the target type is an Option. 

In Spark {{{}3.3.3{}}}, this behaviour has changed and the Option value comes through as {{null}} which is likely to cause a {{NullPointerException}} for most Scala code that operates on the Option. The change seems to be related to the following commit:

[https://github.com/apache/spark/commit/9110c05d54c392e55693eba4509be37c571d610a]

I have made a reproduction with a couple of examples in a public Github repo here:

[https://github.com/q-willboulter/spark-tuple-encoders-bug] 

The common use case where this is likely to be encountered is while doing any joins that can return null, e.g. left or outer joins. When casting the result of a left join it is sensible to wrap the right-hand side in an Option to handle the case where there is no match. Since 3.3.3 this would fail if the encoder is derived manually using {{Encoders.tuple(leftEncoder, rightEncoder).}}

If the entire tuple encoder {{Encoder[(Left, Option[Right]])}} is derived at once using reflection, the encoder works as expected. The bug appears to be in the following function inside {{ExpressionEncoder.scala}}
{code:java}
def tuple(encoders: Seq[ExpressionEncoder[_]]): ExpressionEncoder[_] = ...{code}
 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): SPARK-47385
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Mar 14 05:34:27 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1m1hs:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 14/Mar/24 05:34;joshrosen;FYI, this looks like it was duplicated by https://issues.apache.org/jira/browse/SPARK-47385 which now has a PR open to fix it.;;;
Affects Version/s.1: 3.4.0
Affects Version/s.2: 3.4.1
Affects Version/s.3: 3.4.2
Affects Version/s.4: 3.5.0
Comment.1:

Summary: Fix performance regression in JDK 17 caused from RocksDB logging
Issue key: SPARK-47369
Issue id: 13571674
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: neilramaswamy
Creator: neilramaswamy
Created: 3/12/24 21:04
Updated: 3/13/24 17:48
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.3.0, 3.3.1, 3.3.2, 3.3.3, 3.3.4, 3.4.0, 3.4.1, 3.4.2, 3.5.0, 3.5.1
Fix Version/s: 
Component/s: Structured Streaming
Due Date: 
Votes: 0
Labels: 
Description: JDK 17 has a performance regression in the JNI's AttachCurrentThread and DetachCurrentThread calls, as reported here: [https://bugs.openjdk.org/browse/JDK-8314859]. You can find a minimal reproduction of the JDK issue in that bug report. I have marked as affected versions 3.3.0^ since that is when JDK 17 started being offered in Spark.

For context, every time RocksDB logs, it currently [attaches itself to the JVM|https://github.com/facebook/rocksdb/blob/main/java/rocksjni/loggerjnicallback.cc#L140], invokes the RocksDB [logging callback that we specify|https://github.com/apache/spark/blob/8fcef1657a02189f91d5485eabb5b165706cdce9/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/state/RocksDB.scala#L839], and then [detaches itself from the JVM|https://github.com/facebook/rocksdb/blob/main/java/rocksjni/loggerjnicallback.cc#L170]. These attach/detach calls regressed, causing JDK 17 SS queries to run up to 10-15% slower than their respective JDK 8 queries.

For example, a 100K record/second dropDuplicates had a p95 latency regression of 12%. A regression of 12% and 21% (at the p95) was observed for a query with 1M record/second, 100K keys, 10 second windows, and 0 second watermark.

Because the Hotspot folks marked this as "Won't fix," one way to fix this is to avoid the JNI entirely and write the RocksDB to stderr. RocksDB [8.11.3 natively supports this|https://github.com/facebook/rocksdb/wiki/Logging-in-RocksJava#configuring-a-native-logger] (I implemented that feature in RocksJava). We can configure our RocksDB logger to do its logging this way.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Mar 13 17:48:32 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1nxm8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 12/Mar/24 21:05;neilramaswamy;cc: [~dongjoon] and [~LuciferYang], who were involved on the JDK 17 upgrade to 8.11.3. Maybe you would be interested in discussing this issue and the proposed fix.;;;, 12/Mar/24 22:00;dongjoon;Thank you for reporting, [~neilramaswamy]  Could you provide a reproducible Spark example for the further discussion?;;;, 13/Mar/24 07:40;LuciferYang;From the current Spark code, it appears that the {{Logger}} is only set for the {{RocksDB}} instance built for external shuffle db(inRocksDBProvider), and not for other parts. However, it seems that the Spark code does not actively print RocksDB-related logs (perhaps my confirmation method is incorrect, could you provide a way to confirm it? [~neilramaswamy] );;;, 13/Mar/24 17:48;neilramaswamy;[~dongjoon], I will create a minimal Spark repro and paste it in here shortly.

[~LuciferYang], I believe that you're looking at the `DBProvider`, which invokes the`RocksDBProvider`. Indeed, this is used for the external shuffle. However, Structured Streaming uses the RocksDB class, which [_always_ creates a logger invoked over the JNI|https://github.com/apache/spark/blob/b75325ccefa67b0c2daee317264808c67d76854f/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/state/RocksDB.scala#L132]. It's possible that the External shuffle service's use of RocksDB logging also suffers from a JDK 17 JNI attach/detach performance regression but I have never observed this in practice. If you are able to create a regression repro for the ESS, we should address it in a separate ticket.;;;
Affects Version/s.1: 3.3.1
Affects Version/s.2: 3.3.2
Affects Version/s.3: 3.3.3
Affects Version/s.4: 3.3.4
Comment.1: 12/Mar/24 22:00;dongjoon;Thank you for reporting, [~neilramaswamy]  Could you provide a reproducible Spark example for the further discussion?;;;

Summary: Spark wrongly map the BOOLEAN Type to BIT(1) in Snowflake
Issue key: SPARK-44866
Issue id: 13547843
Parent id: 13571633
Issue Type: Sub-task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hayssam
Reporter: hayssam
Creator: hayssam
Created: 8/18/23 9:20
Updated: 3/12/24 14:44
Last Viewed: 7/17/24 20:45
Resolved: 9/8/23 22:14
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: In Snowflake the Boolean type is represented by the Boolean data type ([https://docs.snowflake.com/en/sql-reference/data-types-logical]), but Spark rely on the default JdbcDialect to generate the mapping which maps _Boolean_ to _BIT(1)_

This should be probably handled by a dialect specific to Snowflake.
Environment: 
Log Work: 
Original Estimate: 7200
Remaining Estimate: 7200
Time Spent: 
Work Ratio: 0%
Σ Original Estimate: 7200
Σ Remaining Estimate: 7200
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Sep 08 22:14:37 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jvg8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 18/Aug/23 13:26;hayssam;Created PR [https://github.com/apache/spark/pull/42545];;;, 08/Sep/23 22:14;dongjoon;Issue resolved by pull request 42545
[https://github.com/apache/spark/pull/42545];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 08/Sep/23 22:14;dongjoon;Issue resolved by pull request 42545
[https://github.com/apache/spark/pull/42545];;;

Summary: Too Many Shared Locks due to PostgresDialect.getTableExistsQuery - LIMIT 1
Issue key: SPARK-46747
Issue id: 13565089
Parent id: 13571633
Issue Type: Sub-task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: yao
Reporter: bbellam
Creator: bbellam
Created: 1/17/24 13:19
Updated: 3/12/24 14:39
Last Viewed: 7/17/24 20:45
Resolved: 1/30/24 12:41
Affects Version/s: 2.0.0, 2.0.1, 2.0.2, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.4.5, 2.4.6, 2.4.7, 2.4.8, 3.0.0, 3.0.1, 3.0.2, 3.0.3, 3.1.0, 3.1.1, 3.1.2, 3.1.3, 3.2.0, 3.2.1, 3.2.2, 3.2.3, 3.2.4, 3.3.0, 3.3.1, 3.3.2, 3.3.3, 3.3.4, 3.4.0, 3.4.1, 3.4.2, 3.5.0
Fix Version/s: 3.4.3, 3.5.1, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: +*Background:*+
PostgresDialect.getTableExistsQuery is using LIMIT 1 query to check the table existence in the database by overriding the default JdbcDialect.getTableExistsQuery which has WHERE 1 = 0.

+*Issue:*+
Due to LIMIT 1 query pattern, we are seeing high number of shared locks in the PostgreSQL installations where there are many partitions under a table that's being written to. Hence resorting to the default JdbcDialect which does WHERE 1 = 0 is proven to be more optimal as it doesn't scan any of the partitions and effectively checks for table existence.

The SELECT 1 FROM table LIMIT 1 query can indeed be heavier in certain scenarios, especially with partitioned tables or tables with a lot of data, as it may take shared locks on all partitions or involve more planner and execution time to determine the quickest way to get a single row.

On the other hand, SELECT 1 FROM table WHERE 1=0 doesn't actually try to read any data due to the always false WHERE condition. This makes it a lighter operation, as it typically only involves checking the table's metadata to validate the table's existence without taking locks on the table's data or partitions.

So, considering performance and minimizing locks, SELECT 1 FROM table WHERE 1=0 would be a better choice if we're strictly looking to check for a table's existence and want to avoid potentially heavier operations like taking shared locks on partitions.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): Important
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): Scala
Custom field (Last public comment date): Tue Jan 30 14:45:17 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1mth4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 30/Jan/24 03:41;yao;It would be better if you could provide the stats of # of shared locks before and after.;;;, 30/Jan/24 12:41;yao;Issue resolved by pull request 44948
[https://github.com/apache/spark/pull/44948];;;, 30/Jan/24 13:08;bbellam;Thank you very much [~yao] . Sure, I can provide those number of shared locks as soon as I can.

Currently we are using older versions of Spark (2.3). Does this PR update the older versions as well?;;;, 30/Jan/24 14:38;yao;according to the release policies of Spark，patches never get merged to EOL versions. FYI, Spark 3.2 and before are EOL.

if you stay in 2.3 for some reason, consider backport the patch to it
;;;, 30/Jan/24 14:45;bbellam;Thanks [~yao] . So, does this get released to 3.3 & higher? ;;;
Affects Version/s.1: 2.0.1, 2.2.3, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0, 2.4.1, 2.4.2, 2.4.3
Affects Version/s.2: 2.0.2, 2.4.4, 2.4.5, 2.4.6, 2.4.7, 2.4.8, 3.0.0, 3.0.1, 3.0.2, 3.0.3, 3.1.0
Affects Version/s.3: 2.1.0, 3.1.1, 3.1.2, 3.1.3, 3.2.0, 3.2.1, 3.2.2, 3.2.3, 3.2.4, 3.3.0, 3.3.1
Affects Version/s.4: 2.1.1, 3.3.2, 3.3.3, 3.3.4, 3.4.0, 3.4.1, 3.4.2, 3.5.0
Comment.1: 30/Jan/24 12:41;yao;Issue resolved by pull request 44948
[https://github.com/apache/spark/pull/44948];;;

Summary: spark.catalog.listTables fails with ParseException after upgrading to Spark 3.4.1 from 3.3.1
Issue key: SPARK-45854
Issue id: 13557342
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: orolesko
Creator: orolesko
Created: 11/9/23 14:36
Updated: 3/12/24 4:26
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.0, 3.4.1
Fix Version/s: 
Component/s: PySpark, Spark Core, Spark Submit
Due Date: 
Votes: 0
Labels: 
Description: After upgrading to Spark 3.4.1, the listTables() method in PySpark now throws a ParseException with the message "Syntax error at or near end of input.". This did not occur in previous versions of Spark, such as 3.3.1.

Install Spark version 3.4.1.
 
Run pyspark
```bash
{{pyspark --packages io.delta:delta-core_2.12:2.4.0 --conf "spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension" --conf "spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog"}}
```
 
Attempt to list tables using
```console
{{spark.range(1).createTempView("test_view")}}
{{spark.catalog.listTables()}}
```
Expected result: The listTables() method should return a list of tables without throwing any exceptions.

Actual result: 
{{Traceback (most recent call last):}}
{{File "<stdin>", line 1, in <module>}}
{{File ".venv/lib/python3.10/site-packages/pyspark/sql/catalog.py", line 302, in listTables}}
{{iter = self._jcatalog.listTables(dbName).toLocalIterator()}}
{{File ".venv/lib/python3.10/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in _{_}call{_}_}}
{{File ".venv/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 175, in deco}}
{{raise converted from None}}
{{pyspark.errors.exceptions.captured.ParseException:}}
{{[PARSE_SYNTAX_ERROR] Syntax error at or near end of input.(line 1, pos 0)}}

== SQL ==

^^^

>>>

The same code worked correctly in Spark version 3.3.1.
No changes were made to the code aside from upgrading Spark.

Thank you for considering this issue! Any assistance in resolving it would be greatly appreciated.

Best regards,
Andrej
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Mar 12 04:26:18 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1li0w:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 12/Mar/24 04:26;lee@chungmin.dev;This is probably a bug in ShowTablesExec (isTempView always returns false if the catalog is not V2SessionCatalog) but it could be an intended behavior. Anyway, you can set spark.sql.legacy.useV1Command to true to workaround the issue.;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Spark shell log filter should be applied to all AbstractAppender
Issue key: SPARK-46510
Issue id: 13562908
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: angerszhuuuu
Creator: angerszhuuuu
Created: 12/26/23 6:47
Updated: 3/8/24 6:19
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.2.1, 3.3.4, 3.4.1
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: When we set async appender and refer to console, spark shell log filter won't work.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 47:45.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1mg0w:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.3.4
Affects Version/s.2: 3.4.1
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: DataType __repr__ change breaks datatype checking (anit-)pattern
Issue key: SPARK-47288
Issue id: 13570866
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: tedjenks
Creator: tedjenks
Created: 3/5/24 17:26
Updated: 3/8/24 0:10
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: This pr: [https://github.com/apache/spark/pull/34320]

Made reprs for datatype eval-able. This is kind of nice, but we have a ton of users doing stuff like:

 
{code:java}
if str(data_type) == "StringType":
   ...
{code}
 

Which breaks.

 

What would people think of adding a __str__ to the base class that returns the old behaviour so we can have the best of both worlds.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Mar 08 00:10:34 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1nsmw:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 05/Mar/24 17:26;tedjenks;[~gurwls223] I saw you on the original PR, curious for you thoughts.;;;, 08/Mar/24 00:10;gurwls223;I agree in principle but my concern is more about backward compatibility.;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 08/Mar/24 00:10;gurwls223;I agree in principle but my concern is more about backward compatibility.;;;

Summary: get_json_object flattens wildcard queries that match a single value
Issue key: SPARK-46778
Issue id: 13565481
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: revans2
Creator: revans2
Created: 1/19/24 18:47
Updated: 3/4/24 22:14
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: I think this impacts all versions of {{{}get_json_object{}}}, but I am not 100% sure.

The unit test for [$.store.book[*].reader|https://github.com/apache/spark/blob/39f8e1a5953b5897f893151d24dc585a80c0c8a0/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/JsonExpressionsSuite.scala#L142-L146] verifies that the output of this query is a single level JSON array, but when I put the same JSON and JSON path into [http://jsonpath.com/] I get a result with multiple levels of nesting. It looks like Apache Spark tries to flatten lists for {{[*]}} matches when there is only a single element that matches.
{code:java}
scala> Seq("""[{"a":"A"},{"b":"B"}]""","""[{"a":"A"},{"a":"B"}]""").toDF("jsonStr").selectExpr("""get_json_object(jsonStr,"$[*].a")""").show(false)
+--------------------------------+
|get_json_object(jsonStr, $[*].a)|
+--------------------------------+
|"A"                             |
|["A","B"]                       |
+--------------------------------+ {code}
But this has problems in that I no longer have a consistent schema returned, even if the input schema is known to be consistent. For example if I wanted to know how many elements matched this query I could wrap it in a {{json_array_length}} but that does not work in the generic case.
{code:java}
scala> Seq("""[{"a":"A"},{"b":"B"}]""","""[{"a":"A"},{"a":"B"}]""").toDF("jsonStr").selectExpr("""json_array_length(get_json_object(jsonStr,"$[*].a"))""").show(false)
+---------------------------------------------------+
|json_array_length(get_json_object(jsonStr, $[*].a))|
+---------------------------------------------------+
|null                                               |
|2                                                  |
+---------------------------------------------------+ {code}
If the value returned might be a JSON array, and then I would get a number, but it is wrong.
{code:java}
scala> Seq("""[{"a":[1,2,3,4,5]},{"b":"B"}]""","""[{"a":[1,2,3,4,5]},{"a":[1,2,3,4,5]}]""").toDF("jsonStr").selectExpr("""json_array_length(get_json_object(jsonStr,"$[*].a"))""").show(false)
+---------------------------------------------------+
|json_array_length(get_json_object(jsonStr, $[*].a))|
+---------------------------------------------------+
|5                                                  |
|2                                                  |
+---------------------------------------------------+ {code}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Mar 04 22:14:06 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1mvw8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 04/Mar/24 22:14;planga82;I was looking at it and I found a comment in the code that explain why this behavior ([https://github.com/apache/spark/blob/35bced42474e3221cf61d13a142c3c5470df1f22/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/jsonExpressions.scala#L377]) 

There are some tests around the code that test it and I reproduced it in hive 3.1.3 and it still maintains this behavior so I don't know if we can change it.;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Fix `core` module to succeed SBT tests
Issue key: SPARK-47196
Issue id: 13570075
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: dongjoon
Reporter: dongjoon
Creator: dongjoon
Created: 2/27/24 21:23
Updated: 2/28/24 2:23
Last Viewed: 7/17/24 20:45
Resolved: 2/28/24 2:22
Affects Version/s: 3.4.0, 3.4.1, 3.4.2
Fix Version/s: 3.4.3
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: This happens at branch-3.4 only. branch-3.3/branch-3.5/master are okay.
{code:java}
$ build/sbt "core/testOnly *.DAGSchedulerSuite"
[info] DAGSchedulerSuite:
[info] - [SPARK-3353] parent stage should have lower stage id *** FAILED *** (439 milliseconds)
[info]   java.lang.IllegalStateException: Could not initialize plugin: interface org.mockito.plugins.MockMaker (alternate: null)
...
[info] *** 1 SUITE ABORTED ***
[info] *** 118 TESTS FAILED ***
[error] Error during tests:
[error] 	org.apache.spark.scheduler.DAGSchedulerSuite
[error] (core / Test / testOnly) sbt.TestsFailedException: Tests unsuccessful
[error] Total time: 48 s, completed Feb 27, 2024, 1:26:27 PM {code}
 

MAVEN
{code:java}
$ build/mvn dependency:tree -pl core | grep byte-buddy
...
[INFO] |  +- net.bytebuddy:byte-buddy:jar:1.12.10:test
[INFO] |  +- net.bytebuddy:byte-buddy-agent:jar:1.12.10:test
{code}
SBT
{code:java}
$ build/sbt "core/test:dependencyTree" | grep byte-buddy
[info]   | | | | +-net.bytebuddy:byte-buddy:1.12.10 (evicted by: 1.12.18)
[info]   | | | | +-net.bytebuddy:byte-buddy:1.12.18
{code}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Feb 28 02:22:22 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1nnr4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 28/Feb/24 02:22;dongjoon;Issue resolved by pull request 45295
[https://github.com/apache/spark/pull/45295];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.4.2
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: In the spark driver pod. Failed to access the krb5 file
Issue key: SPARK-47114
Issue id: 13569290
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Resolved
Assignee: 
Reporter: melin
Creator: melin
Created: 2/21/24 6:31
Updated: 2/28/24 1:17
Last Viewed: 7/17/24 20:45
Resolved: 2/28/24 1:17
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Kubernetes
Due Date: 
Votes: 0
Labels: 
Description: spark runs in kubernetes and accesses an external hdfs cluster (kerberos)，pod error logs
{code:java}
Caused by: java.lang.IllegalArgumentException: KrbException: krb5.conf loading failed{code}
This error generally occurs when the krb5 file cannot be found

[~yao] [~Qin Yao] 
{code:java}
./bin/spark-submit \
    --master k8s://https://172.18.5.44:6443 \
    --deploy-mode cluster \
    --name spark-pi \
    --class org.apache.spark.examples.SparkPi \
    --conf spark.executor.instances=1 \
    --conf spark.kubernetes.submission.waitAppCompletion=true \
    --conf spark.kubernetes.driver.pod.name=spark-xxxxxxx \
    --conf spark.kubernetes.executor.podNamePrefix=spark-executor-xxxxxxx \
    --conf spark.kubernetes.driver.label.profile=production \
    --conf spark.kubernetes.executor.label.profile=production \
    --conf spark.kubernetes.namespace=superior \
    --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
    --conf spark.kubernetes.container.image=registry.cn-hangzhou.aliyuncs.com/melin1204/spark-jobserver:3.4.0 \
    --conf spark.kubernetes.file.upload.path=hdfs://cdh1:8020/user/superior/kubernetes/ \
    --conf spark.kubernetes.container.image.pullPolicy=Always \
    --conf spark.kubernetes.container.image.pullSecrets=docker-reg-demos \
    --conf spark.kubernetes.kerberos.krb5.path=/etc/krb5.conf  \
    --conf spark.kerberos.principal=superior/admin@DATACYBER.COM  \
    --conf spark.kerberos.keytab=/root/superior.keytab  \
    file:///root/spark-3.4.2-bin-hadoop3/examples/jars/spark-examples_2.12-3.4.2.jar  5{code}
{code:java}
(base) [root@cdh1 ~]# kubectl logs spark-xxxxxxx -n superior
Exception in thread "main" java.lang.IllegalArgumentException: Can't get Kerberos realm
        at org.apache.hadoop.security.HadoopKerberosName.setConfiguration(HadoopKerberosName.java:71)
        at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:315)
        at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:300)
        at org.apache.hadoop.security.UserGroupInformation.isAuthenticationMethodEnabled(UserGroupInformation.java:395)
        at org.apache.hadoop.security.UserGroupInformation.isSecurityEnabled(UserGroupInformation.java:389)
        at org.apache.hadoop.security.UserGroupInformation.loginUserFromKeytab(UserGroupInformation.java:1119)
        at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:385)
        at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:955)
        at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:192)
        at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:215)
        at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
        at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1111)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1120)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.IllegalArgumentException: KrbException: krb5.conf loading failed
        at java.security.jgss/javax.security.auth.kerberos.KerberosPrincipal.<init>(Unknown Source)
        at org.apache.hadoop.security.authentication.util.KerberosUtil.getDefaultRealm(KerberosUtil.java:120)
        at org.apache.hadoop.security.HadoopKerberosName.setConfiguration(HadoopKerberosName.java:69)
        ... 13 more
(base) [root@cdh1 ~]# kubectl describe pod spark-xxxxxxx -n superior
Name:             spark-xxxxxxx
Namespace:        superior
Priority:         0
Service Account:  spark
Node:             cdh2/172.18.5.45
Start Time:       Wed, 21 Feb 2024 15:48:08 +0800
Labels:           profile=production
                  spark-app-name=spark-pi
                  spark-app-selector=spark-728e24e49f9040fa86b04c521463020b
                  spark-role=driver
                  spark-version=3.4.2
Annotations:      <none>
Status:           Failed
IP:               10.244.1.4
IPs:
  IP:  10.244.1.4
Containers:
  spark-kubernetes-driver:
    Container ID:  containerd://cceaf13b70cc5f21a639e71cb8663989ec73e122380844624d4bfac3946bae15
    Image:         spark:3.4.1
    Image ID:      docker.io/library/spark@sha256:69fb485a0bcad88f9a2bf066e1b5d555f818126dc9df5a0b7e6a3b6d364bc694
    Ports:         7078/TCP, 7079/TCP, 4040/TCP
    Host Ports:    0/TCP, 0/TCP, 0/TCP
    Args:
      driver
      --properties-file
      /opt/spark/conf/spark.properties
      --class
      org.apache.spark.examples.SparkPi
      spark-internal
      5
    State:          Terminated
      Reason:       Error
      Exit Code:    1
      Started:      Wed, 21 Feb 2024 15:49:54 +0800
      Finished:     Wed, 21 Feb 2024 15:49:56 +0800
    Ready:          False
    Restart Count:  0
    Limits:
      memory:  1408Mi
    Requests:
      cpu:     1
      memory:  1408Mi
    Environment:
      SPARK_USER:                 superior
      SPARK_APPLICATION_ID:       spark-728e24e49f9040fa86b04c521463020b
      SPARK_DRIVER_BIND_ADDRESS:   (v1:status.podIP)
      HADOOP_CONF_DIR:            /opt/hadoop/conf
      SPARK_LOCAL_DIRS:           /var/data/spark-5e734880-8e00-4349-a88e-e6062ecee6f8
      SPARK_CONF_DIR:             /opt/spark/conf
    Mounts:
      /etc/krb5.conf from krb5-file (rw,path="krb5.conf")
      /mnt/secrets/kerberos-keytab from kerberos-keytab (rw)
      /opt/hadoop/conf from hadoop-properties (rw)
      /opt/spark/conf from spark-conf-volume-driver (rw)
      /var/data/spark-5e734880-8e00-4349-a88e-e6062ecee6f8 from spark-local-dir-1 (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-mn8dm (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  hadoop-properties:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      spark-pi-ea209a8dcaa2d678-hadoop-config
    Optional:  false
  krb5-file:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      spark-pi-ea209a8dcaa2d678-krb5-file
    Optional:  false
  kerberos-keytab:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  spark-pi-ea209a8dcaa2d678-kerberos-keytab
    Optional:    false
  spark-local-dir-1:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  spark-conf-volume-driver:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      spark-drv-0a84c78dcaa2de11-conf-map
    Optional:  false
  kube-api-access-mn8dm:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   Burstable
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason       Age    From               Message
  ----     ------       ----   ----               -------
  Normal   Scheduled    2m46s  default-scheduler  Successfully assigned superior/spark-xxxxxxx to cdh2
  Warning  FailedMount  2m46s  kubelet            MountVolume.SetUp failed for volume "krb5-file" : configmap "spark-pi-ea209a8dcaa2d678-krb5-file" not found
  Warning  FailedMount  2m46s  kubelet            MountVolume.SetUp failed for volume "hadoop-properties" : configmap "spark-pi-ea209a8dcaa2d678-hadoop-config" not found
  Warning  FailedMount  2m46s  kubelet            MountVolume.SetUp failed for volume "kerberos-keytab" : secret "spark-pi-ea209a8dcaa2d678-kerberos-keytab" not found
  Warning  FailedMount  2m46s  kubelet            MountVolume.SetUp failed for volume "spark-conf-volume-driver" : configmap "spark-drv-0a84c78dcaa2de11-conf-map" not found
  Normal   Pulling      2m45s  kubelet            Pulling image "spark:3.4.1"
  Normal   Pulled       60s    kubelet            Successfully pulled image "spark:3.4.1" in 1m44.871s (1m44.871s including waiting)
  Normal   Created      60s    kubelet            Created container spark-kubernetes-driver
  Normal   Started      60s    kubelet            Started container spark-kubernetes-driver{code}
 

 cm:  spark-pi-ea209a8dcaa2d678-kerberos-keytab not exists
{code:java}
(base) [root@cdh1 ~]# kubectl get cm -n superior
NAME                                      DATA   AGE
kube-root-ca.crt                          1      161m
spark-drv-0a84c78dcaa2de11-conf-map       2      8m43s
spark-pi-ea209a8dcaa2d678-hadoop-config   11     8m43s
spark-pi-ea209a8dcaa2d678-krb5-file       1      8m43s {code}

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Feb 28 01:16:42 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1niwo:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 28/Feb/24 01:16;melin;默认jre17 不支持kerberos，换成jdk ;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Preformance issue on thrift API
Issue key: SPARK-47085
Issue id: 13568966
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: igreenfi
Reporter: igreenfi
Creator: igreenfi
Created: 2/18/24 8:10
Updated: 2/26/24 5:34
Last Viewed: 7/17/24 20:45
Resolved: 2/19/24 7:57
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 3.4.3, 3.5.2, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: This new complexity was introduced in SPARK-39041.

before this PR the code was:
{code:java}
while (curRow < maxRows && iter.hasNext) {
  val sparkRow = iter.next()
  val row = ArrayBuffer[Any]()
  var curCol = 0
  while (curCol < sparkRow.length) {
    if (sparkRow.isNullAt(curCol)) {
      row += null
    } else {
      addNonNullColumnValue(sparkRow, row, curCol, timeFormatters)
    }
    curCol += 1
  }
  resultRowSet.addRow(row.toArray.asInstanceOf[Array[Object]])
  curRow += 1
}{code}
 foreach without the _*O(n^2)*_ complexity so this change just return the state to what it was before.

 

In class `RowSetUtils` there is a loop that has _*O(n^2)*_ complexity:
{code:scala}
...
 while (i < rowSize) {
          val row = rows(I)
          ...
{code}
It can be easily converted back into _*O( n )*_ complexity.

 

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): SPARK-39041
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Feb 20 20:37:45 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ngww:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 18/Feb/24 08:30;igreenfi;https://github.com/apache/spark/pull/45155;;;, 19/Feb/24 07:57;yao;resolved by https://github.com/apache/spark/pull/45155;;;, 20/Feb/24 15:53;dongjoon;Hi, [~igreenfi]and [~yao]. 
Could you provide some background why this is a regression at 3.4.1 and 3.5.0? If this is not a regression at that version, we should change `Affected Versions` to `4.0.0` because this is an improvement.;;;, 20/Feb/24 18:23;igreenfi;[~dongjoon] I updated the details....;;;, 20/Feb/24 20:37;dongjoon;Thank you. I added SPARK-39041 as a link `is caused by`.;;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 19/Feb/24 07:57;yao;resolved by https://github.com/apache/spark/pull/45155;;;

Summary: Migrate Log4j 2.x in Spark 3.4.1 to Logback
Issue key: SPARK-44646
Issue id: 13545925
Parent id: 
Issue Type: Brainstorming
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: ytian
Creator: ytian
Created: 8/2/23 22:39
Updated: 2/24/24 13:54
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Build
Due Date: 
Votes: 0
Labels: 
Description: Hi,

We are working on the spark 3.4.1 upgrade from spark 3.1.3, in our logging system, we are using logback framework, it is working with spark 3.1.3 since it is using log4j 1.x. However, when we upgrade spark to 3.4.1, based on the [release notes|https://spark.apache.org/docs/latest/core-migration-guide.html], spark is migrating from log4j 2.x from log4j 1.x, the way we are replacing the log4j with logback is causing build failures in spark master start process.

Error: Unable to initialize main class org.apache.spark.deploy.master.Master
Caused by: java.lang.NoClassDefFoundError: org/apache/logging/log4j/core/Filter

In our current approach, we are using log4j-over-slf4j to replace the log4j-core, it is only applicable to log4j 1.x library. And there is no log4j-over-slf4j for log4j 2.x out there yet. (please correct me if I am wrong). 

I am also curious that why spark choose to use log4j 2.x instead of using SPI, which gives the users less flexibility to choose whatever logger implementation they want to use.

I want to share this issue and see if anyone else has been reported this and if there is any work-around or alternative solutions for it. Any suggestions are appreciated, thanks.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 09/Aug/23 21:40;ytian;Screenshot 2023-08-09 at 2.40.12 PM.png;https://issues.apache.org/jira/secure/attachment/13062013/Screenshot+2023-08-09+at+2.40.12+PM.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 1
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sat Feb 24 13:54:09 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jjz4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 03/Aug/23 21:33;ytian;Hi [~viirya] 

Could you please check this thread? It is a question related to https://issues.apache.org/jira/browse/SPARK-37814

Thanks.;;;, 03/Aug/23 21:51;viirya;I have not used it but maybe you can try https://logging.apache.org/log4j/log4j-2.2/log4j-to-slf4j/index.html.;;;, 09/Aug/23 21:42;ytian;Hi [~viirya] 

Thanks for the suggestion, we spent some time evaluate the log4j-to-slf4j approach, unfortunately, it seems not working.

Compared to log4j-over-slf4j for log4j 1.x, log4j-to-slf4j is mainly an adapter for log4j-core, which means we still need the dependency of log4j-core. Since logback and log4j-core are 2 implementations, slf4j will complain about it. Below is the diagram we have tried:

!Screenshot 2023-08-09 at 2.40.12 PM.png!

If there are no better solutions, we may need to rewrite the existing logging logics with log4j 2.x. Thanks.;;;, 24/Aug/23 12:19;filtzsche;Hi all,  
we are running into the same problem, and I believe the problem is not in the forwarding library but in Spark itself.  When initializing the logging in [Logging.scala|[https://github.com/apache/spark/blob/v3.3.1/core/src/main/scala/org/apache/spark/internal/Logging.scala#L232C22-L232C22]], the log4j implementation (dependency org.apache.logging.log4j.log4j-slf4j-impl) is required.
However, this dependency also needs to be excluded in order to successfully use logging via logback. 
I was able to run our program with logback logging in debug mode, by skipping the code line liked above. Wrapping the call to “StaticLoggerBinder.getSingleton.getLoggerFactoryClassStr” in a try block and return an empty string if the class is not known would probably solve the problem.
It would be great if this issue could be fixed soon, as it blocks us from upgrading to Spark version 3.3.0 and newer.
Thanks.;;;, 24/Feb/24 13:54;rmucha-c;Hi [~viirya] ,

Do you have any plans to somehow address this issue? It is quite serious problem, since it force using log4j2 implementation (log4j-core) with Spark. Solution is either quite naive approach like [here|https://github.com/apache/spark/pull/45001] , or on the other hand, creating separate interfaces in Spark core and developing packages that offer implementations utilising different logging frameworks - it is spring approach. Have you had any discussions about that?

Best;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 03/Aug/23 21:51;viirya;I have not used it but maybe you can try https://logging.apache.org/log4j/log4j-2.2/log4j-to-slf4j/index.html.;;;

Summary: Use AnalyzeTableCommand overwrite statistics information incorrectly
Issue key: SPARK-46996
Issue id: 13567672
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: davidxdh
Creator: davidxdh
Created: 2/7/24 2:31
Updated: 2/7/24 12:05
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 2.4.4, 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: When the size of the table changes but the total number of rows in the table does not change, I use the sql statement "analyze table student compute statistics" to analyze the external table statistics. The Statistics information returned by the sql statement "desc extended student" only contains the table Size information, excluding rowCounts information.

Specific operating instructions:
{code:sql}
Create external table

create table student(id int, name string, age int) row format delimited fields terminated by ','
lines terminated by '\n' location 'hdfs://nameservice/spark/student';


The contents of the external table file are as follows:
class1.txt:

1,'Jack',25
2,'Thompson',28


class2.txt:

3,'Davy',30
4,'Thompson',35


class3.txt：

5,'Curry',40
6,'Morgan',20


Import external table data

hdfs dfs -put 1.txt /spark/student
hdfs dfs -put 2.txt /spark/student


Analyze external table statistics

analyze table student compute statistics;
desc extended student;

Return results

Type EXTERNAL
Provider hive
Table Properties [transient_lastDdlTime=1707265554]
Statistics 56 bytes, 4 rows
Location hdfs://nameservice/spark/student
Serde Library org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
InputFormat org.apache.hadoop.mapred.TextInputFormat
OutputFormat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
Storage Properties [serialization.format=,, line.delim=
, field.delim=,]
Partition Provider Catalog


Modify external table

hdfs dfs -rm /spark/student/student2.txt
hdfs dfs -put student3.txt /spark/student


Analyze the external table again

analyze table student compute statistics;
desc extended student;

Return results

Type EXTERNAL
Provider hive
Table Properties [transient_lastDdlTime=1707265719]
Statistics 55 bytes
Location hdfs://nameservice/spark/student
Serde Library org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
InputFormat org.apache.hadoop.mapred.TextInputFormat
OutputFormat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
Storage Properties [serialization.format=,, line.delim=
, field.delim=,]
Partition Provider Catalog
{code}
Through the above operation results, I found that when the table size changes but the number of rows does not change, the statistics should include the new table size and the total number of rows. I don’t know if it is correct to only display the statistics of the table size.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 31:08.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1n9ew:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: failed to insert the table using the default value of union
Issue key: SPARK-46192
Issue id: 13560141
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: 
Reporter: zengxl
Creator: zengxl
Created: 12/1/23 3:01
Updated: 1/31/24 1:17
Last Viewed: 7/17/24 20:45
Resolved: 1/31/24 1:17
Affects Version/s: 3.4.0, 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description:  

Obtain the following tables and data
{code:java}
create table test_spark(k string default null,v int default null) stored as orc;
create table test_spark_1(k string default null,v int default null) stored as orc;
insert into table test_spark_1 values('k1',1),('k2',2),('k3',3);
create table test_spark_2(k string default null,v int default null) stored as orc; 
insert into table test_spark_2 values('k3',3),('k4',4),('k5',5);

{code}
Execute the following SQL
{code:java}
insert into table test_spark (k) 
select k from test_spark_1
union
select k from test_spark_2 

{code}
exception:
{code:java}
23/12/01 10:44:25 INFO HiveSessionStateBuilder$$anon$1: here is CatalogAndIdentifier
23/12/01 10:44:25 INFO HiveSessionStateBuilder$$anon$1: here is CatalogAndIdentifier
23/12/01 10:44:25 INFO HiveSessionStateBuilder$$anon$1: here is CatalogAndIdentifier
23/12/01 10:44:26 INFO Analyzer$ResolveUserSpecifiedColumns: i.userSpecifiedCols.size is 1
23/12/01 10:44:26 INFO Analyzer$ResolveUserSpecifiedColumns: i.userSpecifiedCols.size is 1
23/12/01 10:44:26 INFO Analyzer$ResolveUserSpecifiedColumns: i.table.output 2 ,resolved :1 , i.query 1
23/12/01 10:44:26 INFO Analyzer$ResolveUserSpecifiedColumns: here is ResolveUserSpecifiedColumns tableOutoyt: 2---nameToQueryExpr : 1Error in query: `default`.`test_spark` requires that the data to be inserted have the same number of columns as the target table: target table has 2 column(s) but the inserted data has 1 column(s), including 0 partition column(s) having constant value(s). {code}
 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Jan 31 01:12:25 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lyyg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 26/Dec/23 11:16;zengxl;{code:java}
create table test_spark_3(k string default null,v int default null,m string default null) stored as orc; 

insert into table test_spark_3(k,v) select k,sum(v) v from test_spark_1 group by k;

insert into table test_spark_3(k,v) select distinct a.k,a.v from test_spark a left join test_spark_1 b on a.k=b.k  limit 2;{code}
The above SQL has the same exception

 ;;;, 28/Dec/23 13:36;raciniewska;I am working on it;;;, 31/Jan/24 01:12;zengxl;This patch solves all of these problems

https://issues.apache.org/jira/browse/SPARK-43742;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 28/Dec/23 13:36;raciniewska;I am working on it;;;

Summary: Remove inline scripts from UI descriptions
Issue key: SPARK-46893
Issue id: 13566440
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: rshkv
Reporter: rshkv
Creator: rshkv
Created: 1/28/24 17:59
Updated: 1/30/24 6:44
Last Viewed: 7/17/24 20:45
Resolved: 1/30/24 6:43
Affects Version/s: 3.4.1
Fix Version/s: 3.4.3, 3.5.1, 4.0.0
Component/s: UI, Web UI
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Users can inject inline scripts (e.g. {{onclick}} or {{onmouseover}} handlers) in the UI job and stage descriptions.

The UI already has precaution to treat, e.g., {{<script>}} tags as plain-text. But that doesn't extend to inline scripts.

Example:

{code:title=Bad job descriptions}
scala> sc.setJobDescription("""<a href="/link" onmouseover="alert('oops');">onmouseover</a>""")

scala> spark.sql("SELECT 1").show()
...

scala> sc.setJobDescription("""<a href="/link" onclick="alert('oops');">onclick</a>""")

scala> spark.sql("SELECT 1").show()
...
{code}

 !Screenshot 2024-01-29 at 09.06.34.png|width=600! 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 28/Jan/24 17:59;rshkv;Screen Recording 2024-01-28 at 17.51.47.mov;https://issues.apache.org/jira/secure/attachment/13066301/Screen+Recording+2024-01-28+at+17.51.47.mov, 29/Jan/24 09:07;rshkv;Screenshot 2024-01-29 at 09.06.34.png;https://issues.apache.org/jira/secure/attachment/13066306/Screenshot+2024-01-29+at+09.06.34.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 2
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Jan 30 06:43:52 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1n1tc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 29/Jan/24 12:15;rshkv;cc [~dongjoon], for your awareness as PMC who's recently touched the UI.

I'm wondering if we should file a CVE for this.;;;, 30/Jan/24 06:36;dongjoon;Thank you for pinging me, [~rshkv].;;;, 30/Jan/24 06:43;dongjoon;Issue resolved by pull request 44933
[https://github.com/apache/spark/pull/44933];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 30/Jan/24 06:36;dongjoon;Thank you for pinging me, [~rshkv].;;;

Summary: RocksDB versionID Mismatch in SST files
Issue key: SPARK-46796
Issue id: 13565713
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: bhuwan.sahni
Reporter: bhuwan.sahni
Creator: bhuwan.sahni
Created: 1/22/24 20:28
Updated: 1/24/24 12:49
Last Viewed: 7/17/24 20:45
Resolved: 1/24/24 12:49
Affects Version/s: 3.4.1, 3.4.2, 3.5.0, 3.5.1, 3.5.2, 4.0.0
Fix Version/s: 3.5.1, 4.0.0
Component/s: Structured Streaming
Due Date: 
Votes: 0
Labels: pull-request-available
Description: We need to ensure that the correct SST files are used on executor during RocksDB load as per mapping in metadata.zip. With current implementation, its possible that the executor uses a SST file (with a different UUID) from a older version which is not the exact file mapped in the metadata.zip. This can cause version Id mismatch errors while loading RocksDB leading to streaming query failures.

Few scenarios in which such a situation can occur are:

**Scenario 1 - Distributed file system does not support overwrite functionality**
 # A task T1 on executor A commits Rocks Db snapshot for version X.
 # Another task T2 on executor A loads version X-1, and tries to commit X. During commit, SST files are copied but metadata file is not overwritten.
 # Task T3 is scheduled on A, this task reuses previously loaded X (loaded in (2) above) and commits X+1.
 # Task T4 is scheduled on A again for state store version X. The executor deletes SST files corresponding to commit X+1, downloads the metadata for version X (which was committed in task T1), and loads RocksDB. This would fail because the metadata in (1) is not compatible with SST files in (2).

 

**Scenario 2 - Multiple older State versions have different DFS files for a particular SST file.**


In the current logic, we look at all the versions older than X to find if a local SST file can be reused. The reuse logic only ensures that the local SST file was present in any of the previous version. However, its possible that 2 different older versions had a different SST file (`0001-uuid1.sst` and `0001-uuid2.sst`) uploaded on DFS. These SST files will have the same local name (with UUID truncated) and size, but are not compatible due to different RocksDB Version Ids. We need to ensure that the correct SST file (as per UUID) is picked as mentioned in the metadata.zip.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Jan 24 12:49:23 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1mxbs:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 22/Jan/24 20:29;bhuwan.sahni;Working on a PR for the fix.;;;, 22/Jan/24 21:54;bhuwan.sahni;PR created - [https://github.com/apache/spark/pull/44837];;;, 24/Jan/24 12:49;kabhwan;Issue resolved by pull request 44837
[https://github.com/apache/spark/pull/44837];;;
Affects Version/s.1: 3.4.2
Affects Version/s.2: 3.5.0
Affects Version/s.3: 3.5.1
Affects Version/s.4: 3.5.2
Comment.1: 22/Jan/24 21:54;bhuwan.sahni;PR created - [https://github.com/apache/spark/pull/44837];;;

Summary: Coalesce partiton assert error after skew join optimization
Issue key: SPARK-46590
Issue id: 13563546
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: Jackey Lee
Reporter: Jackey Lee
Creator: Jackey Lee
Created: 1/4/24 8:36
Updated: 1/24/24 7:44
Last Viewed: 7/17/24 20:45
Resolved: 1/23/24 8:12
Affects Version/s: 3.3.1, 3.3.2, 3.3.3, 3.3.4, 3.4.0, 3.4.1, 3.5.0, 3.5.1, 4.0.0
Fix Version/s: 3.5.1, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Recently when we were testing TPCDS Q71, we found that if `spark.sql.shuffle.partitions` and `spark.sql.adaptive.coalescePartitions.initialPartitionNum` are both set to the number of executor cores, an AssertError may be reported in coalescePartition due to the partitionSpecs of joins after skew are different.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 04/Jan/24 08:37;Jackey Lee;problem.log;https://issues.apache.org/jira/secure/attachment/13065728/problem.log
Custom field (Affects version (Component)): 
Custom field (Attachment count): 1
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Jan 23 08:12:09 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1mjyg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 23/Jan/24 08:12;cloud_fan;Issue resolved by pull request 44661
[https://github.com/apache/spark/pull/44661];;;
Affects Version/s.1: 3.3.2
Affects Version/s.2: 3.3.3
Affects Version/s.3: 3.3.4
Affects Version/s.4: 3.4.0
Comment.1:

Summary: Relax constraint for columnar shuffle check in AQE
Issue key: SPARK-44660
Issue id: 13546050
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: csun
Creator: csun
Created: 8/3/23 19:27
Updated: 1/21/24 2:36
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: Currently in AQE, after evaluating the columnar rules, Spark will check if the top operator of the stage is still a shuffle operator, and throw exception if it doesn't.

{code}
        val optimized = e.withNewChildren(Seq(optimizeQueryStage(e.child, isFinalStage = false)))
        val newPlan = applyPhysicalRules(
          optimized,
          postStageCreationRules(outputsColumnar = plan.supportsColumnar),
          Some((planChangeLogger, "AQE Post Stage Creation")))
        if (e.isInstanceOf[ShuffleExchangeLike]) {
          if (!newPlan.isInstanceOf[ShuffleExchangeLike]) {
            throw SparkException.internalError(
              "Custom columnar rules cannot transform shuffle node to something else.")
          }
{code}

However, once a shuffle operator is transformed into a custom columnar shuffle operator, the {{supportsColumnar}} of the new shuffle operator will return true, and therefore the columnar rules will insert {{ColumnarToRow}} on top of it. This means the {{newPlan}} is likely no longer a {{ShuffleExchangeLike}} but a {{ColumnarToRow}}, and exception will be thrown, even though the use case is valid.

This JIRA proposes to relax the check by allowing the above case.




Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sun Jan 21 02:36:13 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jkqw:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 03/Aug/23 20:37;csun;In fact the check is necessary, but it seems 
{code}
postStageCreationRules(outputsColumnar = plan.supportsColumnar)
{code}

can be relaxed: if the new shuffle operator supports columnar, then maybe we shouldn't insert {{ColumnarToRow}} to this stage. This is assuming the following stage knows the shuffle output is columnar and has corresponding {{ColumnarToRow}} if necessary.;;;, 21/Jan/24 02:36;Suraj Naik;[~csun] Did you manage to fix this? ;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 21/Jan/24 02:36;Suraj Naik;[~csun] Did you manage to fix this? ;;;

Summary: Avro connector: convert a union of a single primitive type to a StructType
Issue key: SPARK-44919
Issue id: 13548294
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: adrianhu96
Creator: adrianhu96
Created: 8/22/23 22:19
Updated: 1/19/24 0:19
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Spark Avro data source schema converter currently converts union with a single primitive type to a Spark primitive type instead of a StructType.

While for more complex union types that consists of multiple primitive types, the schema converter translate them into StructTypes.

For example, 
import scala.collection.JavaConverters._
import org.apache.avro._
import org.apache.spark.sql.avro._

// ["string", "null"]
SchemaConverters.toSqlType(
  Schema.createUnion(Seq(Schema.create(Schema.Type.STRING), Schema.create(Schema.Type.NULL)).asJava)
).dataType

// ["string", "int", "null"]
SchemaConverters.toSqlType(
  Schema.createUnion(Seq(Schema.create(Schema.Type.STRING), Schema.create(Schema.Type.INT), Schema.create(Schema.Type.NULL)).asJava)
).dataType
The first one would return StringType, the second would return StructType(StringType, IntegerType).
 
We hope to add a new configuration to control the conversion behavior. The default behavior would still be the same. When the config is altered, a union with single primitive type would be translated into StructType.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 19:37.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jy88:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: The return status is incorrect in standalone mode
Issue key: SPARK-45290
Issue id: 13551761
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: changhu
Creator: changhu
Created: 9/24/23 1:53
Updated: 1/16/24 0:19
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.0, 3.4.1, 3.5.0
Fix Version/s: 
Component/s: Block Manager
Due Date: 
Votes: 0
Labels: pull-request-available
Description:  When a job is submitted in standalone mode using spark launch, sparkLancher returns a successful execution and then a failed execution. Examples are as follows

log: Spark App Id [app-20230922160022-0006] State Changed.  State [FINISHED]
23/09/22 16:01:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/09/22 16:01:10 INFO MemoryStore: MemoryStore cleared
23/09/22 16:01:10 INFO BlockManager: BlockManager stopped
23/09/22 16:01:10 INFO BlockManagerMaster: BlockManagerMaster stopped
23/09/22 16:01:10 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/09/22 16:01:10 INFO SparkContext: Successfully stopped SparkContext
23/09/22 16:01:10 INFO ShutdownHookManager: Shutdown hook called
23/09/22 16:01:10 INFO ShutdownHookManager: Deleting directory /tmp/spark-e015933f-a220-45a8-9d73-650b8bd8a337
23/09/22 16:01:10 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-8879f1d8-1f21-4b52-bca1-d3c66af6f754
23/09/22 16:01:11 INFO log: Spark App Id [app-20230922160022-0006] State Changed.  State [FAILED]
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 53:21.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kjmg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 3.4.0, 3.4.1, 3.5.0
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Fix `MasterPage` to sort `Running Drivers` table by `Duration` column correctly
Issue key: SPARK-46704
Issue id: 13564544
Parent id: 13557406
Issue Type: Sub-task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: dongjoon
Reporter: dongjoon
Creator: dongjoon
Created: 1/12/24 20:06
Updated: 1/12/24 20:54
Last Viewed: 7/17/24 20:45
Resolved: 1/12/24 20:54
Affects Version/s: 3.0.0, 3.1.3, 3.2.4, 3.3.4, 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.4.3, 3.5.1, 4.0.0
Component/s: Spark Core, Web UI
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Jan 12 20:54:58 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1mq48:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 12/Jan/24 20:54;dongjoon;Issue resolved by pull request 44711
[https://github.com/apache/spark/pull/44711];;;
Affects Version/s.1: 3.1.3
Affects Version/s.2: 3.2.4
Affects Version/s.3: 3.3.4
Affects Version/s.4: 3.4.1
Comment.1:

Summary: Remove unnecessary TaskScheduler.killAllTaskAttempts
Issue key: SPARK-46052
Issue id: 13558991
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: Ngone51
Reporter: Ngone51
Creator: Ngone51
Created: 11/22/23 8:28
Updated: 1/12/24 9:18
Last Viewed: 7/17/24 20:45
Resolved: 1/12/24 9:18
Affects Version/s: 3.0.3, 3.1.3, 3.2.4, 3.3.3, 3.4.1, 3.5.0
Fix Version/s: 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Spark has two functions to kill all tasks in a Stage:
* `cancelTasks`: Not only kill all the running tasks in all the stage attempts but also abort all the stage attempts
*  `killAllTaskAttempts`: Only kill all the running tasks in all the stage attemtps but won't abort the attempts.


However, there's no use case in Spark that a stage would launch new tasks after its all tasks get killed. So I think we can replace `killAllTaskAttempts` with `cancelTasks` directly.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Jan 12 09:18:10 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lrvc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 12/Jan/24 09:18;cloud_fan;Issue resolved by pull request 43954
[https://github.com/apache/spark/pull/43954];;;
Affects Version/s.1: 3.1.3
Affects Version/s.2: 3.2.4
Affects Version/s.3: 3.3.3
Affects Version/s.4: 3.4.1
Comment.1:

Summary: Pyspark throwing TypeError while collecting a RDD
Issue key: SPARK-46636
Issue id: 13564074
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: skyrim233
Creator: skyrim233
Created: 1/9/24 15:32
Updated: 1/9/24 15:33
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: PySpark
Due Date: 
Votes: 0
Labels: 
Description: Im trying to collect a RDD after applying a filter on it but its throwing an error.

 

Error can be reproduced from below code
{code:java}
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").appName("Practice").getOrCreate()

sc = spark.sparkContext

data = [1,2,3,4,5,6,7,8,9,10,11,12]
dataRdd = sc.parallelize(data)

dataRdd = dataRdd.filter(lambda a: a%2==0)

dataRdd.collect() {code}
Below is the error that its throwing:

 
{code:java}
--------------------------------------------------------------------------- TypeError Traceback (most recent call last) Cell In[18], line 1 ----> 1 dataRdd.collect() 
File ~\anaconda3\envs\spark_latest\Lib\site-packages\pyspark\rdd.py:
1814, in RDD.collect(self)  
1812 with SCCallSiteSync(self.context):  
1813 assert self.ctx._jvm is not None 
-> 1814 sock_info = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())  
1815 return list(_load_from_socket(sock_info, self._jrdd_deserializer)) 
File ~\anaconda3\envs\spark_latest\Lib\site-packages\pyspark\rdd.py:
5441, in PipelinedRDD._jrdd(self)  
438 else:  
5439 profiler = None 
-> 5441 wrapped_func = _wrap_function(  
5442 self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler  
5443 )  
5445 assert self.ctx._jvm is not None  
5446 python_rdd = self.ctx._jvm.PythonRDD(  
5447 self._prev_jrdd.rdd(), wrapped_func, self.preservesPartitioning, self.is_barrier  
5448 ) 
File ~\anaconda3\envs\spark_latest\Lib\site-packages\pyspark\rdd.py:
5243, in _wrap_function(sc, func, deserializer, serializer, profiler)  
5241 pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)  
5242 assert sc._jvm is not None 
-> 5243 return sc._jvm.SimplePythonFunction(  
5244 bytearray(pickled_command),  
5245 env,  
5246 includes,  
5247 sc.pythonExec,  
5248 sc.pythonVer,  
5249 broadcast_vars,  
5250 sc._javaAccumulator,  
5251 ) 

TypeError: 'JavaPackage' object is not callable{code}
 

 
Environment: Running this in anaconda jupyter notebook

Python== 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) 

[MSC v.1916 64 bit (AMD64)]

Spark== 3.3.4

pyspark== 3.4.1
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 32:26.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1mn7s:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: OrcColumnarBatchReader should respect the memory mode when creating column vectors for the missing column
Issue key: SPARK-46598
Issue id: 13563593
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: cloud_fan
Reporter: cloud_fan
Creator: cloud_fan
Created: 1/4/24 14:15
Updated: 1/6/24 20:48
Last Viewed: 7/17/24 20:45
Resolved: 1/6/24 20:48
Affects Version/s: 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.4.3, 3.5.1, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sat Jan 06 20:48:09 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1mk8w:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 06/Jan/24 20:48;dongjoon;Issue resolved by pull request 44598
[https://github.com/apache/spark/pull/44598];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 4.0.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: critical CVE vulnerability with a fix in Derby
Issue key: SPARK-46267
Issue id: 13560637
Parent id: 
Issue Type: Dependency upgrade
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: julienlau
Creator: julienlau
Created: 12/5/23 11:06
Updated: 1/2/24 11:52
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Build
Due Date: 
Votes: 1
Labels: security
Description:  

It would be necessary to upgrade Derby dependency in order to solve a critical vulnerability that was fixed in the latest release of Derby in November:

[https://db.apache.org/derby/releases/release-10_17_1_0.cgi]

https://issues.apache.org/jira/browse/DERBY-7147?focusedCommentId=17799544&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17799544

 

 

The vuln:

```

│                   Library                    │ Vulnerability  │ Severity │ Status │ Installed Version │ Fixed Version │                            Title                             │

│ org.apache.derby:derby (derby-10.14.2.0.jar) │ CVE-2022-46337 │ CRITICAL │ fixed  │ 10.14.2.0         │ 10.17.1.0     │ A cleverly devised username might bypass LDAP authentication │

```
Environment: I know it is in spark 3.4.1 that is the last version released by canonical charmed spark.

Since the fix was released on Nov 10 on derby side it probably affects all versions of spark.
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): Important
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 06:01.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1m20o:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Push filters through intersect
Issue key: SPARK-44812
Issue id: 13547331
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: HectorZhang
Creator: HectorZhang
Created: 8/15/23 4:42
Updated: 12/30/23 0:18
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: For following SQL
{code:sql}
select a from (select a from tl intersect select x from tr) where a > 123 {code}
The physical plan is
{code:bash}
== Physical Plan ==
AdaptiveSparkPlan isFinalPlan=false
+- HashAggregate(keys=[a#8L], functions=[])
   +- Exchange hashpartitioning(a#8L, 200), ENSURE_REQUIREMENTS, [plan_id=133]
      +- HashAggregate(keys=[a#8L], functions=[])
         +- BroadcastHashJoin [coalesce(a#8L, 0), isnull(a#8L)], [coalesce(x#24L, 0), isnull(x#24L)], LeftSemi, BuildRight, false
            :- Filter (isnotnull(a#8L) AND (a#8L > 123))
            :  +- FileScan json [a#8L] ...
            +- BroadcastExchange HashedRelationBroadcastMode(List(coalesce(input[0, bigint, true], 0), isnull(input[0, bigint, true])),false), [plan_id=129]
               +- FileScan json [x#24L] ... {code}
We can find the filter {color:#ff8b00}_a > 123_{color} is not pushed to right table.

 

 

Further more, for following SQL
{code:sql}
select a from (select a from tl intersect select x from tr) join trr on a = y{code}
The physical plan is
{code:bash}
*(3) Project [a#8L]
+- *(3) BroadcastHashJoin [a#8L], [y#114L], Inner, BuildRight, false
   :- *(3) HashAggregate(keys=[a#8L], functions=[])
   :  +- Exchange hashpartitioning(a#8L, 200), ENSURE_REQUIREMENTS, [plan_id=506]
   :     +- *(1) HashAggregate(keys=[a#8L], functions=[])
   :        +- *(1) BroadcastHashJoin [coalesce(a#8L, 0), isnull(a#8L)], [coalesce(x#24L, 0), isnull(x#24L)], LeftSemi, BuildRight, false
   :           :- *(1) Filter isnotnull(a#8L)
   :           :  +- FileScan json [a#8L] ...
   :           +- BroadcastExchange HashedRelationBroadcastMode(List(coalesce(input[0, bigint, true], 0), isnull(input[0, bigint, true])),false), [plan_id=490]
   :              +- FileScan json [x#24L] ...
   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, false]),false), [plan_id=512]
      +- *(2) Filter isnotnull(y#114L)
         +- FileScan json [y#114L] ...{code}
There should be a filter _{color:#ff8b00}isnotnull( x ){color}_ for table tr, while it's not pushed down.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 42:47.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jsag:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Support keyword columns on filters that interact with HMS
Issue key: SPARK-45102
Issue id: 13549947
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: scarlin
Creator: scarlin
Created: 9/7/23 16:18
Updated: 12/25/23 0:19
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Connect
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Recently, https://issues.apache.org/jira/browse/HIVE-27665 was pushed on Hive. This will allow HMS to handle columns that are surrounded by backticks in filters.  An example of a customer who hit this problem had a filter in Spark like this:

where date='2015-01-06'

This didn't work because the word "date" is a keyword.  In order for the customer to work, the where clause should be changed to this:

where `date`='2015-01-06'

Spark strips out the backticks before passing the filter to HMS.  We need to no longer strip the backticks as a configurable flag.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 18:22.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k8fk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Do not transpose windows if they conflict on ORDER BY / PROJECT clauses
Issue key: SPARK-45055
Issue id: 13549439
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: gubichev
Creator: gubichev
Created: 9/1/23 18:59
Updated: 12/23/23 0:18
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: TransposeWindows rule reorders parent and child window functions. Currently it incorrectly reorders the window functions in cases where the top window function orders by on the result of the bottom window function, e.g. {{sum1}} in the following example:

{{SELECT ROW_NUMBER() OVER (PARTITION BY C ORDER BY sum1)  FROM (SELECT ROW_NUMBER() OVER (PARTITION BY C) as sum1 FROM T) }}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Sep 06 09:39:50 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k5ao:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 06/Sep/23 09:39;aparna.garg;User 'agubichev' has created a pull request for this issue:
https://github.com/apache/spark/pull/42778;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Shutdown hook timeouts during ui stop
Issue key: SPARK-46456
Issue id: 13562302
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: yao
Reporter: yao
Creator: yao
Created: 12/19/23 9:57
Updated: 12/21/23 2:10
Last Viewed: 7/17/24 20:45
Resolved: 12/20/23 23:05
Affects Version/s: 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Dec 20 23:05:01 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1mcag:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 20/Dec/23 23:05;dongjoon;Issue resolved by pull request 44413
[https://github.com/apache/spark/pull/44413];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 4.0.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Scala None shows up as null for Aggregator BUF or OUT  
Issue key: SPARK-44323
Issue id: 13542727
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: koert
Creator: koert
Created: 7/6/23 17:08
Updated: 12/19/23 0:19
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: when doing an upgrade from spark 3.3.1 to spark 3.4.1 we suddenly started getting null pointer exceptions in Aggregators (classes extending org.apache.spark.sql.expressions.Aggregator) that use scala Option for BUF and/or OUT. basically None is now showing up as null.

after adding a simple test case and doing a binary search on commits we landed on SPARK-37829 being the cause.

we observed the issue at first with NPE inside Aggregator.merge because None was null. i am having a hard time replicating that in a spark unit test, but i did manage to get a None become null in the output. simple test that now fails:

 
{code:java}
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/DatasetAggregatorSuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/DatasetAggregatorSuite.scala
index e9daa825dd4..a1959d7065d 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/DatasetAggregatorSuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/DatasetAggregatorSuite.scala
@@ -228,6 +228,16 @@ case class FooAgg(s: Int) extends Aggregator[Row, Int, Int] {
   def outputEncoder: Encoder[Int] = Encoders.scalaInt
 }
 
+object OptionStringAgg extends Aggregator[Option[String], Option[String], Option[String]] {
+  override def zero: Option[String] = None
+  override def reduce(b: Option[String], a: Option[String]): Option[String] = merge(b, a)
+  override def finish(reduction: Option[String]): Option[String] = reduction
+  override def merge(b1: Option[String], b2: Option[String]): Option[String] =
+    b1.map{ b1v => b2.map{ b2v => b1v ++ b2v }.getOrElse(b1v) }.orElse(b2)
+  override def bufferEncoder: Encoder[Option[String]] = ExpressionEncoder()
+  override def outputEncoder: Encoder[Option[String]] = ExpressionEncoder()
+}
+
 class DatasetAggregatorSuite extends QueryTest with SharedSparkSession {
   import testImplicits._
 
@@ -432,4 +442,15 @@ class DatasetAggregatorSuite extends QueryTest with SharedSparkSession {
     val agg = df.select(mode(col("a"))).as[String]
     checkDataset(agg, "3")
   }
+
+  test("typed aggregation: option string") {
+    val ds = Seq((1, Some("a")), (1, None), (1, Some("c")), (2, None)).toDS()
+
+    checkDataset(
+      ds.groupByKey(_._1).mapValues(_._2).agg(
+        OptionStringAgg.toColumn
+      ),
+      (1, Some("ac")), (2, None)
+    )
+  }
 }
 {code}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): SPARK-37829
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sun Jul 09 15:35:37 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j09s:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 06/Jul/23 18:28;koert;i think the issue is that Nones inside Tuples now become nulls.

so its the usage of nullSafe inside the childrenDeserializers for tuples introduced in [https://github.com/apache/spark/pull/40755];;;, 09/Jul/23 15:35;koert;not sure why pullreq isnt getting linked automatically but its here:

https://github.com/apache/spark/pull/41903;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 09/Jul/23 15:35;koert;not sure why pullreq isnt getting linked automatically but its here:

https://github.com/apache/spark/pull/41903;;;

Summary: Encoders.bean does no longer work with read-only properties
Issue key: SPARK-45081
Issue id: 13549685
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: 
Reporter: gbloisi-openaire
Creator: gbloisi-openaire
Created: 9/5/23 14:42
Updated: 12/15/23 4:52
Last Viewed: 7/17/24 20:45
Resolved: 9/12/23 14:17
Affects Version/s: 3.4.1
Fix Version/s: 3.4.2, 3.5.1, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Since Spark 3.4.x an exception is thrown when Encoders.bean is called providing a bean having read-only properties, such as:

 
{code:java}
public static class ReadOnlyPropertyBean implements Serializable {
    public boolean isEmpty() {
      return true;
    }
} {code}
 

 
Encoders.bean(ReadOnlyPropertyBean.class) will throw:
{code:java}
java.util.NoSuchElementException: None.get
        at scala.None$.get(Option.scala:529)
        at scala.None$.get(Option.scala:527)
        at org.apache.spark.sql.catalyst.ScalaReflection$.$anonfun$deserializerFor$8(ScalaReflection.scala:359)
        at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
        at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
        at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
        at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)
        at scala.collection.TraversableLike.map(TraversableLike.scala:286)
        at scala.collection.TraversableLike.map$(TraversableLike.scala:279)
        at scala.collection.AbstractTraversable.map(Traversable.scala:108)
        at org.apache.spark.sql.catalyst.ScalaReflection$.deserializerFor(ScalaReflection.scala:348)
        at org.apache.spark.sql.catalyst.ScalaReflection$.deserializerFor(ScalaReflection.scala:183)
        at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$.apply(ExpressionEncoder.scala:56)
        at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$.javaBean(ExpressionEncoder.scala:62)
        at org.apache.spark.sql.Encoders$.bean(Encoders.scala:179)
        at org.apache.spark.sql.Encoders.bean(Encoders.scala) {code}
This problem is described also in [link Encoders.bean doesn't work anymore on a Java POJO, with Spark 3.4.0|https://stackoverflow.com/questions/76036349/encoders-bean-doesnt-work-anymore-on-a-java-pojo-with-spark-3-4-0]
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): SPARK-45311
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Sep 18 20:40:37 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k6tc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 18/Sep/23 20:40;dongjoon;This is backported to branch-3.4 via https://github.com/apache/spark/pull/42913;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Encoders.bean does not support superclasses with generic type arguments
Issue key: SPARK-44910
Issue id: 13548200
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: gbloisi-openaire
Reporter: gbloisi-openaire
Creator: gbloisi-openaire
Created: 8/22/23 11:54
Updated: 12/15/23 4:52
Last Viewed: 7/17/24 20:45
Resolved: 9/19/23 4:37
Affects Version/s: 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.4.2, 3.5.1, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: As per SPARK-44634 another unsupported feature of bean encoder is when the superclass of the bean has generic type arguments. For example:
{code:java}
class JavaBeanWithGenericsA<T> {
    public T getPropertyA() {
        return null;
    }

    public void setPropertyA(T a) {

    }
}

class JavaBeanWithGenericBase extends JavaBeanWithGenericsA<String> {
}

Encoders.bean(JavaBeanWithGenericBase.class); // Exception

{code}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): SPARK-45311
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Sep 19 04:39:19 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jxnk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 31/Aug/23 16:52;ignitetcbot;User 'gbloisi-openaire' has created a pull request for this issue:
https://github.com/apache/spark/pull/42634;;;, 19/Sep/23 04:37;dongjoon;Issue resolved by pull request 42634
[https://github.com/apache/spark/pull/42634];;;, 19/Sep/23 04:39;dongjoon;This landed at branch-3.4 via https://github.com/apache/spark/pull/42914;;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 4.0.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 19/Sep/23 04:37;dongjoon;Issue resolved by pull request 42634
[https://github.com/apache/spark/pull/42634];;;

Summary: Encoders.bean does no longer support nested beans with type arguments
Issue key: SPARK-44634
Issue id: 13545823
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: 
Reporter: gbloisi-openaire
Creator: gbloisi-openaire
Created: 8/2/23 9:13
Updated: 12/15/23 4:52
Last Viewed: 7/17/24 20:45
Resolved: 8/7/23 14:14
Affects Version/s: 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.4.2, 3.5.0, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: Hi,

  while upgrading a project from spark 2.4.0 to 3.4.1 version, I have encountered the same problem described in [java - Encoders.bean attempts to check the validity of a return type considering its generic type and not its concrete class, with Spark 3.4.0 - Stack Overflow|https://stackoverflow.com/questions/76045255/encoders-bean-attempts-to-check-the-validity-of-a-return-type-considering-its-ge].

Put it short, starting from Spark 3.4.x Encoders.bean throws an exception when the passed class contains a field whose type is a nested bean with type arguments:

 
{code:java}
class A<T> {
   T value;
   // value getter and setter
}

class B {
   A<String> stringHolder;
   // stringHolder getter and setter
}

Encoders.bean(B.class); // throws "SparkUnsupportedOperationException: [ENCODER_NOT_FOUND]..."{code}
 

 

It looks like this is a regression introduced with [SPARK-42093 SQL Move JavaTypeInference to AgnosticEncoders|https://github.com/apache/spark/commit/18672003513d5a4aa610b6b94dbbc15c33185d3#diff-1191737b908340a2f4c22b71b1c40ebaa0da9d8b40c958089c346a3bda26943b] while getting rid of TypeToken, that somehow managed that case.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): SPARK-45311
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Aug 07 14:14:33 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jjcg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 07/Aug/23 14:14;gbloisi-openaire;PR has been merged;;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 4.0.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Encoder fails on many "NoSuchElementException: None.get" since 3.4.x, search for an encoder for a generic type, and since 3.5.x isn't "an expression encoder"
Issue key: SPARK-45311
Issue id: 13551860
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: 
Reporter: mlebihan
Creator: mlebihan
Created: 9/25/23 8:46
Updated: 12/15/23 4:52
Last Viewed: 7/17/24 20:45
Resolved: 12/15/23 4:52
Affects Version/s: 3.4.0, 3.4.1, 3.5.0
Fix Version/s: 3.4.2, 3.5.1, 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: If you find it convenient, you might clone the [https://gitlab.com/territoirevif/minimal-tests-spark-issue] project (that does many operations around cities, local authorities and accounting with open data) where I've extracted from my work what's necessary to make a set of 35 tests that run correctly with Spark 3.3.x, and show the troubles encountered with 3.4.x and 3.5.x.

 

It is working well with Spark 3.2.x, 3.3.x. But as soon as I selec{*}t Spark 3.4.x{*}, where the encoder seems to have deeply changed, the encoder fails with two problems:

 

*1)* It throws *java.util.NoSuchElementException: None.get* messages everywhere.

Asking over the Internet, I wasn't alone facing this problem. Reading it, you'll see that I've attempted a debug but my Scala skills are low.

[https://stackoverflow.com/questions/76036349/encoders-bean-doesnt-work-anymore-on-a-java-pojo-with-spark-3-4-0]

{color:#172b4d}by the way, if possible, the encoder and decoder functions should forward a parameter as soon as the name of the field being handled is known, and then all the long of their process, so that when the encoder is at any point where it has to throw an exception, it knows the field it is handling in its specific call and can send a message like:{color}
{color:#00875a}_java.util.NoSuchElementException: None.get when encoding [the method or field it was targeting]_{color}

 

*2)* *Not found an encoder of the type RS to Spark SQL internal representation.* Consider to change the input type to one of supported at (...)
Or : Not found an encoder of the type *OMI_ID* to Spark SQL internal representation (...)

 
where *RS* and *OMI_ID* are generic types.
This is strange.
[https://stackoverflow.com/questions/76045255/encoders-bean-attempts-to-check-the-validity-of-a-return-type-considering-its-ge]

 

*3)* When I switch to the *Spark 3.5.0* version, the same problems remain, but another add itself to the list:
"{*}Only expression encoders are supported for now{*}" on what was accepted and working before.
 
Environment: Debian 12

Java 17

Underlying Spring-Boot 2.7.14
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): SPARK-44634, SPARK-44910, SPARK-45081
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 24/Nov/23 05:21;mlebihan;JavaTypeInference_116.png;https://issues.apache.org/jira/secure/attachment/13064654/JavaTypeInference_116.png, 24/Nov/23 05:26;mlebihan;sparkIssue_02.png;https://issues.apache.org/jira/secure/attachment/13064655/sparkIssue_02.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 2
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): Java
Custom field (Last public comment date): Fri Dec 15 04:52:21 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kk8g:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 12/Nov/23 10:55;mlebihan;The problem *java.util.NoSuchElementException: None.get*   happens in `{color:#0033b3} {color}{color:#000000}JavaBeanEncoder{color}({color:#000000}tag{color}, {color:#000000}fields{color})` case  of 
`deserializerFor` method in `ScalaReflexion`

(sorry for the indentation that I had to change due to a bad copy-paste)

 
{code:java}
case JavaBeanEncoder(tag, fields) =>
      val setters = fields.map { f =>
            val newTypePath = walkedTypePath.recordField(
                f.enc.clsTag.runtimeClass.getName,
                f.name)
    val setter = expressionWithNullSafety(
        deserializerFor(
            f.enc,
            addToPath(path, f.name, f.enc.dataType, newTypePath),
            newTypePath),
          nullable = f.nullable,
          newTypePath)
     f.writeMethod.get -> setter
}
{code}
 
`f.writeMethod` is valued with `None` if it happens that the method observed, a `getSomething()` or `isSomething()` doesn't have a corresponding setter method `setSomething(...)`.

I cannot tell if it's the new wished behavior for Spark after the `3.4.x` or if it's a regression.

But until `3.3.x`, it was possible to have class having `isSomething()` methods, in order to do some checkings, without the need of having a setter.
----
 
The workaround is to rename a method not having a setter to `something()` only, without `get` or `is` prefix.
Then Spark will skip it.;;;, 20/Nov/23 09:52;gbloisi-openaire;This is likely a duplicate of https://issues.apache.org/jira/browse/SPARK-45081 a fix has already been applied to 3.4 branch and will be part of 3.4.2 release. There are also other issues about backward compatibility of java beans support https://issues.apache.org/jira/browse/SPARK-44910 and https://issues.apache.org/jira/browse/SPARK-44634 that have been recently fixed and will be part of next releases.;;;, 21/Nov/23 06:29;mlebihan;Thanks, that's a good news. I'll check if this 3.4.2 succeed in resolving the two first issues mentioned (I think it will) from the SNAPSHOT in preparation, and will close them as duplicate.

For the last one,

*3)* When I switch to the *Spark 3.5.0* version, the same problems remain, but another add itself to the list:
"{*}Only expression encoders are supported for now{*}" on what was accepted and working before.

it's a new one, I should keep it, open, isn't it?
 ;;;, 22/Nov/23 20:25;gbloisi-openaire;I agree point 3) is a different problem that remains valid to report. Please note the fix here is 
to use Encoders.row(schema) instead of RowEncoder.encoderFor(schema). This is likely caused by the refactoring required for implementing "Spark Connect". ;;;, 22/Nov/23 21:22;mlebihan;I'll do a try for 3.5.0. I believe that I was forced to change from _{color:#000000}RowEncoder{color}.apply({color:#000000}schema{color}) (3.3.x and 3.4.x)_ to {color:#000000}_RowEncoder.encoderFor(schema)_ by the wish of the 3.5.0 version.{color}because _{color:#000000}RowEncoder{color}.apply_ doesn't exist anymore.

I didn't found an {{Encoders.row(...)}} method, one {{new Encoder(schema)}} was possible, but I found difficult to extract a {{{}ClassInfo<Row> getCls(){}}}.

I've found and changed for this, below, and it seems to reach the workaround you wrote about in 3.5.x. (I'll will continue to check, later) :
{code:java}
ExpressionEncoder<Row> encoder = ExpressionEncoder.apply(schema);

cible = cible.mapPartitions((MapPartitionsFunction<Row, Row>) it -> {
   List<Row> rows = new LinkedList<>();

   while (it.hasNext()) {
      [...]
      rows.add(RowFactory.create(valeurs.toArray()));
   }

   return rows.iterator();
}, encoder); {code}
 
----
I've experienced the latest 3.4.2-SNAPSHOT version available (refreshed my fork 19h ago)
to check for the problems related to  java.util.NoSuchElementException: None.get and the generic types. And it improves the execution greatly.

From 22 (or around) failing tests, for the 3.4.0 or 3.4.1,  the 3.4.2-SNAPSHOT faces 4 failures only:  but they look different than before.
{code:java}
-------------------------------------------------------------------------------
Test set: fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT
-------------------------------------------------------------------------------
Tests run: 6, Failures: 1, Errors: 3, Skipped: 0, Time elapsed: 8.709 s <<< FAILURE! - in fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT
catalogueJeuxDeDonneesEtRessources Time elapsed: 1.472 s <<< ERROR!
java.lang.ClassCastException: class [Ljava.lang.Object; cannot be cast to class [Ljava.lang.reflect.TypeVariable; ([Ljava.lang.Object; and [Ljava.lang.reflect.TypeVariable; are in module java.base of loader 'bootstrap')
at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT.catalogueJeuxDeDonneesEtRessources(CatalogueDatagouvIT.java:161)

catalogueDatasetsObjetsMetiersPagines Time elapsed: 1.03 s <<< ERROR!
java.lang.ClassCastException: class [Ljava.lang.Object; cannot be cast to class [Ljava.lang.reflect.TypeVariable; ([Ljava.lang.Object; and [Ljava.lang.reflect.TypeVariable; are in module java.base of loader 'bootstrap')
at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT.lambda$catalogueDatasetsObjetsMetiersPagines$0(CatalogueDatagouvIT.java:105)
at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT.catalogueDatasetsObjetsMetiersPagines(CatalogueDatagouvIT.java:105)

catalogueJeuxDeDonnees Time elapsed: 0.043 s <<< ERROR!
java.lang.ClassCastException: class [Ljava.lang.Object; cannot be cast to class [Ljava.lang.reflect.TypeVariable; ([Ljava.lang.Object; and [Ljava.lang.reflect.TypeVariable; are in module java.base of loader 'bootstrap')
at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT.catalogueJeuxDeDonnees(CatalogueDatagouvIT.java:143)

catalogueDatasetsObjetsMetiersPaginesStreames Time elapsed: 0.534 s <<< FAILURE!
org.opentest4j.AssertionFailedError: Unexpected exception thrown: java.lang.ClassCastException: class [Ljava.lang.Object; cannot be cast to class [Ljava.lang.reflect.TypeVariable; ([Ljava.lang.Object; and [Ljava.lang.reflect.TypeVariable; are in module java.base of loader 'bootstrap')
at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT.catalogueDatasetsObjetsMetiersPaginesStreames(CatalogueDatagouvIT.java:126)
Caused by: java.lang.ClassCastException: class [Ljava.lang.Object; cannot be cast to class [Ljava.lang.reflect.TypeVariable; ([Ljava.lang.Object; and [Ljava.lang.reflect.TypeVariable; are in module java.base of loader 'bootstrap')
at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT.lambda$catalogueDatasetsObjetsMetiersPaginesStreames$3(CatalogueDatagouvIT.java:127)
at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT.lambda$catalogueDatasetsObjetsMetiersPaginesStreames$4(CatalogueDatagouvIT.java:127)
at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT.catalogueDatasetsObjetsMetiersPaginesStreames(CatalogueDatagouvIT.java:126){code};;;, 23/Nov/23 10:43;gbloisi-openaire;Could you disable failsafe trimStackTrace (as explained in [https://stackoverflow.com/questions/42248856/how-to-get-the-full-stacktrace-of-failed-tests-in-failsafe] ) to get the full stack of the error and report it here? ;;;, 24/Nov/23 04:36;mlebihan;I've updated the  [https://gitlab.com/territoirevif/minimal-tests-spark-issue] testing project accordingly.
{code:java}
-------------------------------------------------------------------------------
Test set: fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT
-------------------------------------------------------------------------------
Tests run: 6, Failures: 1, Errors: 3, Skipped: 0, Time elapsed: 8.715 s <<< FAILURE! - in fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT
catalogueJeuxDeDonneesEtRessources  Time elapsed: 1.498 s  <<< ERROR!
java.lang.ClassCastException: class [Ljava.lang.Object; cannot be cast to class [Ljava.lang.reflect.TypeVariable; ([Ljava.lang.Object; and [Ljava.lang.reflect.TypeVariable; are in module java.base of loader 'bootstrap')
    at org.apache.spark.sql.catalyst.JavaTypeInference$.encoderFor(JavaTypeInference.scala:116)
    at org.apache.spark.sql.catalyst.JavaTypeInference$.$anonfun$encoderFor$1(JavaTypeInference.scala:140)
    at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:929)
    at org.apache.spark.sql.catalyst.JavaTypeInference$.encoderFor(JavaTypeInference.scala:138)
    at org.apache.spark.sql.catalyst.JavaTypeInference$.encoderFor(JavaTypeInference.scala:60)
    at org.apache.spark.sql.catalyst.JavaTypeInference$.encoderFor(JavaTypeInference.scala:53)
    at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$.javaBean(ExpressionEncoder.scala:62)
    at org.apache.spark.sql.Encoders$.bean(Encoders.scala:179)
    at org.apache.spark.sql.Encoders.bean(Encoders.scala)
    at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvJeuxDeDonneesDataset.catalogueDataset(CatalogueDatagouvJeuxDeDonneesDataset.java:100)
    at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvJeuxDeDonneesDataset.catalogueDataset(CatalogueDatagouvJeuxDeDonneesDataset.java:88)
    at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT.catalogueJeuxDeDonneesEtRessources(CatalogueDatagouvIT.java:161)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.base/java.lang.reflect.Method.invoke(Method.java:568)
    at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
    at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
    at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
    at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
    at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
    at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
    at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
    at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
    at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
    at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
    at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
    at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
    at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
    at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
    at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
    at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
    at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
    at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
    at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
    at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
    at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
    at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:220)
    at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$6(DefaultLauncher.java:188)
    at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:202)
    at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:181)
    at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:128)
    at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
    at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
    at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
    at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
    at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
    at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)catalogueDatasetsObjetsMetiersPagines  Time elapsed: 0.954 s  <<< ERROR!
java.lang.ClassCastException: class [Ljava.lang.Object; cannot be cast to class [Ljava.lang.reflect.TypeVariable; ([Ljava.lang.Object; and [Ljava.lang.reflect.TypeVariable; are in module java.base of loader 'bootstrap')
    at org.apache.spark.sql.catalyst.JavaTypeInference$.encoderFor(JavaTypeInference.scala:116)
    at org.apache.spark.sql.catalyst.JavaTypeInference$.$anonfun$encoderFor$1(JavaTypeInference.scala:140)
    at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:929)
    at org.apache.spark.sql.catalyst.JavaTypeInference$.encoderFor(JavaTypeInference.scala:138)
    at org.apache.spark.sql.catalyst.JavaTypeInference$.encoderFor(JavaTypeInference.scala:60)
    at org.apache.spark.sql.catalyst.JavaTypeInference$.encoderFor(JavaTypeInference.scala:53)
    at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$.javaBean(ExpressionEncoder.scala:62)
    at org.apache.spark.sql.Encoders$.bean(Encoders.scala:179)
    at org.apache.spark.sql.Encoders.bean(Encoders.scala)
    at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvJeuxDeDonneesDataset.catalogueDataset(CatalogueDatagouvJeuxDeDonneesDataset.java:100)
    at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT.lambda$catalogueDatasetsObjetsMetiersPagines$0(CatalogueDatagouvIT.java:105)
    at fr.ecoemploi.adapters.outbound.spark.dataset.core.Paginateur.toObjetMetierDataset(Paginateur.java:73)
    at fr.ecoemploi.adapters.outbound.spark.dataset.core.Paginateur.paginer(Paginateur.java:59)
    at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT.catalogueDatasetsObjetsMetiersPagines(CatalogueDatagouvIT.java:105)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.base/java.lang.reflect.Method.invoke(Method.java:568)
    at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
    at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
    at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
    at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
    at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
    at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
    at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
    at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
    at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
    at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
    at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
    at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
    at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
    at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
    at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
    at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
    at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
    at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
    at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
    at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
    at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
    at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:220)
    at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$6(DefaultLauncher.java:188)
    at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:202)
    at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:181)
    at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:128)
    at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
    at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
    at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
    at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
    at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
    at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)catalogueJeuxDeDonnees  Time elapsed: 0.059 s  <<< ERROR!
java.lang.ClassCastException: class [Ljava.lang.Object; cannot be cast to class [Ljava.lang.reflect.TypeVariable; ([Ljava.lang.Object; and [Ljava.lang.reflect.TypeVariable; are in module java.base of loader 'bootstrap')
    at org.apache.spark.sql.catalyst.JavaTypeInference$.encoderFor(JavaTypeInference.scala:116)
    at org.apache.spark.sql.catalyst.JavaTypeInference$.$anonfun$encoderFor$1(JavaTypeInference.scala:140)
    at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:929)
    at org.apache.spark.sql.catalyst.JavaTypeInference$.encoderFor(JavaTypeInference.scala:138)
    at org.apache.spark.sql.catalyst.JavaTypeInference$.encoderFor(JavaTypeInference.scala:60)
    at org.apache.spark.sql.catalyst.JavaTypeInference$.encoderFor(JavaTypeInference.scala:53)
    at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$.javaBean(ExpressionEncoder.scala:62)
    at org.apache.spark.sql.Encoders$.bean(Encoders.scala:179)
    at org.apache.spark.sql.Encoders.bean(Encoders.scala)
    at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvJeuxDeDonneesDataset.catalogueDataset(CatalogueDatagouvJeuxDeDonneesDataset.java:100)
    at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvJeuxDeDonneesDataset.catalogueDataset(CatalogueDatagouvJeuxDeDonneesDataset.java:88)
    at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT.catalogueJeuxDeDonnees(CatalogueDatagouvIT.java:143)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.base/java.lang.reflect.Method.invoke(Method.java:568)
    at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
    at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
    at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
    at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
    at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
    at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
    at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
    at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
    at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
    at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
    at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
    at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
    at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
    at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
    at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
    at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
    at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
    at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
    at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
    at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
    at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
    at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
    at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
    at org.junit.platform.engine.support.hierarchical
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: ThrowableCollector.execute(ThrowableCollector.java:73)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:220)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$6(DefaultLauncher.java:188)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:202)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:181)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:128)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)catalogueDatasetsObjetsMetiersPaginesStreames  Time elapsed: 0.529 s  <<< FAILURE!
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: org.opentest4j.AssertionFailedError: Unexpected exception thrown: java.lang.ClassCastException: class [Ljava.lang.Object; cannot be cast to class [Ljava.lang.reflect.TypeVariable; ([Ljava.lang.Object; and [Ljava.lang.reflect.TypeVariable; are in module java.base of loader 'bootstrap')
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.api.AssertDoesNotThrow.createAssertionFailedError(AssertDoesNotThrow.java:83)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:54)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:37)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.api.Assertions.assertDoesNotThrow(Assertions.java:3135)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT.catalogueDatasetsObjetsMetiersPaginesStreames(CatalogueDatagouvIT.java:126)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at java.base/java.lang.reflect.Method.invoke(Method.java:568)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:220)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$6(DefaultLauncher.java:188)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:202)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:181)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:128)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Caused by: java.lang.ClassCastException: class [Ljava.lang.Object; cannot be cast to class [Ljava.lang.reflect.TypeVariable; ([Ljava.lang.Object; and [Ljava.lang.reflect.TypeVariable; are in module java.base of loader 'bootstrap')
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.spark.sql.catalyst.JavaTypeInference$.encoderFor(JavaTypeInference.scala:116)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.spark.sql.catalyst.JavaTypeInference$.$anonfun$encoderFor$1(JavaTypeInference.scala:140)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:929)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.spark.sql.catalyst.JavaTypeInference$.encoderFor(JavaTypeInference.scala:138)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.spark.sql.catalyst.JavaTypeInference$.encoderFor(JavaTypeInference.scala:60)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.spark.sql.catalyst.JavaTypeInference$.encoderFor(JavaTypeInference.scala:53)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$.javaBean(ExpressionEncoder.scala:62)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.spark.sql.Encoders$.bean(Encoders.scala:179)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.apache.spark.sql.Encoders.bean(Encoders.scala)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvJeuxDeDonneesDataset.catalogueDataset(CatalogueDatagouvJeuxDeDonneesDataset.java:100)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT.lambda$catalogueDatasetsObjetsMetiersPaginesStreames$3(CatalogueDatagouvIT.java:127)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at fr.ecoemploi.adapters.outbound.spark.dataset.core.Paginateur.toObjetMetierDataset(Paginateur.java:73)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at fr.ecoemploi.adapters.outbound.spark.dataset.core.Paginateur.paginer(Paginateur.java:59)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at fr.ecoemploi.adapters.outbound.spark.dataset.core.Paginateur.paginerEnStream(Paginateur.java:42)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at fr.ecoemploi.adapters.outbound.spark.dataset.datagouv.CatalogueDatagouvIT.lambda$catalogueDatasetsObjetsMetiersPaginesStreames$4(CatalogueDatagouvIT.java:127)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     at org.junit.jupiter.api.AssertDoesNotThrow.assertDoesNotThrow(AssertDoesNotThrow.java:50)
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:     ... 68 more
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:  {code};;;
Issue key:  24/Nov/23 05:29;mlebihan;A breakpoint in {{catalogueJeuxDeDonnees()}} test
Issue id:   at :
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: 
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: {{org.apache.spark.sql.catalyst.JavaTypeInference$.encoderFor(JavaTypeInference.scala:116}}
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:  
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: 
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: !JavaTypeInference_116.png!
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: 
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: The caller of it :
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: 
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: !sparkIssue_02.png!
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: 
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: {{OMD_ID}} is a generic
Issue key:  compatible with {{{}CatalogueId{}}}.
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: 
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:  ;;;
Issue key:  26/Nov/23 23:38;gbloisi-openaire;The issue arise while Encoders.bean is inferring the schema for JeuDeDonnees class. This class has a field of type Ressources.class which extends a LinkedHashMap<RessourceJeuDeDonneesId
Issue id:  Ressource>.
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: 
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: A simple work-around to let the tests pass is to modify the JeuDeDonnees and declare ressources as a Map:
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: 
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:  
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: {code:java}
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: private Map<RessourceJeuDeDonneesId
Issue key:  Ressource> ressources; 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: //...
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: public Map<RessourceJeuDeDonneesId
Issue key:  Ressource> getRessources() {
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: //...{code}
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: and
Issue key:  when required
Issue id:  iterate the values explicitly:
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: 
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:  
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: 
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:  
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: {code:java}
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: jeuDeDonnees.getRessources().values().forEach {code}
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:  
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: 
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:  
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: 
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: The exception is thrown because the code assumes (wrongly in that case) that if a class (such as Ressources.class) is a Map
Issue key:  then it has generic type information attached to it
Issue id:  here instead the information is available in the base/super class.
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: 
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: There is a wider problem behind this. There are cases where mapping to a Spark schema would be ambigous
Issue key:  for example:
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:  * Ressources could have also getters and setters
Issue key:  should it be mapped as a map or a struct?
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:  * A class could implement both List and Map interfaces. should it be mapped as an array or a map?
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: 
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: IMO the workaround is also a good idiomatic way to structure beans to be used with Spark
Issue key:  as it makes the mapping explicit and removes the possibility of ambiguities. 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: 
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:  ;;;
Issue key:  27/Nov/23 04:39;mlebihan;Thanks.
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: 
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: I only had to change the :
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: {{{color:#0033b3}public{color} Ressources getRessources()}} getter to
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: {{{color:#0033b3}public {color}{color:#000000}Map{color}<{color:#000000}RessourceJeuDeDonneesId{color}
Issue key:  {color:#000000}Ressource{color}> getRessources()}}
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary:  
Issue key: 
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: to make it working. And change a test from {{jeuDeDonnees.getRessources().forEach((ressource) -> {color:#871094}LOGGER{color}.info(...))}} to {{jeuDeDonnees.getRessources().forEach((id
Issue key:  ressource) -> {color:#871094}LOGGER{color}.info(...))}}
Issue id: 
Parent id: 
Issue Type: 
Status: 
Project key: 
Project name: 
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: and now
Issue key:  all the troubles I had in this issue are solved or have found a workaround.;;;
Issue id:  15/Dec/23 04:52;mlebihan;Resolved through the resolution of linked issues;;;"
Parent id: 3.4.1
Issue Type: 3.5.0
Status: 
Project key: 
Project name: 20/Nov/23 09:52;gbloisi-openaire;This is likely a duplicate of https://issues.apache.org/jira/browse/SPARK-45081 a fix has already been applied to 3.4 branch and will be part of 3.4.2 release. There are also other issues about backward compatibility of java beans support https://issues.apache.org/jira/browse/SPARK-44910 and https://issues.apache.org/jira/browse/SPARK-44634 that have been recently fixed and will be part of next releases.;;;, 15/Dec/23 04:52;mlebihan;Resolved through the resolution of linked issues;;;
Project type: 
Project lead: 
Project description: 
Project url: 
Priority: 
Resolution: 
Assignee: 
Reporter: 
Creator: 
Created: 
Updated: 
Last Viewed: 
Resolved: 
Affects Version/s: 
Fix Version/s: 
Component/s: 
Due Date: 
Votes: 
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): 
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 
Custom field (Rank (Obsolete)): 
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: calculation error 
Issue key: SPARK-46362
Issue id: 13561359
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: paridee
Creator: paridee
Created: 12/11/23 10:47
Updated: 12/12/23 13:23
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: Hi,

I had wrong values while using the POW function in SPARK SQL, please see this example (in this example I multiply (10^-2)*25051 and the expected result is 250.51

 

from pyspark.sql.functions import lit
df = spark.range(1)
df.createOrReplaceTempView("TEST")
spark.sql("SELECT POWER(10, -2)*25051 FROM TEST").show()

 

but I got 250.51000000000002

 

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Dec 12 13:23:46 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1m6h4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 12/Dec/23 13:23;apeng;[~paridee] This is not a defect of Spark, it's related to the representation of floating-point numbers.

More details [here|https://stackoverflow.com/questions/70404164/the-calculation-accuracy-of-floating-point-numbers-float-double-in-java-ieee].;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Return null when overflowing during casting from timestamp to integers
Issue key: SPARK-45816
Issue id: 13556981
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: viirya
Reporter: viirya
Creator: viirya
Created: 11/7/23 5:52
Updated: 12/11/23 20:49
Last Viewed: 7/17/24 20:45
Resolved: 11/8/23 12:23
Affects Version/s: 3.3.3, 3.4.1, 3.5.0
Fix Version/s: 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Spark cast works in two modes: ansi and non-ansi. When overflowing during casting, the common behavior under non-ansi mode is to return null. However, casting from Timestamp to Int/Short/Byte returns a wrapping value now. The behavior to silently overflow doesn't make sense.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Nov 08 12:23:54 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lfso:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 08/Nov/23 12:23;beliefer;Issue resolved by pull request 43694
[https://github.com/apache/spark/pull/43694];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Cannot deploy Spark application using VolcanoFeatureStep to specify podGroupTemplate file 
Issue key: SPARK-46310
Issue id: 13561009
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: lsbx96_
Creator: lsbx96_
Created: 12/7/23 14:59
Updated: 12/11/23 12:35
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Kubernetes
Due Date: 
Votes: 0
Labels: 
Description: I'm trying to deploy a Spark application (version 3.4.1) on Kubernetes using Volcano as the scheduler. I define a [VolcanoJob|https://volcano.sh/en/docs/vcjob/] that represents the Spark driver - it has only one task, whose pod specification includes the driver container, which invokes the spark-submit command.

Following the official Spark documentation (available on "[Using Volcano as Customized Scheduler for Spark on Kubernetes|https://spark.apache.org/docs/latest/running-on-kubernetes.html#using-volcano-as-customized-scheduler-for-spark-on-kubernetes]"), I define the necessary configuration parameters to make use of Volcano as the scheduler for my Spark workload:
{code:java}
/opt/spark/bin/spark-submit --name "volcano-spark-1" --deploy-mode="client" \
--class "org.apache.spark.examples.SparkPi" \
--conf spark.executor.instances="1" \
--conf spark.kubernetes.driver.pod.featureSteps="org.apache.spark.deploy.k8s.features.VolcanoFeatureStep" \
--conf spark.kubernetes.executor.pod.featureSteps="org.apache.spark.deploy.k8s.features.VolcanoFeatureStep" \
--conf spark.kubernetes.scheduler.volcano.podGroupTemplateFile="/var/template/podgroup.yaml" \
file:///opt/spark/examples/jars/spark-examples_2.12-3.4.1.jar
{code}
In the block above, I omitted some Kubernetes configuration parameters that aren't important for this example. The parameter *{{spark.kubernetes.scheduler.volcano.podGroupTemplateFile}}* points to a file mounted in the driver container. It has a content just as the following example (cpu / memory values may vary):
{code:yaml}
apiVersion: scheduling.volcano.sh/v1beta1
kind: PodGroup
metadata: 
  name: pod-group-test
spec: 
  minResources: 
    cpu: "2"
    memory: "2Gi"
  queue: some-existing-queue
{code}
I manually verified that this file "/var/template/podgroup.yaml" exists in the container before the "spark-submit" command is issued. I also granted all the necessary RBAC permissions so that the driver pod can interact with Kubernetes objects (pods, VolcanoJobs, podgroups, queues, etc.).

When I execute this VolcanoJob, I see only the driver pod being created, and when inspecting its logs, I see the following error:
{code:java}
io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://api.<masked-environment-endpoint>/api/v1/namespaces/04522055-15b3-40d8-ba07-22b1a2a5ffcc/pods. Message: admission webhook "validatepod.volcano.sh" denied the request: failed to get PodGroup for pod <04522055-15b3-40d8-ba07-22b1a2a5ffcc/volcano-spark-1-driver-0-exec-789>: podgroups.scheduling.volcano.sh "spark-5ad570e340934d3997065fa6d504910e-podgroup" not found. Received status: Status(apiVersion=v1, code=400, details=null, kind=Status, message=admission webhook "validatepod.volcano.sh" denied the request: failed to get PodGroup for pod <04522055-15b3-40d8-ba07-22b1a2a5ffcc/volcano-spark-1-driver-0-exec-789>: podgroups.scheduling.volcano.sh "spark-5ad570e340934d3997065fa6d504910e-podgroup" not found, metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=null, status=Failure, additionalProperties={}).
	at io.fabric8.kubernetes.client.KubernetesClientException.copyAsCause(KubernetesClientException.java:238)
	at io.fabric8.kubernetes.client.dsl.internal.OperationSupport.waitForResult(OperationSupport.java:538)
	at io.fabric8.kubernetes.client.dsl.internal.OperationSupport.handleResponse(OperationSupport.java:558)
	at io.fabric8.kubernetes.client.dsl.internal.OperationSupport.handleCreate(OperationSupport.java:349)
	at io.fabric8.kubernetes.client.dsl.internal.BaseOperation.handleCreate(BaseOperation.java:711)
	at io.fabric8.kubernetes.client.dsl.internal.BaseOperation.handleCreate(BaseOperation.java:93)
	at io.fabric8.kubernetes.client.dsl.internal.CreateOnlyResourceOperation.create(CreateOnlyResourceOperation.java:42)
	at io.fabric8.kubernetes.client.dsl.internal.BaseOperation.create(BaseOperation.java:1113)
	at io.fabric8.kubernetes.client.dsl.internal.BaseOperation.create(BaseOperation.java:93)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:440)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:417)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:370)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:363)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:363)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:134)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:134)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:143)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:131)
	at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:85)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:182)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:296)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:838)
{code}
The error seems to be triggered when the driver attempts to deploy the executors of my Spark application. In the error message, it says that the podGroup "spark-5ad570e340934d3997065fa6d504910e-podgroup" cannot be found (pointed out by the Volcano admission hook).

I was expecting that the driver and executors would be assigned to the same PodGroup object, created by the VolcanoFeatureStep using the template file that I provided through the configuration parameter "{*}{{spark.kubernetes.scheduler.volcano.podGroupTemplateFile}}{*}". With that, I would have a proper batch scheduling of my Spark application, as driver and executor pods would reside in the same pod group, and would be scheduled together by Volcano. But instead, only the driver pod is deployed, and the error seen above is found on its logs.

The documentation "[Using Volcano as Customized Scheduler for Spark on Kubernetes|https://spark.apache.org/docs/latest/running-on-kubernetes.html#using-volcano-as-customized-scheduler-for-spark-on-kubernetes]" leads me to understand that by providing the PodGroup template file, my Spark application (i.e., driver and executors) would be allocated in the same PodGroup object, following the specification I provided. That doesn't seem to be the case, and it looks like the PodGroup isn't created following the provided template, nor can the executors be created.

Some more details about the environment I used:
 - Volcano Version: v1.8.0
 - Spark Version: 3.4.1
 - Kubernetes version: v1.26.7
 - Cloud provider: GCP
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Dec 11 12:35:20 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1m4bc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 11/Dec/23 12:35;lsbx96_;Just saw [https://github.com/volcano-sh/volcano/issues/3250]  - can someone please confirm that VolcanoFeatureStep doesn't support Spark in client mode? If that's the case, what would be the alternative for using Volcano with client mode deployment?;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: DiskBlockManager should check and be able to handle stale directories
Issue key: SPARK-44632
Issue id: 13545788
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: yao
Creator: yao
Created: 8/2/23 4:14
Updated: 12/11/23 0:19
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: The subDir in the memory cache could be stale, for example, after a damaged disk repair or replacement. This dir could be accessed subsequently by others. Especially,  `filename` generated by `RDDBlockId` is unchanged between task reties, so it probably attempts to access the same subDir repeatedly. Therefore, it is necessary to check if the subDir exists. If it is stale and the hardware has been recovered without data and directories, we will recreate the subDir to prevent FileNotFoundException during writing.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Aug 31 09:20:28 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jj4o:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 31/Aug/23 09:20;githubbot;User 'yaooqinn' has created a pull request for this issue:
https://github.com/apache/spark/pull/42287;;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Hide Jetty info 
Issue key: SPARK-46239
Issue id: 13560433
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: chenyu-opensource
Reporter: chenyu-opensource
Creator: chenyu-opensource
Created: 12/4/23 9:23
Updated: 12/5/23 1:38
Last Viewed: 7/17/24 20:45
Resolved: 12/4/23 22:42
Affects Version/s: 3.0.3, 3.1.3, 3.2.4, 3.3.2, 3.4.1, 3.5.0
Fix Version/s: 3.3.4, 3.4.3, 3.5.1, 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 04/Dec/23 09:23;chenyu-opensource;screenshot-1.png;https://issues.apache.org/jira/secure/attachment/13064936/screenshot-1.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 1
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Dec 04 22:42:09 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1m0rc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 04/Dec/23 09:24;chenyu-opensource;It is unsafe to expose version information.

It will obtain remote WWW service information through HTTP.;;;, 04/Dec/23 22:42;dongjoon;Issue resolved by pull request 44158
[https://github.com/apache/spark/pull/44158];;;
Affects Version/s.1: 3.1.3
Affects Version/s.2: 3.2.4
Affects Version/s.3: 3.3.2
Affects Version/s.4: 3.4.1
Comment.1: 04/Dec/23 22:42;dongjoon;Issue resolved by pull request 44158
[https://github.com/apache/spark/pull/44158];;;

Summary: Shuffle data lost on decommissioned executor caused by race condition between lastTaskRunningTime and lastShuffleMigrationTime
Issue key: SPARK-46182
Issue id: 13559998
Parent id: 
Issue Type: Task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: jiangxb1987
Reporter: jiangxb1987
Creator: jiangxb1987
Created: 11/30/23 3:09
Updated: 12/4/23 19:00
Last Viewed: 7/17/24 20:45
Resolved: 12/4/23 6:09
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 3.4.3, 3.5.1, 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: We recently identified a very tricky race condition in decommissioned node, which could lead to shuffle data lost even data migration is enabled:

* At 04:30:51, RDD block refresh happened, and found no pending works
* Shortly after that (a few milliseconds), the shutdownThread in CoarseGrainedExecutorBackend found 1 running task, so lastTaskRunningTime updated to the current system nano time
* Shortly after that, Shuffle block refresh happened, and found no pending works
* Shortly after that, a task finished on the decommissioned executor, and generated new shuffle blocks
* One second later, the shutdownThread in CoarseGrainedExecutorBackend found no running task, lastTaskRunningTime would not be updated, and the executor didn’t exit because min(lastRDDMigrationTime, lastShuffleMigrationTime) <  lastTaskRunningTime
* After 30 seconds, at 04:31:21, RDD block refresh happened, and found no pending works, lastRDDMigrationTime updated to the current system nano time
* At this exact moment, all known blocks are migrated, and min(lastRDDMigrationTime, lastShuffleMigrationTime) > lastTaskRunningTime
* shutdownThread is triggered, and asked to stop the executor
* Shuffle block refresh thread was still sleeping, and got interrupted by the stop command, so it didn’t have the chance to discover the shuffle blocks generated by the previously finished task
* Eventually, the executor exited, and the output of the task was lost, Spark need to recompute that partition

The root cause for the race condition is that the Shuffle block refresh happened between lastTaskRunningTime was updated and task finished, in that case the shutdownThread could request to stop the executor before the BlockManagerDecommissioner discover the new shuffle blocks generated by the latest finished task.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Dec 04 06:09:18 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ly2o:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 04/Dec/23 06:09;dongjoon;Issue resolved by pull request 44090
[https://github.com/apache/spark/pull/44090];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Expression encoding fails for Seq/Map of Option[Seq/Date/Timestamp/BigDecimal]
Issue key: SPARK-45896
Issue id: 13557588
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: bersprockets
Reporter: bersprockets
Creator: bersprockets
Created: 11/11/23 18:47
Updated: 12/4/23 16:27
Last Viewed: 7/17/24 20:45
Resolved: 11/12/23 22:36
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 3.4.2, 3.5.1, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: The following action fails on 3.4.1, 3.5.0, and master:
{noformat}
scala> val df = Seq(Seq(Some(Seq(0)))).toDF("a")
val df = Seq(Seq(Some(Seq(0)))).toDF("a")
org.apache.spark.SparkRuntimeException: [EXPRESSION_ENCODING_FAILED] Failed to encode a value of the expressions: mapobjects(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -1), mapobjects(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -2), assertnotnull(validateexternaltype(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -2), IntegerType, IntegerType)), unwrapoption(ObjectType(interface scala.collection.immutable.Seq), validateexternaltype(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -1), ArrayType(IntegerType,false), ObjectType(class scala.Option))), None), input[0, scala.collection.immutable.Seq, true], None) AS value#0 to a row. SQLSTATE: 42846
...
Caused by: java.lang.RuntimeException: scala.Some is not a valid external type for schema of array<int>
  at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.MapObjects_0$(Unknown Source)
...
{noformat}
However, it succeeds on 3.3.3:
{noformat}
scala> val df = Seq(Seq(Some(Seq(0)))).toDF("a")
df: org.apache.spark.sql.DataFrame = [a: array<array<int>>]

scala> df.collect
res0: Array[org.apache.spark.sql.Row] = Array([WrappedArray(WrappedArray(0))])
{noformat}
Map of Option[Seq] also fails on 3.4.1, 3.5.0, and master:
{noformat}
scala> val df = Seq(Map(0 -> Some(Seq(0)))).toDF("a")
val df = Seq(Map(0 -> Some(Seq(0)))).toDF("a")
org.apache.spark.SparkRuntimeException: [EXPRESSION_ENCODING_FAILED] Failed to encode a value of the expressions: externalmaptocatalyst(lambdavariable(ExternalMapToCatalyst_key, ObjectType(class java.lang.Object), false, -1), assertnotnull(validateexternaltype(lambdavariable(ExternalMapToCatalyst_key, ObjectType(class java.lang.Object), false, -1), IntegerType, IntegerType)), lambdavariable(ExternalMapToCatalyst_value, ObjectType(class java.lang.Object), true, -2), mapobjects(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -3), assertnotnull(validateexternaltype(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -3), IntegerType, IntegerType)), unwrapoption(ObjectType(interface scala.collection.immutable.Seq), validateexternaltype(lambdavariable(ExternalMapToCatalyst_value, ObjectType(class java.lang.Object), true, -2), ArrayType(IntegerType,false), ObjectType(class scala.Option))), None), input[0, scala.collection.immutable.Map, true]) AS value#0 to a row. SQLSTATE: 42846
...
Caused by: java.lang.RuntimeException: scala.Some is not a valid external type for schema of array<int>
  at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.MapObjects_0$(Unknown Source)
...
{noformat}
As with the first example, this succeeds on 3.3.3:
{noformat}
scala> val df = Seq(Map(0 -> Some(Seq(0)))).toDF("a")
df: org.apache.spark.sql.DataFrame = [a: map<int,array<int>>]

scala> df.collect
res0: Array[org.apache.spark.sql.Row] = Array([Map(0 -> WrappedArray(0))])
{noformat}
Other cases the fail on 3.4.1, 3.5.0, and master but work fine on 3.3.3:
- {{Seq[Option[Timestamp]]}}
- {{Map[Option[Timestamp]]}}
- {{Seq[Option[Date]]}}
- {{Map[Option[Date]]}}
- {{Seq[Option[BigDecimal]]}}
- {{Map[Option[BigDecimal]]}}

However, the following work fine on 3.3.3, 3.4.1, 3.5.0, and master:

- {{Seq[Option[Map]]}}
- {{Map[Option[Map]]}}
- {{Seq[Option[<primitive-type>]]}}
- {{Map[Option[<primitive-type>]]}}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): SPARK-45644
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sat Nov 11 23:02:30 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ljjc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 11/Nov/23 23:02;bersprockets;I think I have a handle on this and will make a PR shortly.;;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: CONV produces incorrect result near Long.MIN_VALUE, fails to detect overflow
Issue key: SPARK-44943
Issue id: 13548480
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: jira.shegalov
Creator: jira.shegalov
Created: 8/24/23 7:49
Updated: 12/4/23 0:19
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Signed conversion does not detect overflow 
{code:java}
>>> spark.conf.set('spark.sql.ansi.enabled', True)
>>> sql("SELECT conv('-9223372036854775809', 10, -10)").show(truncate=False)
+-----------------------------------+
|conv(-9223372036854775809, 10, -10)|
+-----------------------------------+
|-9223372036854775807               |
+-----------------------------------+
{code}

Unsigned conversion produces -1 but does not throw in the ANSI mode
{code}
>>> sql("SELECT conv('-9223372036854775809', 10, 10)").show(truncate=False)
+----------------------------------+
|conv(-9223372036854775809, 10, 10)|
+----------------------------------+
|18446744073709551615              |
+----------------------------------+
{code}

Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Aug 24 09:20:15 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jzdk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 24/Aug/23 09:19;githubbot;User 'gerashegalov' has created a pull request for this issue:
https://github.com/apache/spark/pull/42652;;;, 24/Aug/23 09:20;githubbot;User 'gerashegalov' has created a pull request for this issue:
https://github.com/apache/spark/pull/42652;;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 4.0.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 24/Aug/23 09:20;githubbot;User 'gerashegalov' has created a pull request for this issue:
https://github.com/apache/spark/pull/42652;;;

Summary: Various Pandas functions fail in interpreted mode
Issue key: SPARK-46189
Issue id: 13560133
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: bersprockets
Reporter: bersprockets
Creator: bersprockets
Created: 11/30/23 21:58
Updated: 12/1/23 2:31
Last Viewed: 7/17/24 20:45
Resolved: 12/1/23 2:29
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 3.4.3, 3.5.1, 4.0.0
Component/s: Pandas API on Spark, SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Various Pandas functions ({{kurt}}, {{var}}, {{skew}}, {{cov}}, and {{stddev}}) fail with an unboxing-related exception when run in interpreted mode.

Here are some reproduction cases for pyspark interactive mode:
{noformat}
spark.sql("set spark.sql.codegen.wholeStage=false")
spark.sql("set spark.sql.codegen.factoryMode=NO_CODEGEN")

import numpy as np
import pandas as pd

import pyspark.pandas as ps

pser = pd.Series([1, 2, 3, 7, 9, 8], index=np.random.rand(6), name="a")
psser = ps.from_pandas(pser)

# each of the following actions gets an unboxing error
psser.kurt()
psser.var()
psser.skew()

# set up for covariance test
pdf = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)], columns=["a", "b"])
psdf = ps.from_pandas(pdf)

# this gets an unboxing error
psdf.cov()

# set up for stddev resr
from pyspark.pandas.spark import functions as SF
from pyspark.sql.functions import col
from pyspark.sql import Row
df = spark.createDataFrame([Row(a=1), Row(a=2), Row(a=3), Row(a=7), Row(a=9), Row(a=8)])

# this gets an unboxing error
df.select(SF.stddev(col("a"), 1)).collect()
{noformat}
Exception from the first case ({{psser.kurt()}}) is
{noformat}
java.lang.ClassCastException: class java.lang.Integer cannot be cast to class java.lang.Double (java.lang.Integer and java.lang.Double are in module java.base of loader 'bootstrap')
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:112)
	at org.apache.spark.sql.catalyst.types.PhysicalDoubleType$$anonfun$2.compare(PhysicalDataType.scala:184)
	at scala.math.Ordering.lt(Ordering.scala:98)
	at scala.math.Ordering.lt$(Ordering.scala:98)
	at org.apache.spark.sql.catalyst.types.PhysicalDoubleType$$anonfun$2.lt(PhysicalDataType.scala:184)
	at org.apache.spark.sql.catalyst.expressions.LessThan.nullSafeEval(predicates.scala:1196)
{noformat}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Dec 01 02:29:54 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lywo:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 01/Dec/23 02:29;podongfeng;Issue resolved by pull request 44099
[https://github.com/apache/spark/pull/44099];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: ANSI Double quoted identifiers do not work in Python threads
Issue key: SPARK-46190
Issue id: 13560134
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: mpayson
Creator: mpayson
Created: 11/30/23 22:30
Updated: 11/30/23 22:30
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.0, 3.4.1, 3.5.0
Fix Version/s: 
Component/s: PySpark
Due Date: 
Votes: 0
Labels: ansi-sql, python, threads
Description: Enabling and using `spark.sql.ansi.doubleQuotedIdentifiers` does not work correctly in Python threads

The following example shows how applying a filter, "\"status\" = 'Unchanged'", leads to empty results when run in a thread. I believe this is because the "status" field is interpreted as a literal in the thread, but as an attribute outside of it.
{code:python}
from concurrent import futures
from pyspark import sql

spark = (
  sql.SparkSession.builder.master("local[*]")
  .config("spark.sql.ansi.enabled", "true")
  .config("spark.sql.ansi.doubleQuotedIdentifiers", "true")
  .getOrCreate()
)

def demonstrate_issue(spark):
  # Path to JSON file with contents:
  # [{"status": "Unchanged"}, {"status": "Changed"}]
  df = spark.read.json("data/example.json")
  df.filter("\"status\" = 'Unchanged'").show()

# Shows 1 record, expected
demonstrate_issue(spark)

with futures.ThreadPoolExecutor(1) as executor:
  # Shows 0 records, unexpected
  executor.submit(demonstrate_issue, spark)
 {code}
 

Additional testing notes:
 * When parsing the expression with `sql.functions.expr` in Java via Py4J, the "status" field is interpreted as a literal value from the thread, not an attribute
 * Using double quotes with `spark.sql` does work in the thread
 * Using a dataframe created in memory does work in the thread
 * Tested in versions 3.4.0, 3.4.1, & 3.5.0 on Windows and Mac

 

The original PR that added this option is here: [https://github.com/apache/spark/pull/38022]

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 30:57.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lyww:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: can't return prediction that has different length than ml input
Issue key: SPARK-46175
Issue id: 13559971
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: rbavery
Creator: rbavery
Created: 11/29/23 19:15
Updated: 11/29/23 19:16
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: MLlib, PySpark
Due Date: 
Votes: 0
Labels: 
Description: I'm using

 
from pyspark.ml.functions import predict_batch_udf
to construct a pandas udf that runs a computer vision model to predict classification labels for images. The model takes a 4D array as input and returns a 4D array as output (Batch, Channels, Height, Width)
 
However I'd like to run some additional processing in the pandas_udf to convert the 4D output array (floats) to text labels since this is a more useful output and we are trying to register pandas_udfs ahead of time for spark.sql users.
 
 
When I set the return type to a StringType though I get an error
 
```
23/11/29 02:43:04 WARN TaskSetManager: Lost task 0.0 in stage 8.0 (TID 16) (172.18.0.2 executor 0): org.apache.spark.api.python.PythonException: Traceback (most recent call last): File "/opt/spark/python/pyspark/ml/functions.py", line 809, in predict yield _validate_and_transform_prediction_result( File "/opt/spark/python/lib/pyspark.zip/pyspark/ml/functions.py", line 331, in _validate_and_transform_prediction_result raise ValueError("Prediction results must have same length as input data.") ValueError: Prediction results must have same length as input data.
```
 
This seems like an unnecessary limitation, since it is common for ML models, especially in computer vision, to take input shapes different from output shapes.
 
I think the issue is here: [https://spark.apache.org/docs/latest/api/python/_modules/pyspark/ml/functions.html]
 
Can this check that enforces same shape be removed?
 
 
to illustrate the problem, here are my StructTypes. The Raw one works but the Str one does not
 
```
from collections import namedtuple
from pyspark.sql.types import ArrayType, IntegerType, StringType,StructType, StructField, FloatType

Task = namedtuple('TaskSchema', ['inference_input', 'inference_result'])

SingleLabelClassificationRaw = Task(
inference_input=StructType([
StructField("array", ArrayType(IntegerType()), nullable=False),
StructField("shape", ArrayType(IntegerType()), nullable=False)
]),
inference_result=ArrayType(FloatType())
)

SingleLabelClassificationStr = Task(
inference_input=StructType([
StructField("array", ArrayType(IntegerType()), nullable=False),
StructField("shape", ArrayType(IntegerType()), nullable=False)
]),
inference_result=StringType()
)
```
Environment: I'm on spark 3.4
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 15:14.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lxwo:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: YarnAllocator miss clean targetNumExecutorsPerResourceProfileId after YarnSchedulerBackend call stop
Issue key: SPARK-46006
Issue id: 13558671
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: angerszhuuu
Reporter: angerszhuuu
Creator: angerszhuuu
Created: 11/20/23 9:53
Updated: 11/28/23 3:06
Last Viewed: 7/17/24 20:45
Resolved: 11/22/23 8:52
Affects Version/s: 3.1.3, 3.2.4, 3.3.2, 3.4.1, 3.5.0
Fix Version/s: 3.3.4, 3.4.2, 3.5.1, 4.0.0
Component/s: YARN
Due Date: 
Votes: 0
Labels: pull-request-available
Description: We meet a case that user call sc.stop() after run all custom code, but stuck in some place. 

Cause below situation
 # User call sc.stop()
 # sc.stop() stuck in some process, but SchedulerBackend.stop was called
 # Since tarn ApplicationMaster didn't finish， still call YarnAllocator.allocateResources()
 # Since driver endpoint stop new allocated executor failed to register
 # untll trigger Max number of executor failures

Caused by 

Before call CoarseGrainedSchedulerBackend.stop() will call YarnSchedulerBackend.requestTotalExecutor() to clean request info

!image-2023-11-20-17-56-56-507.png|width=898,height=297!

 

From the log we make sure that CoarseGrainedSchedulerBackend.stop()  was called

 

 

When YarnAllocator handle then empty resource request,  since resourceTotalExecutorsWithPreferedLocalities is empty, miss clean targetNumExecutorsPerResourceProfileId.

!image-2023-11-20-17-56-45-212.png|width=708,height=379!

 

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 20/Nov/23 09:56;angerszhuuu;image-2023-11-20-17-56-45-212.png;https://issues.apache.org/jira/secure/attachment/13064567/image-2023-11-20-17-56-45-212.png, 20/Nov/23 09:56;angerszhuuu;image-2023-11-20-17-56-56-507.png;https://issues.apache.org/jira/secure/attachment/13064568/image-2023-11-20-17-56-56-507.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 2
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Nov 22 08:52:36 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lpwo:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 22/Nov/23 08:52;yao;Issue resolved by pull request 43906
[https://github.com/apache/spark/pull/43906];;;
Affects Version/s.1: 3.2.4
Affects Version/s.2: 3.3.2
Affects Version/s.3: 3.4.1
Affects Version/s.4: 3.5.0
Comment.1:

Summary: Add support for MSK IAM to the kafka connector
Issue key: SPARK-44285
Issue id: 13542351
Parent id: 
Issue Type: New Feature
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: nihal.pot
Creator: nihal.pot
Created: 7/3/23 23:18
Updated: 11/27/23 14:59
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Structured Streaming
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Managed Streaming for Kafka (MSK) is a fully managed service offered by Amazon Web Services (AWS) that simplifies the deployment, management, and scaling of Apache Kafka clusters. Kafka is an open-source streaming platform widely used for building real-time data pipelines and streaming applications. MSK provides a managed environment for running Kafka clusters, reducing the operational overhead associated with self-managing Kafka infrastructure.

Currently when we connect to MSK using spark, users would have to install an external library and then try to connect with MSK IAM auth. To simplify this for users, we can add this as a dependency directly to Spark and then users can connect to it by simply specifying the class paths directly.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Jul 03 23:19:27 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ixzs:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 03/Jul/23 23:19;nihal.pot;Working on it in [https://github.com/apache/spark/pull/41791] ;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Restore documentation for DSv2 API
Issue key: SPARK-45963
Issue id: 13558315
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: gurwls223
Reporter: gurwls223
Creator: gurwls223
Created: 11/16/23 23:53
Updated: 11/24/23 3:49
Last Viewed: 7/17/24 20:45
Resolved: 11/17/23 21:04
Affects Version/s: 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.4.2, 3.5.1, 4.0.0
Component/s: Documentation, SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: DSv2 documentation is mistakenly gone after https://github.com/apache/spark/pull/38392. It used to exist in 3.3.0: https://spark.apache.org/docs/3.3.0/api/scala/org/apache/spark/sql/connector/catalog/index.html
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Nov 17 21:04:34 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lo0w:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 17/Nov/23 21:04;dongjoon;Issue resolved by pull request 43865
[https://github.com/apache/spark/pull/43865];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 4.0.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: CTE reference node does not inherit the flag `isStreaming` from CTE definition node
Issue key: SPARK-46062
Issue id: 13559131
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: kabhwan
Reporter: kabhwan
Creator: kabhwan
Created: 11/23/23 2:28
Updated: 11/23/23 14:33
Last Viewed: 7/17/24 20:45
Resolved: 11/23/23 14:33
Affects Version/s: 3.3.2, 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.4.2, 3.5.1, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Looks like this is a long standing bug.

We figured out that CTE reference node would never set the isStreaming flag to true, regardless of the value for flag in CTE definition. The node cannot determine the right value of isStreaming flag by itself (likewise it cannot determine about resolution by itself) but it has no parameter in constructor, hence always takes the default (no children, so batch one).

This may impact some rules which behaves differently depending on isStreaming flag. It would no longer be a problem once CTE reference is replaced with CTE definition at some point in "optimization phase", but all rules in analyzer and optimizer being triggered before the rule takes effect may be impacted.

We probably couldn't sync the flag in real time, but we should sync the flag when we mark CTE reference to be "resolved". The rule `ResolveWithCTE` will be a good place to do that.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Nov 23 14:33:11 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lsqg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 23/Nov/23 02:28;kabhwan;Working on the PR. Will submit a PR sooner.;;;, 23/Nov/23 14:33;kabhwan;Issue resolved by pull request 43966
[https://github.com/apache/spark/pull/43966];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 4.0.0
Affects Version/s.4: 
Comment.1: 23/Nov/23 14:33;kabhwan;Issue resolved by pull request 43966
[https://github.com/apache/spark/pull/43966];;;

Summary: EliminateEventTimeWatermark does not consider the fact that isStreaming flag can change for current child during resolution
Issue key: SPARK-46064
Issue id: 13559147
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: kabhwan
Reporter: kabhwan
Creator: kabhwan
Created: 11/23/23 5:05
Updated: 11/23/23 11:26
Last Viewed: 7/17/24 20:45
Resolved: 11/23/23 11:26
Affects Version/s: 3.3.2, 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.4.2, 3.5.1, 4.0.0
Component/s: Structured Streaming
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Looks like this is a long standing bug.

The object `EliminateEventTimeWatermark` is implemented as a rule, but it is not registered in analyzer/optimizer. Instead, it is called directly when withWatermark method is called, which means the rule is applied immediately against the child, regardless whether child is resolved or not.

It is not an issue for the usage of pure DataFrame API because streaming sources have the flag isStreaming set to true even it is yet resolved, but mix-up of SQL and DataFrame API would expose the issue; we may not know the exact value of isStreaming flag on unresolved node and it is subject to change upon resolution.

We should register EliminateEventTimeWatermark as a rule on analysis (or pre-optimization) instead, and do not apply the elimination if the child is not yet resolved.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Nov 23 11:26:38 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lsu0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 23/Nov/23 11:26;kabhwan;Issue resolved by pull request 43971
[https://github.com/apache/spark/pull/43971];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 4.0.0
Affects Version/s.4: 
Comment.1:

Summary: EventLogFileReader should not read rolling logs if appStatus is missing
Issue key: SPARK-46012
Issue id: 13558753
Parent id: 13557406
Issue Type: Sub-task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: dongjoon
Reporter: dongjoon
Creator: dongjoon
Created: 11/20/23 20:59
Updated: 11/22/23 3:27
Last Viewed: 7/17/24 20:45
Resolved: 11/21/23 1:53
Affects Version/s: 3.0.0, 3.1.3, 3.2.4, 3.3.3, 3.4.1
Fix Version/s: 3.3.4, 3.4.2, 3.5.1, 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Nov 21 01:53:14 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lqew:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 21/Nov/23 01:53;dongjoon;Issue resolved by pull request 43914
[https://github.com/apache/spark/pull/43914];;;
Affects Version/s.1: 3.1.3
Affects Version/s.2: 3.2.4
Affects Version/s.3: 3.3.3
Affects Version/s.4: 3.4.1
Comment.1:

Summary: Plugin API for PySpark and SparkR workers
Issue key: SPARK-44767
Issue id: 13546881
Parent id: 
Issue Type: New Feature
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: rshkv
Creator: rshkv
Created: 8/10/23 21:41
Updated: 11/22/23 0:19
Last Viewed: 7/17/24 20:42
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: An API to customize Python and R workers allows for extensibility beyond what can be expressed via static configs and environment variables like, e.g., {{spark.pyspark.python}}.

A use case for this is overriding {{PATH}} when using {{spark.archives}} with, say, conda-pack (as documented [here|https://spark.apache.org/docs/3.1.1/api/python/user_guide/python_packaging.html#using-conda]). Some packages rely on binaries. And if we want to use those packages in Spark, we need to include their binaries in the {{PATH}}.

But we can't set the {{PATH}} via some config because 1) the environment with its binaries may be at a dynamic location (archives are unpacked on the driver [into a directory with random name|https://github.com/apache/spark/blob/5db87787d5cc1cefb51ec77e49bac7afaa46d300/core/src/main/scala/org/apache/spark/SparkFiles.scala#L33-L37]), and 2) we may not want to override the {{PATH}} that's pre-configured on the hosts.

Other use cases unlocked by this include overriding the executable dynamically (e.g., to select a version) or forking/redirecting the worker's output stream.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Nov 21 10:48:02 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jpvk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 4.0.0
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 10/Aug/23 22:16;rshkv;I put up a proposal implementation here: https://github.com/apache/spark/pull/42440;;;, 21/Nov/23 10:48;rshkv;[~gurwls223], curious what you think about this proposal. I know you're leaning towards dynamic environment selection for Spark Connect [(apache/spark#41215)|https://github.com/apache/spark/pull/41215] instead of relying on a single environment per Spark application or per host. 

At Palantir, we use conda-pack based environments with {{spark.archives}}. But that wasn't sufficient to make native library dependencies work. Internally, we implemented a {{ProcessBuilder}} plugin (using the [proposed API|https://github.com/apache/spark/pull/42440]). Among other things we use it to append the environment's {{bin/}} to the process' {{PATH}} variable or to discover Python module and non-Python binary locations outside the packaged environment.;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 21/Nov/23 10:48;rshkv;[~gurwls223], curious what you think about this proposal. I know you're leaning towards dynamic environment selection for Spark Connect [(apache/spark#41215)|https://github.com/apache/spark/pull/41215] instead of relying on a single environment per Spark application or per host. 

At Palantir, we use conda-pack based environments with {{spark.archives}}. But that wasn't sufficient to make native library dependencies work. Internally, we implemented a {{ProcessBuilder}} plugin (using the [proposed API|https://github.com/apache/spark/pull/42440]). Among other things we use it to append the environment's {{bin/}} to the process' {{PATH}} variable or to discover Python module and non-Python binary locations outside the packaged environment.;;;

Summary: Fix ArrayIndexOutOfBoundsException in conv()
Issue key: SPARK-44973
Issue id: 13548693
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: markj-db
Reporter: jira.shegalov
Creator: jira.shegalov
Created: 8/25/23 21:05
Updated: 11/21/23 22:16
Last Viewed: 7/17/24 20:45
Resolved: 11/21/23 19:39
Affects Version/s: 3.0.3, 3.3.3, 3.4.1, 3.5.0
Fix Version/s: 3.3.4, 3.4.2, 3.5.1, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
{code:scala}
scala> sql(s"SELECT CONV('${Long.MinValue}', 10, -2)").show(false)
java.lang.ArrayIndexOutOfBoundsException: -1
  at org.apache.spark.sql.catalyst.util.NumberConverter$.convert(NumberConverter.scala:183)
  at org.apache.spark.sql.catalyst.expressions.Conv.nullSafeEval(mathExpressions.scala:463)
  at org.apache.spark.sql.catalyst.expressions.TernaryExpression.eval(Expression.scala:821)
  at org.apache.spark.sql.catalyst.expressions.ToPrettyString.eval(ToPrettyString.scala:57)
  at org.apache.spark.sql.catalyst.optimizer.ConstantFolding$.org$apache$spark$sql$catalyst$optimizer$ConstantFolding$$constantFolding(expressions.scala:81)
  at org.apache.spark.sql.catalyst.optimizer.ConstantFolding$.$anonfun$constantFolding$4(expressions.scala:91)
{code}

Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Nov 21 22:16:01 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k0ow:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 18/Nov/23 05:52;dongjoon;I added 3.3.3 to the `Affected Version`.
{code}
scala> spark.version
res1: String = 3.3.3

scala> sql(s"SELECT CONV('${Long.MinValue}', 10, -2)").show(false)
java.lang.ArrayIndexOutOfBoundsException: -1
{code};;;, 19/Nov/23 16:15;markj-db;I believe it's affected back to 3.2.0: https://github.com/apache/spark/blob/v3.2.0/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/util/NumberConverter.scala#L131;;;, 20/Nov/23 21:29;jira.shegalov;3.0.3 is the oldest version on my box and it exhibits the same bug:

 
{code:java}
scala> spark.version
res1: String = 3.0.3
scala> sql(s"SELECT CONV('${Long.MinValue}', 10, -2)").show(false)
java.lang.ArrayIndexOutOfBoundsException: -1
  at org.apache.spark.sql.catalyst.util.NumberConverter$.convert(NumberConverter.scala:148)
  at org.apache.spark.sql.catalyst.expressions.Conv.nullSafeEval(mathExpressions.scala:338)
  at org.apache.spark.sql.catalyst.expressions.TernaryExpression.eval(Expression.scala:690)
  at org.apache.spark.sql.catalyst.expressions.UnaryExpression.eval(Expression.scala:457)
{code}
 ;;;, 21/Nov/23 19:39;dongjoon;Issue resolved by pull request 43880
[https://github.com/apache/spark/pull/43880];;;, 21/Nov/23 22:16;markj-db;Hmm, possibly it goes back to Spark 2.1.0 due to this line:

[https://github.com/apache/spark/commit/95db8a44f3e2d79913cbe0d29297796b4c3b0d1b#diff-924be5a0a35024a5f63a1411b1a4c3000150356ab59f12eda84fada0659514a2R135]
{code:java}
val temp = new Array[Byte](64){code}
I was looking only for the earliest version with

[https://github.com/apache/spark/commit/c5b0cb2d945437a998c35917bbc9d653883244db#diff-924be5a0a35024a5f63a1411b1a4c3000150356ab59f12eda84fada0659514a2R131]
{code:java}
val temp = new Array[Byte](Math.max(n.length, 64)){code};;;
Affects Version/s.1: 3.3.3
Affects Version/s.2: 3.4.1
Affects Version/s.3: 3.5.0
Affects Version/s.4: 
Comment.1: 19/Nov/23 16:15;markj-db;I believe it's affected back to 3.2.0: https://github.com/apache/spark/blob/v3.2.0/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/util/NumberConverter.scala#L131;;;

Summary: support grouping set operation in dataframe api
Issue key: SPARK-45929
Issue id: 13557994
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: JacobZheng
Reporter: JacobZheng
Creator: JacobZheng
Created: 11/15/23 2:58
Updated: 11/21/23 1:41
Last Viewed: 7/17/24 20:45
Resolved: 11/21/23 1:41
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: I am using spark dataframe api for complex calculations. When I need to use the grouping sets function, I can only convert the expression to sql via analyzedPlan and then splice these sql into a complex sql to execute. In some cases, this operation generates an extremely complex sql. executing this complex sql, antlr4 continues to consume a large amount of memory, similar to a memory leak scenario. If you can and rollup, cube function through the dataframe api to calculate these operations will be much simpler.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Nov 21 01:41:35 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lm1k:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 21/Nov/23 01:41;gurwls223;Issue resolved by pull request 43813
[https://github.com/apache/spark/pull/43813];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Add logging for complete write events to file in EventLogFileWriter.closeWriter
Issue key: SPARK-44699
Issue id: 13546298
Parent id: 
Issue Type: Task
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: shuyouZZ
Creator: shuyouZZ
Created: 8/7/23 6:52
Updated: 11/17/23 0:18
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Sometimes we want to know when to finish logging the events to eventLog file, we need add a log to make it clearer.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Aug 08 16:52:49 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jma0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 08/Aug/23 16:52;hudson;User 'shuyouZZ' has created a pull request for this issue:
https://github.com/apache/spark/pull/42372;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Support deserializing long fields into `Metadata` object
Issue key: SPARK-44488
Issue id: 13544207
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: richardc-db
Reporter: richardc-db
Creator: richardc-db
Created: 7/20/23 3:10
Updated: 11/16/23 2:45
Last Viewed: 7/17/24 20:45
Resolved: 8/3/23 3:08
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Aug 03 03:08:35 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j9e0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 03/Aug/23 03:08;gurwls223;Issue resolved by pull request 42083
[https://github.com/apache/spark/pull/42083];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Refactor the optimizer plan validation to decouple validateSchemaOutput and validateExprIdUniqueness
Issue key: SPARK-45892
Issue id: 13557543
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: xiliang678
Reporter: xiliang678
Creator: xiliang678
Created: 11/10/23 22:26
Updated: 11/13/23 21:28
Last Viewed: 7/17/24 20:45
Resolved: 11/13/23 21:28
Affects Version/s: 3.4.0, 3.4.1
Fix Version/s: 4.0.0
Component/s: Optimizer
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Currently, the expressionIDUniqueness validation is closely coupled with output schema validation. 

https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/plans/logical/LogicalPlan.scala#L403C7-L411C8

Some refactoring can improve readability and reuse.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Nov 13 21:28:36 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lj9k:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 10/Nov/23 23:22;xiliang678;cc [~cloud_fan] here's the PR [https://github.com/apache/spark/pull/43761] PTAL, thanks!;;;, 13/Nov/23 21:28;cloud_fan;Issue resolved by pull request 43761
[https://github.com/apache/spark/pull/43761];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 13/Nov/23 21:28;cloud_fan;Issue resolved by pull request 43761
[https://github.com/apache/spark/pull/43761];;;

Summary: Number check for InputFileBlockSources is missing for V2 source (BatchScan) ?
Issue key: SPARK-45879
Issue id: 13557463
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: firestarmanllc
Creator: firestarmanllc
Created: 11/10/23 8:57
Updated: 11/13/23 15:16
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.2.3, 3.4.1, 3.5.0
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: When doing a join with the "input_file_name()" function, it will blow up with a

*AnalysisException* if using the v1 data source (FileSourceScan). That's ok.

 

But if we change to use the v2 data source (BatchScan), the expected exception is gone, and the join passes.

Is this number check for InputFileDataSources mssing for V2 data source ? or is it by design ?

 

Repro steps:
{code:java}
scala> spark.range(100).withColumn("const1", lit("from_t1")).write.parquet("/data/tmp/t1")
 
scala> spark.range(100).withColumn("const2", lit("from_t2")).write.parquet("/data/tmp/t2")
 
scala> spark.conf.set("spark.sql.sources.useV1SourceList", "parquet")
 
scala> spark.read.parquet("/data/tmp/t1").join(spark.read.parquet("/data/tmp/t2"), "id", "inner").selectExpr("*", "input_file_name()").show(5, false)
org.apache.spark.sql.AnalysisException: 'input_file_name' does not support more than one sources.; line 1 pos 0;
Project id#376L, const1#377, const2#381, input_file_name() AS input_file_name()#389
+- Project id#376L, const1#377, const2#381
   +- Join Inner, (id#376L = id#380L)
      :- Relation id#376L,const1#377 parquet
      +- Relation id#380L,const2#381 parquet
 
  at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:52)
  at org.apache.spark.sql.execution.datasources.PreReadCheck$.org$apache$spark$sql$execution$datasources$PreReadCheck$$checkNumInputFileBlockSources(rules.scala:476)
  at org.apache.spark.sql.execution.datasources.PreReadCheck$.$anonfun$checkNumInputFileBlockSources$2(rules.scala:472)
  at org.apache.spark.sql.execution.datasources.PreReadCheck$.$anonfun$checkNumInputFileBlockSources$2$adapted(rules.scala:472)
  at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
  at scala.collection.Iterator.foreach(Iterator.scala:943)
  at scala.collection.Iterator.foreach$(Iterator.scala:943)
  at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
  at scala.collection.IterableLike.foreach(IterableLike.scala:74)
  at scala.collection.IterableLike.foreach$(IterableLike.scala:73)

scala> spark.conf.set("spark.sql.sources.useV1SourceList", "")
 
scala> spark.read.parquet("/data/tmp/t1").join(spark.read.parquet("/data/tmp/t2"), "id", "inner").selectExpr("*", "input_file_name()").show(5, false)
+---+-------+-------+---------------------------------------------------------------------------------------+
|id |const1 |const2 |input_file_name()                                                                      |
+---+-------+-------+---------------------------------------------------------------------------------------+
|91 |from_t1|from_t2|file:///data/tmp/t1/part-00011-a52b9990-4463-447c-9cdf-7a84542de2f7-c000.snappy.parquet|
|92 |from_t1|from_t2|file:///data/tmp/t1/part-00011-a52b9990-4463-447c-9cdf-7a84542de2f7-c000.snappy.parquet|
|93 |from_t1|from_t2|file:///data/tmp/t1/part-00011-a52b9990-4463-447c-9cdf-7a84542de2f7-c000.snappy.parquet|
|94 |from_t1|from_t2|file:///data/tmp/t1/part-00011-a52b9990-4463-447c-9cdf-7a84542de2f7-c000.snappy.parquet|
|95 |from_t1|from_t2|file:///data/tmp/t1/part-00011-a52b9990-4463-447c-9cdf-7a84542de2f7-c000.snappy.parquet|
+---+-------+-------+---------------------------------------------------------------------------------------+
only showing top 5 rows{code}
Environment: I tried on Spark 323 and Spark 341, and both can reproduce this issue.
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 57:20.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lirs:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: current_date() not supported in Streaming Query Observed metrics
Issue key: SPARK-45655
Issue id: 13555397
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: bhuwan.sahni
Reporter: bhuwan.sahni
Creator: bhuwan.sahni
Created: 10/24/23 20:48
Updated: 11/12/23 21:44
Last Viewed: 7/17/24 20:45
Resolved: 11/12/23 7:50
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 4.0.0
Component/s: Structured Streaming
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Streaming queries do not support current_date() inside CollectMetrics. The primary reason is that current_date() (resolves to CurrentBatchTimestamp) is marked as non-deterministic. However, {{current_date}} and {{current_timestamp}} are both deterministic today, and {{current_batch_timestamp}} should be the same.

 

As an example, the query below fails due to observe call on the DataFrame.

 
{quote}val inputData = MemoryStream[Timestamp]

inputData.toDF()
      .filter("value < current_date()")
      .observe("metrics", count(expr("value >= current_date()")).alias("dropped"))
      .writeStream
      .queryName("ts_metrics_test")
      .format("memory")
      .outputMode("append")
      .start()
{quote}
 
Environment: 
Log Work: 
Original Estimate: 172800
Remaining Estimate: 172800
Time Spent: 
Work Ratio: 0%
Σ Original Estimate: 172800
Σ Remaining Estimate: 172800
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sun Nov 12 07:50:29 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1l614:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 24/Oct/23 20:48;bhuwan.sahni;I am working on a fix for this issue, and will submit a PR soon.;;;, 24/Oct/23 22:21;bhuwan.sahni;PR link https://github.com/apache/spark/pull/43517;;;, 12/Nov/23 07:50;kabhwan;Issue resolved by pull request 43517
[https://github.com/apache/spark/pull/43517];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 24/Oct/23 22:21;bhuwan.sahni;PR link https://github.com/apache/spark/pull/43517;;;

Summary: java.lang.NoClassDefFoundError: javax/servlet/Servlet incompatibilities upgrading springboot-dependencies 2.7 to 3.* (package javax.* -> jakarta.*)
Issue key: SPARK-45897
Issue id: 13557623
Parent id: 
Issue Type: Dependency upgrade
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: arnaud.nauwynck
Creator: arnaud.nauwynck
Created: 11/12/23 18:10
Updated: 11/12/23 18:22
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.2.4, 3.3.3, 3.4.0, 3.4.1, 3.5.0
Fix Version/s: 
Component/s: Web UI
Due Date: 
Votes: 0
Labels: 
Description: updating springboot-dependencies 2.7 to 3.1 breaks spark with springboot compatibilities.


{noformat}
    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-dependencies</artifactId>
                <version>2.7.14</version> <!-- OK 2.7.* works fine, but  3.* ERROR --> 
                <type>pom</type>
                <scope>import</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>
{noformat}

Internally, everything compile ok, but fail at runtime while creating the SparkSession, with SparkUI:


{noformat}
Caused by: java.lang.NoClassDefFoundError: javax/servlet/Servlet
	at org.apache.spark.ui.SparkUI$.create(SparkUI.scala:239) ~[spark-core_2.13-3.5.0.jar:3.5.0]
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:503) ~[spark-core_2.13-3.5.0.jar:3.5.0]
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2888) ~[spark-core_2.13-3.5.0.jar:3.5.0]
	at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1099) ~[spark-sql_2.13-3.5.0.jar:3.5.0]
	at scala.Option.getOrElse(Option.scala:201) ~[scala-library-2.13.8.jar:na]
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1093) ~[spark-sql_2.13-3.5.0.jar:3.5.0]
....

Caused by: java.lang.ClassNotFoundException: javax.servlet.Servlet
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641) ~[na:na]
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188) ~[na:na]
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:521) ~[na:na]
	... 49 common frames omitted

{noformat}

Root cause: major change with springboot 3: 'javax.servlet.Servlet' class is NO more defined in package 'javax.servlet.', but migrated to 'jakarta.servlet.'

The compiled dependency from spark-core to javax-servlet-api is replaced by maven dependencyManagement


It "might be" possible to get rid of maven dependencyManagement or to override several artifact versions, but it is NOT PRACTICAL.

Here is a version that work, much more complex  with springboot3 than springboot2.

It requires few of forced versions, and exclusions in maven.

    
{noformat}
<properties>
        <spark.version>3.5.0</spark.version>
        <scala.version>2.13</scala.version>
    </properties>

    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-dependencies</artifactId>
                <version>3.1.2</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
            <dependency>
                <groupId>org.glassfish.jersey.containers</groupId>
                <artifactId>jersey-container-servlet-core</artifactId>
                <version>2.41</version>
            </dependency>
            <dependency>
                <groupId>org.slf4j</groupId>
                <artifactId>slf4j-api</artifactId>
                <version>2.0.9</version>
            </dependency>
        </dependencies>
    </dependencyManagement>

    <dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_${scala.version}</artifactId>
            <version>${spark.version}</version>
            <exclusions>
                <exclusion>
                    <groupId>org.apache.logging.log4j</groupId>
                    <artifactId>log4j-slf4j2-impl</artifactId>
                </exclusion>
            </exclusions>
        </dependency>

        <dependency>
            <groupId>jakarta.servlet</groupId>
            <artifactId>jakarta.servlet-api</artifactId>
            <version>4.0.4</version>
        </dependency>

    </dependencies>
{noformat}


there are several examples showing errors and fixed for servlet, log4j, glassfish incompatibilities here as jira attachment, or directly from github: https://github.com/Arnaud-Nauwynck/test-snippets/tree/master/test-springboot-spark



A possible long term solution is to migrate to servlet in package "jakarta.servlet." instead of "javax.servlet." as springboot already did, so there would "not (?)" be incompatibilities between very old and much more recent jars.

Any roadmap for this?





Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 12/Nov/23 18:21;arnaud.nauwynck;test-springboot-spark.zip;https://issues.apache.org/jira/secure/attachment/13064353/test-springboot-spark.zip
Custom field (Affects version (Component)): 
Custom field (Attachment count): 1
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 10:54.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ljr4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.3.3
Affects Version/s.2: 3.4.0
Affects Version/s.3: 3.4.1
Affects Version/s.4: 3.5.0
Comment.1:

Summary: When a task failed and the inferred task for that task is still executing, the number of dynamically scheduled executors will be calculated incorrectly
Issue key: SPARK-44179
Issue id: 13541302
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: liangyongyuan
Creator: liangyongyuan
Created: 6/25/23 11:14
Updated: 11/11/23 0:17
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Assuming a stage has Task 1, with Task 1.0 and a speculative task Task 1.1 running concurrently, the dynamic scheduler calculates the number of executors as 2 (pendingTask: 0, pendingSpeculative: 0, running: 2).

At this point, Task 1.0 fails, and the dynamic scheduler recalculates the number of executors as 2 (pendingTask: 1, pendingSpeculative: 0, running: 1).

Due to the failure of Task 1.0, copyRunning(1) becomes 1. As a result, Task 1 is speculated again and a SparkListenerSpeculativeTaskSubmitted event is triggered. However, the dynamic scheduler's calculation for the number of executors becomes 3 (pendingTask: 1, pendingSpeculative: 1, running: 1), which is obviously not as expected.

Then, Task 1.2 starts, and it is marked as a speculative task. However, the dynamic scheduler still calculates the number of executors as 3 (pendingTask: 1, pendingSpeculative: 1, running: 1), which again is not as expected.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 14:15.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1irjk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Upgrade ORC to 1.8.6
Issue key: SPARK-45884
Issue id: 13557478
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: dongjoon
Reporter: dongjoon
Creator: dongjoon
Created: 11/10/23 10:32
Updated: 11/10/23 16:58
Last Viewed: 7/17/24 20:45
Resolved: 11/10/23 16:56
Affects Version/s: 3.4.1
Fix Version/s: 3.4.2
Component/s: Build
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Nov 10 16:56:15 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1liv4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 10/Nov/23 16:56;dongjoon;Issue resolved by pull request 43755
[https://github.com/apache/spark/pull/43755];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Fix Spark History Server to sort `Duration` column properly
Issue key: SPARK-45749
Issue id: 13556329
Parent id: 13557406
Issue Type: Sub-task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: dongjoon
Reporter: dongjoon
Creator: dongjoon
Created: 11/1/23 0:37
Updated: 11/10/23 2:41
Last Viewed: 7/17/24 20:45
Resolved: 11/1/23 1:57
Affects Version/s: 3.2.0, 3.3.2, 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.3.4, 3.4.2, 3.5.1, 4.0.0
Component/s: Spark Core, Web UI
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): SPARK-34123
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Nov 01 01:57:47 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lbs0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 01/Nov/23 01:57;yao;Issue resolved by pull request 43613
[https://github.com/apache/spark/pull/43613];;;
Affects Version/s.1: 3.3.2
Affects Version/s.2: 3.4.1
Affects Version/s.3: 3.5.0
Affects Version/s.4: 4.0.0
Comment.1:

Summary: Fix getBaseURI error in Spark Worker LogPage UI buttons
Issue key: SPARK-44857
Issue id: 13547788
Parent id: 13557406
Issue Type: Sub-task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: dongjoon
Reporter: dongjoon
Creator: dongjoon
Created: 8/17/23 21:42
Updated: 11/10/23 2:41
Last Viewed: 7/17/24 20:45
Resolved: 8/18/23 1:07
Affects Version/s: 3.2.0, 3.2.4, 3.3.2, 3.4.1, 3.5.0
Fix Version/s: 3.3.4, 3.4.2, 3.5.0, 4.0.0
Component/s: Spark Core, Web UI
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): SPARK-35822
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 17/Aug/23 21:42;dongjoon;Screenshot 2023-08-17 at 2.38.45 PM.png;https://issues.apache.org/jira/secure/attachment/13062258/Screenshot+2023-08-17+at+2.38.45+PM.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 1
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Aug 22 22:11:04 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jv40:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 18/Aug/23 01:07;dongjoon;Issue resolved by pull request 42546
[https://github.com/apache/spark/pull/42546];;;, 22/Aug/23 22:11;dongjoon;Thank you for fixing the `Fix Version`, [~yumwang].;;;
Affects Version/s.1: 3.2.4
Affects Version/s.2: 3.3.2
Affects Version/s.3: 3.4.1
Affects Version/s.4: 3.5.0
Comment.1: 22/Aug/23 22:11;dongjoon;Thank you for fixing the `Fix Version`, [~yumwang].;;;

Summary: Fix WorkerPage to use the same pattern for `logPage` urls
Issue key: SPARK-45187
Issue id: 13550960
Parent id: 13557406
Issue Type: Sub-task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: dongjoon
Reporter: dongjoon
Creator: dongjoon
Created: 9/17/23 8:45
Updated: 11/10/23 2:41
Last Viewed: 7/17/24 20:45
Resolved: 9/17/23 17:34
Affects Version/s: 3.2.4, 3.3.2, 3.4.1, 3.5.0
Fix Version/s: 3.3.4, 3.4.2, 3.5.1, 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sun Sep 17 17:34:42 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1keog:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 17/Sep/23 17:34;dongjoon;Issue resolved by pull request 42959
[https://github.com/apache/spark/pull/42959];;;
Affects Version/s.1: 3.3.2
Affects Version/s.2: 3.4.1
Affects Version/s.3: 3.5.0
Affects Version/s.4: 
Comment.1:

Summary: ClassCastException with SerializedLambda in Spark Cluster Mode
Issue key: SPARK-45860
Issue id: 13557374
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: punditavi@gmail.com
Creator: punditavi@gmail.com
Created: 11/9/23 19:13
Updated: 11/9/23 19:13
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.2.1, 3.4.1
Fix Version/s: 
Component/s: Spark Core, Spark Submit
Due Date: 
Votes: 0
Labels: 
Description: h3. Issue Description

Running a Spark application in cluster mode encounters a `{*}java.lang.ClassCastException{*}` related to `j{*}ava.lang.invoke.SerializedLambda{*}`. This issue seems to be specific to the Spark Cluster mode, and it doesn't occur when running the application locally without Spring Boot.

 
h3. Steps to Reproduce
 # Create a dummy dataset
{code:java}
Dataset<String> dummyData = spark.createDataset(Arrays.asList("Abhi", "Andrii", "Rick", "Duc"), Encoders.STRING()); {code}

 # Call flatMap function to transform the data
{code:java}
Dataset<TestData> transformedData = dummyData.flatMap(new TestDataFlatMap(), Encoders.bean(TestData.class)); {code}

 # Call any action on the transformed dataset
{code:java}
transformedData.show(); {code}

 # Running this Spark application with spark submit command in cluster mode with Spring Boot results in the mentioned ClassCastException.

 
h3. *Complete Code:*

 
{code:java}
@SpringBootApplication(exclude = {org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration.class})
public class SampleSparkJob{
    public static void main(String[] args) {
        SpringApplication.run(DataIngestionServiceApplication.class, args);

        SparkSession spark = SparkSession.builder()
                .appName("SampleSparkJob")
                .master("local[*]")
                .getOrCreate();
        Dataset<String> dummyData = spark.createDataset(Arrays.asList("Abhi", "Andrii", "Rick", "Duc"), Encoders.STRING());
        Dataset<TestData> transformedData = dummyData.flatMap(new TestDataFlatMap(), Encoders.bean(TestData.class));
        transformedData.show();
        transformedData.write().mode("append").parquet("outputpath");
        spark.stop();
    }
}{code}
{code:java}
class TestDataFlatMap implements FlatMapFunction<String, TestData>, Serializable {
    @Override
    public Iterator<TestData> call(String name) {
        return Arrays.asList(new TestData(name)).iterator();
    }
}{code}
{code:java}
@Data
@AllArgsConstructor
public class TestData implements Serializable {
    private String name;
} {code}
 
h3. 
Stack trace:
{code:java}
WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (10.248.66.38 executor 0): java.lang.ClassCastException: cannot assign instance of java.lang.invoke.SerializedLambda to field org.apache.spark.rdd.MapPartitionsRDD.f of type scala.Function3 in instance of org.apache.spark.rdd.MapPartitionsRDD	at java.base/java.io.ObjectStreamClass$FieldReflector.setObjFieldValues(ObjectStreamClass.java:2076)	at java.base/java.io.ObjectStreamClass$FieldReflector.checkObjectFieldValueTypes(ObjectStreamClass.java:2039)	at java.base/java.io.ObjectStreamClass.checkObjFieldValueTypes(ObjectStreamClass.java:1293)	at java.base/java.io.ObjectInputStream.defaultCheckFieldValues(ObjectInputStream.java:2512)	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2419)	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)	at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:527)	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)	at java.base/java.lang.reflect.Method.invoke(Method.java:566)	at java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1046)	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2357)	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)	at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)	at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:527)	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)	at java.base/java.lang.reflect.Method.invoke(Method.java:566)	at java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1046)	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2357)	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)	at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)	at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:527)	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)	at java.base/java.lang.reflect.Method.invoke(Method.java:566)	at java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1046)	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2357)	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)	at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)	at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2496)	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2390)	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2228)	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1687)	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:489)	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:447)	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:76)	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:115)	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:83)	at org.apache.spark.scheduler.Task.run(Task.scala:131)	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)	at java.base/java.lang.Thread.run(Thread.java:829) {code}
 

*Environment*
Java Version: 11
Spring Boot Version: 2.7.10
Spark Version: 3.2.1
h3. Additional Information:

The issue seems to be related to Spring Boot auto-configuration or the dependencies included with Spring Boot.
Environment: *Environment*
Java Version: 11
Spring Boot Version: 2.7.10
Spark Version: 3.2.1
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 13:47.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1li80:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: No way to exclude jars setting to classpath while doing spark-submit
Issue key: SPARK-45115
Issue id: 13550212
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: sumanto_pal_07
Creator: sumanto_pal_07
Created: 9/11/23 12:19
Updated: 11/8/23 3:12
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Spark Submit
Due Date: 
Votes: 0
Labels: 
Description: The challenge is whenever you do spark-submit to start the application, the jars present in spark home directory gets added to classpath automatically and there is no way to exclude specific jars from there. For example, we dont want slf4j jars present in spark home directory to be setted in classpath as in codebase slf4j is already there. Thus it causes conflicts in jars. This forces user to change there codebase to support spark-submit or to manually remove the jars from spark-home directory. This i believe is not right practice as we deviating from using spark as it supposed to be and it causes unfixable behaviors at various instances with no clue. Example linkages errors are common with the jar conflicts. 

 

There is detailed stackoverflow question on this issue. 

refer : https://stackoverflow.com/questions/76476618/linkageerror-facing-while-doing-spark-submit

 
Environment: 
Log Work: 
Original Estimate: 1209600
Remaining Estimate: 1209600
Time Spent: 
Work Ratio: 0%
Σ Original Estimate: 1209600
Σ Remaining Estimate: 1209600
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): https://stackoverflow.com/questions/76476618/linkageerror-facing-while-doing-spark-submit
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Sep 13 07:15:36 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ka2g:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 12/Sep/23 06:14;sumanto_pal_07;[~yao] , is there a way I could prioritize this issue as it'sblocking us to move to production ?;;;, 12/Sep/23 09:49;yao;Build your spark app with slf4j provided scope?;;;, 12/Sep/23 13:54;sumanto_pal_07;Challenge is we are using Firm recommended FAT jar which has slf4j and logging jars which are kind of customised. And we cannot go away with it as its not allowed. So we were hoping if spark could provide any way to exclude jar from spar-submit. [~yao]  
I believe this Jira will help user to avoid conflicts and onboard spark to there systems more conviniently as version issue sare very common with spark. 

I can work on the code fix if we believe this fix is helpful.;;;, 13/Sep/23 04:25;yao;Spark provides a user classpath first feature that might fix your issue.

 

Anyway, feel free to open a PR if you think it is necessary. It's not necessary to wait for any positive permission from spark committers to get started;;;, 13/Sep/23 07:15;sumanto_pal_07;_"Spark provides a user classpath first feature that might fix your issue."_

_~_ We tried this, did'nt helped.

_"Anyway, feel free to open a PR if you think it is necessary. It's not necessary to wait for any positive permission from spark committers to get started"_

~ Thanks, am new to the community, will share the pr soon.;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 12/Sep/23 09:49;yao;Build your spark app with slf4j provided scope?;;;

Summary: Support encoding of scala.collection.immutable.ArraySeq
Issue key: SPARK-45820
Issue id: 13557000
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: eejbyfeldt
Creator: eejbyfeldt
Created: 11/7/23 8:47
Updated: 11/7/23 8:47
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.0, 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: Trying to use `scala.collection.immutable.ArraySeq` will currently derive the encoder as it a subtype of scala.collection.Seq but will then fail at runtime since the builder interface is different then for other Seq.


{code:java}
scala> spark.createDataset(Seq(scala.collection.immutable.ArraySeq(1,2,3))).collect()
23/11/07 09:44:39 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/11/07 09:44:39 INFO SharedState: Warehouse path is 'file:/home/eejbyfeldt/spark-warehouse'.
23/11/07 09:44:40 INFO CodeGenerator: Code generated in 188.491705 ms
23/11/07 09:44:40 INFO CodeGenerator: Code generated in 14.382264 ms
23/11/07 09:44:40 ERROR CodeGenerator: failed to compile: org.codehaus.commons.compiler.CompileException: File 'generated.java', Line 47, Column 101: No applicable constructor/method found for zero actual parameters; candidates are: "public scala.collection.mutable.Builder scala.collection.immutable.ArraySeq$.newBuilder(scala.reflect.ClassTag)", "public scala.collection.mutable.Builder scala.collection.immutable.ArraySeq$.newBuilder(java.lang.Object)", "public abstract scala.collection.mutable.Builder scala.collection.EvidenceIterableFactory.newBuilder(java.lang.Object)"
org.codehaus.commons.compiler.CompileException: File 'generated.java', Line 47, Column 101: No applicable constructor/method found for zero actual parameters; candidates are: "public scala.collection.mutable.Builder scala.collection.immutable.ArraySeq$.newBuilder(scala.reflect.ClassTag)", "public scala.collection.mutable.Builder scala.collection.immutable.ArraySeq$.newBuilder(java.lang.Object)", "public abstract scala.collection.mutable.Builder scala.collection.EvidenceIterableFactory.newBuilder(java.lang.Object)"
    at org.codehaus.janino.UnitCompiler.compileError(UnitCompiler.java:13014)
    at org.codehaus.janino.UnitCompiler.findMostSpecificIInvocable(UnitCompiler.java:9615)
    at org.codehaus.janino.UnitCompiler.findIMethod(UnitCompiler.java:9475)
    at org.codehaus.janino.UnitCompiler.findIMethod(UnitCompiler.java:9391)
    at org.codehaus.janino.UnitCompiler.compileGet2(UnitCompiler.java:5232)
    at org.codehaus.janino.UnitCompiler.access$9300(UnitCompiler.java:236)
    at org.codehaus.janino.UnitCompiler$16.visitMethodInvocation(UnitCompiler.java:4735)
    at org.codehaus.janino.UnitCompiler$16.visitMethodInvocation(UnitCompiler.java:4711)
    at org.codehaus.janino.Java$MethodInvocation.accept(Java.java:5470)
    at org.codehaus.janino.UnitCompiler.compileGet(UnitCompiler.java:4711)
    at org.codehaus.janino.UnitCompiler.compileGetValue(UnitCompiler.java:5854)
    at org.codehaus.janino.UnitCompiler.access$3800(UnitCompiler.java:236)
    at org.codehaus.janino.UnitCompiler$7.visitRvalue(UnitCompiler.java:2766)
    at org.codehaus.janino.UnitCompiler$7.visitRvalue(UnitCompiler.java:2754)
    at org.codehaus.janino.Java$Rvalue.accept(Java.java:4498)
    at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:2754)
    at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:2741)
    at org.codehaus.janino.UnitCompiler.access$2700(UnitCompiler.java:236)
    at org.codehaus.janino.UnitCompiler$6.visitLocalVariableDeclarationStatement(UnitCompiler.java:1589)
    at org.codehaus.janino.UnitCompiler$6.visitLocalVariableDeclarationStatement(UnitCompiler.java:1575)
    at org.codehaus.janino.Java$LocalVariableDeclarationStatement.accept(Java.java:3842)
    at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:1575)
    at org.codehaus.janino.UnitCompiler.compileStatements(UnitCompiler.java:1661)
    at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:1646)
    at org.codehaus.janino.UnitCompiler.access$1700(UnitCompiler.java:236)
    at org.codehaus.janino.UnitCompiler$6.visitBlock(UnitCompiler.java:1579)
    at org.codehaus.janino.UnitCompiler$6.visitBlock(UnitCompiler.java:1575)
    at org.codehaus.janino.Java$Block.accept(Java.java:3115)
    at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:1575)
    at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:2649)
    at org.codehaus.janino.UnitCompiler.access$1900(UnitCompiler.java:236)
    at org.codehaus.janino.UnitCompiler$6.visitIfStatement(UnitCompiler.java:1581)
    at org.codehaus.janino.UnitCompiler$6.visitIfStatement(UnitCompiler.java:1575)
    at org.codehaus.janino.Java$IfStatement.accept(Java.java:3284)
    at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:1575)
    at org.codehaus.janino.UnitCompiler.compileStatements(UnitCompiler.java:1661)
    at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:3658)
    at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:3329)
    at org.codehaus.janino.UnitCompiler.compileDeclaredMethods(UnitCompiler.java:1447)
    at org.codehaus.janino.UnitCompiler.compileDeclaredMethods(UnitCompiler.java:1420)
    at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:829)
    at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:1026)
    at org.codehaus.janino.UnitCompiler.access$700(UnitCompiler.java:236)
    at org.codehaus.janino.UnitCompiler$3.visitMemberClassDeclaration(UnitCompiler.java:425)
    at org.codehaus.janino.UnitCompiler$3.visitMemberClassDeclaration(UnitCompiler.java:418)
    at org.codehaus.janino.Java$MemberClassDeclaration.accept(Java.java:1533)
    at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:418)
    at org.codehaus.janino.UnitCompiler.compileDeclaredMemberTypes(UnitCompiler.java:1397)
    at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:864)
    at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:442)
    at org.codehaus.janino.UnitCompiler.access$400(UnitCompiler.java:236)
    at org.codehaus.janino.UnitCompiler$3.visitPackageMemberClassDeclaration(UnitCompiler.java:422)
    at org.codehaus.janino.UnitCompiler$3.visitPackageMemberClassDeclaration(UnitCompiler.java:418)
    at org.codehaus.janino.Java$PackageMemberClassDeclaration.accept(Java.java:1688)
    at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:418)
    at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:392)
    at org.codehaus.janino.UnitCompiler.access$000(UnitCompiler.java:236)
    at org.codehaus.janino.UnitCompiler$2.visitCompilationUnit(UnitCompiler.java:363)
    at org.codehaus.janino.UnitCompiler$2.visitCompilationUnit(UnitCompiler.java:361)
    at org.codehaus.janino.Java$CompilationUnit.accept(Java.java:371)
    at org.codehaus.janino.UnitCompiler.compileUnit(UnitCompiler.java:361)
    at org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:264)
    at org.codehaus.janino.ClassBodyEvaluator.cook(ClassBodyEvaluator.java:294)
    at org.codehaus.janino.ClassBodyEvaluator.cook(ClassBodyEvaluator.java:288)
    at org.codehaus.janino.ClassBodyEvaluator.cook(ClassBodyEvaluator.java:267)
    at org.codehaus.commons.compiler.Cookable.cook(Cookable.java:82)
    at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.doCompile(CodeGenerator.scala:1497)
    at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.$anonfun$cache$1(CodeGenerator.scala:1589)
    at org.apache.spark.util.NonFateSharingCache$$anon$1.load(NonFateSharingCache.scala:68)
    at org.sparkproject.guava.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)
    at org.sparkproject.guava.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)
    at org.sparkproject.guava.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)
    at org.sparkproject.guava.cache.LocalCache$Segment.get(LocalCache.java:2257)
    at org.sparkproject.guava.cache.LocalCache.get(LocalCache.java:4000)
    at org.sparkproject.guava.cache.LocalCache.getOrLoad(LocalCache.java:4004)
    at org.sparkproject.guava.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4874)
    at org.apache.spark.util.NonFateSharingLoadingCache.$anonfun$get$2(NonFateSharingCache.scala:94)
    at org.apache.spark.util.KeyLock.withLock(KeyLock.scala:64)
    at org.apache.spark.util.NonFateSharingLoadingCache.get(NonFateSharingCache.scala:94)
    at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.compile(CodeGenerator.scala:1444)
    at org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection$.create(GenerateSafeProjection.scala:205)
    at org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection$.create(GenerateSafeProjection.scala:39)
    at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:1369)
    at org.apache.spark.sql.catalyst.expressions.SafeProjection$.createCodeGeneratedObject(Projection.scala:171)
    at org.apache.spark.sql.catalyst.expressions.SafeProjection$.createCodeGeneratedObject(Projection.scala:168)
    at org.apache.spark.sql.catalyst.expressions.CodeGeneratorWithInterpretedFallback.createObject(CodeGeneratorWithInterpretedFallback.scala:50)
    at org.apache.spark.sql.catalyst.expressions.SafeProjection$.create(Projection.scala:194)
    at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Deserializer.apply(ExpressionEncoder.scala:180)
    at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Deserializer.apply(ExpressionEncoder.scala:173)
    at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:929)
    at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4344)
    at org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3585)
    at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)
    at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
    at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)
    at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
    at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
    at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
    at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
    at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
    at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)
    at org.apache.spark.sql.Dataset.collect(Dataset.scala:3585)
    at $line14.$read$$iw.<init>(<console>:1)
    at $line14.$read.<init>(<console>:15)
    at $line14.$read$.<clinit>(<console>:1)
    at $line14.$eval$.$print$lzycompute(<synthetic>:6)
    at $line14.$eval$.$print(<synthetic>:5)
    at $line14.$eval.$print(<synthetic>)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.base/java.lang.reflect.Method.invoke(Method.java:568)
    at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:670)
    at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1020)
    at scala.tools.nsc.interpreter.IMain.$anonfun$doInterpret$1(IMain.scala:506)
    at scala.reflect.internal.util.ScalaClassLoader.asContext(ScalaClassLoader.scala:36)
    at scala.reflect.internal.util.ScalaClassLoader.asContext$(ScalaClassLoader.scala:116)
    at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:43)
    at scala.tools.nsc.interpreter.IMain.loadAndRunReq$1(IMain.scala:505)
    at scala.tools.nsc.interpreter.IMain.$anonfun$doInterpret$3(IMain.scala:519)
    at scala.tools.nsc.interpreter.IMain.doInterpret(IMain.scala:519)
    at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:503)
    at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:501)
    at scala.tools.nsc.interpreter.shell.ILoop.loop$1(ILoop.scala:878)
    at scala.tools.nsc.interpreter.shell.ILoop.interpretStartingWith(ILoop.scala:906)
    at scala.tools.nsc.interpreter.shell.ILoop.command(ILoop.scala:433)
    at scala.tools.nsc.interpreter.shell.ILoop.processLine(ILoop.scala:440)
    at scala.tools.nsc.interpreter.shell.ILoop.loop(ILoop.scala:458)
    at scala.tools.nsc.interpreter.shell.ILoop.run(ILoop.scala:968)
    at org.apache.spark.repl.Main$.doMain(Main.scala:84)
    at org.apache.spark.repl.Main$.main(Main.scala:59)
    at org.apache.spark.repl.Main.main(Main.scala)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.base/java.lang.reflect.Method.invoke(Method.java:568)
    at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
    at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1029)
    at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)
    at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)
    at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
    at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)
    at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)
    at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
23/11/07 09:44:40 INFO CodeGenerator: 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */   private int value_MapObject_lambda_variable_1;
/* 010 */   private boolean globalIsNull_0;
/* 011 */
/* 012 */   public SpecificSafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableRow = (InternalRow) references[references.length - 1];
/* 015 */
/* 016 */
/* 017 */   }
/* 018 */
/* 019 */   public void initialize(int partitionIndex) {
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   public java.lang.Object apply(java.lang.Object _i) {
/* 024 */     InternalRow i = (InternalRow) _i;
/* 025 */     scala.collection.immutable.ArraySeq value_3 = MapObjects_0(i);
/* 026 */     if (globalIsNull_0) {
/* 027 */       mutableRow.setNullAt(0);
/* 028 */     } else {
/* 029 */
/* 030 */       mutableRow.update(0, value_3);
/* 031 */     }
/* 032 */
/* 033 */     return mutableRow;
/* 034 */   }
/* 035 */
/* 036 */
/* 037 */   private scala.collection.immutable.ArraySeq MapObjects_0(InternalRow i) {
/* 038 */     boolean isNull_1 = i.isNullAt(0);
/* 039 */     ArrayData value_1 = isNull_1 ?
/* 040 */     null : (i.getArray(0));
/* 041 */     scala.collection.immutable.ArraySeq value_0 = null;
/* 042 */
/* 043 */     if (!isNull_1) {
/* 044 */
/* 045 */       int dataLength_0 = value_1.numElements();
/* 046 */
/* 047 */       scala.collection.mutable.Builder collectionBuilder_0 = scala.collection.immutable.ArraySeq$.MODULE$.newBuilder();
/* 048 */       collectionBuilder_0.sizeHint(dataLength_0);
/* 049 */
/* 050 */
/* 051 */       int loopIndex_0 = 0;
/* 052 */
/* 053 */       while (loopIndex_0 < dataLength_0) {
/* 054 */         value_MapObject_lambda_variable_1 = (int) (value_1.getInt(loopIndex_0));
/* 055 */
/* 056 */
/* 057 */         if (false) {
/* 058 */           throw new NullPointerException(((java.lang.String) references[0] /* errMsg */));
/* 059 */         }
/* 060 */         if (false) {
/* 061 */           collectionBuilder_0.$plus$eq(null);
/* 062 */         } else {
/* 063 */           collectionBuilder_0.$plus$eq(value_MapObject_lambda_variable_1);
/* 064 */         }
/* 065 */
/* 066 */         loopIndex_0 += 1;
/* 067 */       }
/* 068 */
/* 069 */       value_0 = (scala.collection.immutable.ArraySeq) collectionBuilder_0.result();
/* 070 */     }
/* 071 */     globalIsNull_0 = isNull_1;
/* 072 */     return value_0;
/* 073 */   }
/* 074 */
/* 075 */ }23/11/07 09:44:40 WARN SafeProjection: Expr codegen error and falling back to interpreter mode
java.util.concurrent.ExecutionException: org.codehaus.commons.compiler.CompileException: File 'generated.java', Line 47, Column 101: failed to compile: org.codehaus.commons.compiler.CompileException: File 'generated.java', Line 47, Column 101: No applicable constructor/method found for zero actual parameters; candidates are: "public scala.collection.mutable.Builder scala.collection.immutable.ArraySeq$.newBuilder(scala.reflect.ClassTag)", "public scala.collection.mutable.Builder scala.collection.immutable.ArraySeq$.newBuilder(java.lang.Object)", "public abstract scala.collection.mutable.Builder scala.collection.EvidenceIterableFactory.newBuilder(java.lang.Object)"
    at org.sparkproject.guava.util.concurrent.AbstractFuture$Sync.getValue(AbstractFuture.java:306)
    at org.sparkproject.guava.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:293)
    at org.sparkproject.guava.util.concurrent.AbstractFuture.get(AbstractFuture.java:116)
    at org.sparkproject.guava.util.concurrent.Uninterruptibles.getUninterruptibly(Uninterruptibles.java:135)
    at org.sparkproject.guava.cache.LocalCache$Segment.getAndRecordStats(LocalCache.java:2410)
    at org.sparkproject.guava.cache.LocalCache$Segment.loadSync(LocalCache.java:2380)
    at org.sparkproject.guava.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)
    at org.sparkproject.guava.cache.LocalCache$Segment.get(LocalCache.java:2257)
    at org.sparkproject.guava.cache.LocalCache.get(LocalCache.java:4000)
    at org.sparkproject.guava.cache.LocalCache.getOrLoad(LocalCache.java:4004)
    at org.sparkproject.guava.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4874)
    at org.apache.spark.util.NonFateSharingLoadingCache.$anonfun$get$2(NonFateSharingCache.scala:94)
    at org.apache.spark.util.KeyLock.withLock(KeyLock.scala:64)
    at org.apache.spark.util.NonFateSharingLoadingCache.get(NonFateSharingCache.scala:94)
    at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.compile(CodeGenerator.scala:1444)
    at org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection$.create(GenerateSafeProjection.scala:205)
    at org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection$.create(GenerateSafeProjection.scala:39)
    at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:1369)
    at org.apache.spark.sql.catalyst.expressions.SafeProjection$.createCodeGeneratedObject(Projection.scala:171)
    at org.apache.spark.sql.catalyst.expressions.SafeProjection$.createCodeGeneratedObject(Projection.scala:168)
    at org.apache.spark.sql.catalyst.expressions.CodeGeneratorWithInterpretedFallback.createObject(CodeGeneratorWithInterpretedFallback.scala:50)
    at org.apache.spark.sql.catalyst.expressions.SafeProjection$.create(Projection.scala:194)
    at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Deserializer.apply(ExpressionEncoder.scala:180)
    at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Deserializer.apply(ExpressionEncoder.scala:173)
    at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:929)
    at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4344)
    at org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3585)
    at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)
    at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
    at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)
    at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
    at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
    at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
    at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
    at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
    at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)
    at org.apache.spark.sql.Dataset.collect(Dataset.scala:3585)
    at $line14.$read$$iw.<init>(<console>:1)
    at $line14.$read.<init>(<console>:15)
    at $line14.$read$.<clinit>(<console>:1)
    at $line14.$eval$.$print$lzycompute(<synthetic>:6)
    at $line14.$eval$.$print(<synthetic>:5)
    at $line14.$eval.$print(<synthetic>)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.base/java.lang.reflect.Method.invoke(Method.java:568)
    at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:670)
    at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1020)
    at scala.tools.nsc.interpreter.IMain.$anonfun$doInterpret$1(IMain.scala:506)
    at scala.reflect.internal.util.ScalaClassLoader.asContext(ScalaClassLoader.scala:36)
    at scala.reflect.internal.util.ScalaClassLoader.asContext$(ScalaClassLoader.scala:116)
    at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:43)
    at scala.tools.nsc.interpreter.IMain.loadAndRunReq$1(IMain.scala:505)
    at scala.tools.nsc.interpreter.IMain.$anonfun$doInterpret$3(IMain.scala:519)
    at scala.tools.nsc.interpreter.IMain.doInterpret(IMain.scala:519)
    at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:503)
    at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:501)
    at scala.tools.nsc.interpreter.shell.ILoop.loop$1(ILoop.scala:878)
    at scala.tools.nsc.interpreter.shell.ILoop.interpretStartingWith(ILoop.scala:906)
    at scala.tools.nsc.interpreter.shell.ILoop.command(ILoop.scala:433)
    at scala.tools.nsc.interpreter.shell.ILoop.processLine(ILoop.scala:440)
    at scala.tools.nsc.interpreter.shell.ILoop.loop(ILoop.scala:458)
    at scala.tools.nsc.interpreter.shell.ILoop.run(ILoop.scala:968)
    at org.apache.spark.repl.Main$.doMain(Main.scala:84)
    at org.apache.spark.repl.Main$.main(Main.scala:59)
    at org.apache.spark.repl.Main.main(Main.scala)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.base/java.lang.reflect.Method.invoke(Method.java:568)
    at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
    at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1029)
    at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)
    at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)
    at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
    at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)
    at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)
    at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: org.codehaus.commons.compiler.CompileException: File 'generated.java', Line 47, Column 101: failed to compile: org.codehaus.commons.compiler.CompileException: File 'generated.java', Line 47, Column 101: No applicable constructor/method found for zero actual parameters; candidates are: "public scala.collection.mutable.Builder scala.collection.immutable.ArraySeq$.newBuilder(scala.reflect.ClassTag)", "public scala.collection.mutable.Builder scala.collection.immutable.ArraySeq$.newBuilder(java.lang.Object)", "public abstract scala.collection.mutable.Builder scala.collection.EvidenceIterableFactory.newBuilder(java.lang.Object)"
    at org.apache.spark.sql.errors.QueryExecutionErrors$.compilerError(QueryExecutionErrors.scala:663)
    at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.doCompile(CodeGenerator.scala:1509)
    at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.$anonfun$cache$1(CodeGenerator.scala:1589)
    at org.apache.spark.util.NonFateSharingCache$$anon$1.load(NonFateSharingCache.scala:68)
    at org.sparkproject.guava.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)
    at org.sparkproject.guava.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)
    ... 73 more
java.lang.ArrayStoreException: scala.collection.immutable.$colon$colon
  at scala.runtime.ScalaRunTime$.array_update(ScalaRunTime.scala:74)
  at scala.collection.ArrayOps$.map$extension(ArrayOps.scala:929)
  at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4344)
  at org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3585)
  at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)
  at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
  at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)
  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
  at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)
  at org.apache.spark.sql.Dataset.collect(Dataset.scala:3585)
  ... 42 elided
 {code}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 47:50.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lfww:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 4.0.0
Affects Version/s.4: 
Comment.1:

Summary: When using Spark to read the hive table, the number of file partitions cannot be set using Spark's configuration settings
Issue key: SPARK-44483
Issue id: 13544108
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: hao.duan
Creator: hao.duan
Created: 7/19/23 11:58
Updated: 11/5/23 0:19
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: When using Spark to read the hive table, the number of file partitions cannot be set using Spark's configuration settings
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 58:17.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j8s0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: first operator should respect the nullability of child expression as well as ignoreNulls option
Issue key: SPARK-44517
Issue id: 13544575
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: codingcat
Creator: codingcat
Created: 7/24/23 2:14
Updated: 11/4/23 0:17
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.2.0, 3.2.1, 3.2.2, 3.2.3, 3.2.4, 3.3.0, 3.3.1, 3.3.2, 3.4.0, 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: I found the following problem when using Spark recently:

 
{code:java}
// code placeholder
import spark.implicits._

val s = Seq((1.2, "s", 2.2)).toDF("v1", "v2", "v3")

val schema = StructType(Seq(StructField("v1", DoubleType, nullable = false),StructField("v2", StringType, nullable = true),StructField("v3", DoubleType, nullable = false)))

val df = spark.createDataFrame(s.rdd, schema)val inputDF = 

val inputDF = df.dropDuplicates("v3")

spark.sql("CREATE TABLE local.db.table (\n v1 DOUBLE NOT NULL,\n v2 STRING, v3 DOUBLE NOT NULL)")

inputDF.write.mode("overwrite").format("iceberg").save("local.db.table") {code}
 

 

when I use the above code to write to iceberg (i guess Delta Lake will have the same problem) , I got very confusing exception


{code:java}
Exception in thread "main" java.lang.IllegalArgumentException: Cannot write incompatible dataset to table with schema:

table 

{  1: v1: required double  2: v2: optional string  3: v3: required double}

Provided schema:

table {  1: v1: optional double  2: v2: optional string  3: v3: required double} {code}

basically it complains that we have v1 as the nullable column in our `inputDF` above which is not allowed since we created table with the v1 as not nullable. The confusion comes from that,  if we check the schema with printSchema() of inputDF, v1 is not nullable
{noformat}
root 
|-- v1: double (nullable = false) 
|-- v2: string (nullable = true) 
|-- v3: double (nullable = false){noformat}
Clearly, something changed the v1's nullability unexpectedly!

 

After some debugging I found that the key is that dropDuplicates("v3"). In optimization phase, we have ReplaceDeduplicateWithAggregate to replace the Deduplicate with aggregate on v3 and run first() over all other columns. However, first() operator has hard coded nullable as always "true" which is the source of changed nullability of v1

 

this is a very confusing behavior of Spark, and probably no one really noticed as we do not care too much without the new table formats like delta lake and iceberg which can make nullability check correctly. Nowadays, we users adopt them more and more, this is surfaced up

 

 

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sat Aug 05 16:51:43 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jbns:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 05/Aug/23 16:51;hiveqa;User 'CodingCat' has created a pull request for this issue:
https://github.com/apache/spark/pull/42117;;;
Affects Version/s.1: 3.2.1
Affects Version/s.2: 3.2.2
Affects Version/s.3: 3.2.3
Affects Version/s.4: 3.2.4
Comment.1:

Summary: Extremely slow execution of sum of columns in Spark 3.4.1
Issue key: SPARK-45745
Issue id: 13556321
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: jabot
Creator: jabot
Created: 10/31/23 21:59
Updated: 11/1/23 7:53
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: PySpark
Due Date: 
Votes: 0
Labels: 
Description: We are in the process of upgrading some pySpark jobs from Spark 3.1.2 to Spark 3.4.1 and some code that was running fine is now basically never ending even for small dataframes.

We have simplified the problematic piece of code and the minimum pySpark example below shows the issue:
{code:java}
n_cols = 50
data = [{f"col{i}": i for i in range(n_cols)} for _ in range(5)]
df_data = sql_context.createDataFrame(data)

df_data = df_data.withColumn(
    "col_sum", sum([F.col(f"col{i}") for i in range(n_cols)])
)
df_data.show(10, False) {code}
Basically, this code with Spark 3.1.2 runs fine but with 3.4.1 the computation time seems to explode when the value of `n_cols` is bigger than about 25 columns. A colleague suggested that it could be related to the limit of 22 elements in a tuple in Scala 2.13 (https://www.scala-lang.org/api/current/scala/Tuple22.html), since the 25 columns are suspiciously close to this. Is there any known defect in the logical plan optimization in 3.4.1? Or is this kind of operations (sum of multiple columns) supposed to be implemented differently?
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Nov 01 07:53:18 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lbq8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 31/Oct/23 22:03;jabot;I originally posted a comment in StackOverflow asking for feedback on this ([https://stackoverflow.com/questions/77391731/extremely-slow-execution-in-spark-3-4-1-when-computing-the-sum-of-pyspark-datafr]) and a user there pointed me to a problem to a never ending UT reported here https://issues.apache.org/jira/browse/SPARK-43972 It is for the same Spark version, but I honestly don't know if this can be related.;;;, 31/Oct/23 22:18;bersprockets;Likely SPARK-45071 (which was also reported as SPARK-44912).;;;, 01/Nov/23 07:53;jabot;Thanks for the pointer [~bersprockets]! I'll try to check if 3.4.2 runs my example correctly.;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 31/Oct/23 22:18;bersprockets;Likely SPARK-45071 (which was also reported as SPARK-44912).;;;

Summary: Reenable CatalogTests without Spark Connect
Issue key: SPARK-45735
Issue id: 13556172
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: gurwls223
Reporter: gurwls223
Creator: gurwls223
Created: 10/31/23 3:44
Updated: 10/31/23 7:48
Last Viewed: 7/17/24 20:45
Resolved: 10/31/23 7:48
Affects Version/s: 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.4.2, 3.5.1, 4.0.0
Component/s: PySpark, Tests
Due Date: 
Votes: 0
Labels: pull-request-available
Description: https://issues.apache.org/jira/browse/SPARK-41707 mistakenly make the original tests skipped.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Oct 31 07:48:13 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lat4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 31/Oct/23 07:48;gurwls223;Issue resolved by pull request 43595
[https://github.com/apache/spark/pull/43595];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 4.0.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Add option to use Java tmp dir for RocksDB state store
Issue key: SPARK-44639
Issue id: 13545896
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: kimahriman
Creator: kimahriman
Created: 8/2/23 17:47
Updated: 10/29/23 21:35
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL, Structured Streaming
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Currently local RocksDB state is stored in a local directory given by Utils.getLocalDir. On yarn this is a directory created inside the root application folder such as

{{/tmp/nm-local-dir/usercache/<user>/appcache/<app_id>/}}

The problem with this is that if an executor crashes for some reason (like OOM) and the shutdown hooks don't get run, this directory will stay around forever until the application finishes, which can cause jobs to slowly accumulate more and more temporary space until finally the node manager goes unhealthy.

Because this data will only ever be accessed by the executor that created this directory, it would make sense to store the data inside the container folder, which will always get cleaned up by the node manager when that yarn container gets cleaned up. Yarn sets the `java.io.tmpdir` to a path inside this directory, such as

{{/tmp/nm-local-dir/usercache/<user>/appcache/<app_id>/<container_id>/tmp/}}

I'm not sure the behavior for other resource managers, so this could be an opt-in config that can be specified.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 47:35.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jjso:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: change the external catalog thread safety way
Issue key: SPARK-44472
Issue id: 13543895
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: igreenfi
Creator: igreenfi
Created: 7/18/23 7:38
Updated: 10/29/23 15:13
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: We test changing the sync of the external catalog to use thread-local instead of the synchronized methods.

in our tests, it improve the runtime of parallel actions by about 45% for certain workload ** (time reduced from ~15min to ~9min) 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 18/Jul/23 08:56;igreenfi;add_hive_concurrent_connections.diff;https://issues.apache.org/jira/secure/attachment/13061392/add_hive_concurrent_connections.diff
Custom field (Affects version (Component)): 
Custom field (Attachment count): 1
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sun Oct 29 15:11:27 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j7go:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 29/Oct/23 15:11;igreenfi;Hi, Any comments about this?;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: SparkSubmit does not support --total-executor-cores when deploying on K8s
Issue key: SPARK-45670
Issue id: 13555583
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: chengpan
Reporter: chengpan
Creator: chengpan
Created: 10/26/23 4:09
Updated: 10/27/23 6:26
Last Viewed: 7/17/24 20:45
Resolved: 10/27/23 6:24
Affects Version/s: 3.3.3, 3.4.1, 3.5.0
Fix Version/s: 3.3.4, 3.4.2, 3.5.1
Component/s: Spark Submit
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Oct 27 06:24:50 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1l76g:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 27/Oct/23 06:24;gurwls223;Issue resolved by pull request 43548
[https://github.com/apache/spark/pull/43548];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Caching SQL UNION of different column data types does not work inside Dataset.union
Issue key: SPARK-45657
Issue id: 13555412
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: 
Reporter: jzhuge
Creator: jzhuge
Created: 10/25/23 0:20
Updated: 10/25/23 5:34
Last Viewed: 7/17/24 20:45
Resolved: 10/25/23 5:34
Affects Version/s: 3.3.2, 3.4.0, 3.4.1
Fix Version/s: 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description:  

Cache SQL UNION of 2 sides with different column data types
{code:java}
scala> spark.sql("select 1 id union select 's2' id").cache()  {code}
Dataset.union does not leverage the cache
{code:java}
scala> spark.sql("select 1 id union select 's2' id").union(spark.sql("select 's3'")).queryExecution.optimizedPlan
res15: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =
Union false, false
:- Aggregate [id#109], [id#109]
:  +- Union false, false
:     :- Project [1 AS id#109]
:     :  +- OneRowRelation
:     +- Project [s2 AS id#108]
:        +- OneRowRelation
+- Project [s3 AS s3#111]
   +- OneRowRelation {code}
SQL UNION of the cached SQL UNION does use the cache! Please note `InMemoryRelation` used.
{code:java}
scala> spark.sql("(select 1 id union select 's2' id) union select 's3'").queryExecution.optimizedPlan
res16: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =
Aggregate [id#117], [id#117]
+- Union false, false
   :- InMemoryRelation [id#117], StorageLevel(disk, memory, deserialized, 1 replicas)
   :     +- *(4) HashAggregate(keys=[id#100], functions=[], output=[id#100])
   :        +- Exchange hashpartitioning(id#100, 500), ENSURE_REQUIREMENTS, [plan_id=241]
   :           +- *(3) HashAggregate(keys=[id#100], functions=[], output=[id#100])
   :              +- Union
   :                 :- *(1) Project [1 AS id#100]
   :                 :  +- *(1) Scan OneRowRelation[]
   :                 +- *(2) Project [s2 AS id#99]
   :                    +- *(2) Scan OneRowRelation[]
   +- Project [s3 AS s3#116]
      +- OneRowRelation {code}
 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Oct 25 05:34:44 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1l64g:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 25/Oct/23 00:35;jzhuge;Root cause:
 # SQL UNION of 2 sides with different data types produce a Project of Project on 1 side to cast the type. When this is cached, the Project of Project is preserved.
{noformat}
Distinct
+- Union false, false
   :- Project [cast(id#153 as string) AS id#155]
   :  +- Project [1 AS id#153]
   :     +- OneRowRelation
   +- Project [s2 AS id#154]
      +- OneRowRelation{noformat}

 # Dataset.union applies `CombineUnions` which applies to all unions in the tree. CombineUnions collapses the 2 Projects into 1, thus Dataset.union of the above plan with any plan will not be able to find a matching cached plan.
{code:java}
object CombineUnions extends Rule[LogicalPlan] {
...
  private def flattenUnion(union: Union, flattenDistinct: Boolean):
...
    case p1 @ Project(_, p2: Project)
      if canCollapseExpressions(p1.projectList, p2.projectList, alwaysInline = false) &&
        !p1.projectList.exists(SubqueryExpression.hasCorrelatedSubquery) &&
        !p2.projectList.exists(SubqueryExpression.hasCorrelatedSubquery) =>
      val newProjectList = buildCleanedProjectList(p1.projectList, p2.projectList)
      stack.pushAll(Seq(p2.copy(projectList = newProjectList))){code}

 ;;;, 25/Oct/23 00:46;jzhuge;Checking whether this is still an issue in main branch.;;;, 25/Oct/23 00:50;jzhuge;Interesting, there is warning in Dataset.union
{code:java}
def union(other: Dataset[T]): Dataset[T] = withSetOperator {
  // This breaks caching, but it's usually ok because it addresses a very specific use case:
  // using union to union many files or partitions.
  CombineUnions(Union(logicalPlan, other.logicalPlan))
} {code};;;, 25/Oct/23 04:32;jzhuge;It is fixed in main branch
{code:java}
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 4.0.0-SNAPSHOT
      /_/Using Scala version 2.13.12 (OpenJDK 64-Bit Server VM, Java 17.0.7)
Type in expressions to have them evaluated.
Type :help for more information.
23/10/24 21:30:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Spark context Web UI available at http://192.168.86.29:4040
Spark context available as 'sc' (master = local[*], app id = local-1698208231783).
Spark session available as 'spark'.scala> spark.sql("select 1 id union select 's2' id").cache()
val res0: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: string]scala> spark.sql("select 1 id union select 's2' id").union(spark.sql("select 's3'")).queryExecution.optimizedPlan
val res1: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =
Union false, false
:- InMemoryRelation [id#11], StorageLevel(disk, memory, deserialized, 1 replicas)
:     +- AdaptiveSparkPlan isFinalPlan=false
:        +- HashAggregate(keys=[id#2], functions=[], output=[id#2])
:           +- Exchange hashpartitioning(id#2, 200), ENSURE_REQUIREMENTS, [plan_id=30]
:              +- HashAggregate(keys=[id#2], functions=[], output=[id#2])
:                 +- Union
:                    :- Project [1 AS id#2]
:                    :  +- Scan OneRowRelation[]
:                    +- Project [s2 AS id#1]
:                       +- Scan OneRowRelation[]
+- Project [s3 AS s3#13]
   +- OneRowRelation {code};;;, 25/Oct/23 05:34;jzhuge;The issue is fixed in 3.5.0;;;
Affects Version/s.1: 3.4.0
Affects Version/s.2: 3.4.1
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 25/Oct/23 00:46;jzhuge;Checking whether this is still an issue in main branch.;;;

Summary: Spark SQL returning incorrect values for full outer join on keys with the same name.
Issue key: SPARK-45583
Issue id: 13554492
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: 
Reporter: hcampbell
Creator: hcampbell
Created: 10/18/23 3:38
Updated: 10/20/23 15:03
Last Viewed: 7/17/24 20:45
Resolved: 10/20/23 15:03
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: {{The following query gives the wrong results.}}

 

{{WITH people as (}}
{{  SELECT * FROM (VALUES }}
{{    (1, 'Peter'), }}
{{    (2, 'Homer'), }}
{{    (3, 'Ned'),}}
{{    (3, 'Jenny')}}
{{  ) AS Idiots(id, FirstName)}}
{{{}){}}}{{{}, location as ({}}}
{{  SELECT * FROM (VALUES}}
{{    (1, 'sample0'),}}
{{    (1, 'sample1'),}}
{{    (2, 'sample2')  }}
{{  ) as Locations(id, address)}}
{{{}){}}}{{{}SELECT{}}}
{{  *}}
{{FROM}}
{{  people}}
{{FULL OUTER JOIN}}
{{  location}}
{{ON}}
{{  people.id = location.id}}

{{We find the following table:}}
||id: integer||FirstName: string||id: integer||address: string||
|2|Homer|2|sample2|
|null|Ned|null|null|
|null|Jenny|null|null|
|1|Peter|1|sample0|
|1|Peter|1|sample1|

{{But clearly the first `id` column is wrong, the nulls should be 3.}}

If we rename the id column in (only) the person table to pid we get the correct results:
||pid: integer||FirstName: string||id: integer||address: string||
|2|Homer|2|sample2|
|3|Ned|null|null|
|3|Jenny|null|null|
|1|Peter|1|sample0|
|1|Peter|1|sample1|
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Oct 19 23:28:53 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1l0g0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 18/Oct/23 16:30;bersprockets;Strangely, I cannot reproduce. Is some setting required?
{noformat}
sql("select version()").show(false)
+----------------------------------------------+
|version()                                     |
+----------------------------------------------+
|3.5.0 ce5ddad990373636e94071e7cef2f31021add07b|
+----------------------------------------------+

scala> sql("""WITH people as (
  SELECT * FROM (VALUES 
    (1, 'Peter'), 
    (2, 'Homer'), 
    (3, 'Ned'),
    (3, 'Jenny')
  ) AS Idiots(id, FirstName)
), location as (
  SELECT * FROM (VALUES
    (1, 'sample0'),
    (1, 'sample1'),
    (2, 'sample2')  
  ) as Locations(id, address)
)SELECT
  *
FROM
  people
FULL OUTER JOIN
  location
ON
  people.id = location.id""").show(false)
     |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      | 
+---+---------+----+-------+
|id |FirstName|id  |address|
+---+---------+----+-------+
|1  |Peter    |1   |sample0|
|1  |Peter    |1   |sample1|
|2  |Homer    |2   |sample2|
|3  |Ned      |NULL|NULL   |
|3  |Jenny    |NULL|NULL   |
+---+---------+----+-------+

scala> 
{noformat};;;, 19/Oct/23 23:28;hcampbell;Ahh, apologies, it looks like I was running 3.4.1 when I found this issue.

Testing in 3.5 it does appear to be resolved.;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 19/Oct/23 23:28;hcampbell;Ahh, apologies, it looks like I was running 3.4.1 when I found this issue.

Testing in 3.5 it does appear to be resolved.;;;

Summary: Porting k8s PVC reuse logic to spark standalone
Issue key: SPARK-44526
Issue id: 13544667
Parent id: 
Issue Type: New Feature
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: haldefaiz
Creator: haldefaiz
Created: 7/24/23 14:06
Updated: 10/18/23 20:40
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Shuffle, Spark Core
Due Date: 
Votes: 0
Labels: 
Description: Hi,

This ticket is meant to understand the work that would be involved in porting the k8s PVC reuse feature onto the spark standalone cluster manager which reuses the shuffle files present locally in the disk

We are a heavy user of spot instances and we suffer from spot terminations impacting our long running jobs

The logic in `KubernetesLocalDiskShuffleExecutorComponents` itself is not that much. However when I tried this on the `LocalDiskShuffleExecutorComponents` it was not a successful experiment which suggests there is more to recovering shuffle files

I'd like to understand what will be the work involved for this. We'll be more than happy to contribute
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 06:23.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jc88:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Add "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" so Platform can access cleaner on Java 9+
Issue key: SPARK-45508
Issue id: 13553769
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: joshrosen
Reporter: joshrosen
Creator: joshrosen
Created: 10/12/23 0:59
Updated: 10/13/23 17:44
Last Viewed: 7/17/24 20:45
Resolved: 10/13/23 5:30
Affects Version/s: 3.3.2, 3.4.1, 3.5.0
Fix Version/s: 3.3.4, 3.4.2, 3.5.1, 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: We need to add `--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED` to our JVM options so that the code in `org.apache.spark.unsafe.Platform` can access the JDK internal cleaner classes.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Oct 13 05:30:00 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kvzc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 13/Oct/23 05:30;LuciferYang;Issue resolved by pull request 43344
[https://github.com/apache/spark/pull/43344];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Support stage level task resource profile for k8s cluster when dynamic allocation disabled
Issue key: SPARK-45495
Issue id: 13553604
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: wbo4958
Reporter: wbo4958
Creator: wbo4958
Created: 10/11/23 0:38
Updated: 10/13/23 15:52
Last Viewed: 7/17/24 20:45
Resolved: 10/13/23 15:52
Affects Version/s: 3.4.1
Fix Version/s: 3.5.1, 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: [https://github.com/apache/spark/pull/37268] has introduced a new feature that supports stage-level schedule task resource profile for standalone cluster when dynamic allocation is disabled. It's really cool feature, especially for ML/DL cases, more details can be found in that PR.

 

The problem here is that the feature is only available for standalone and YARN cluster for now, but most users would also expect it can be used for other spark clusters like K8s.

 

So I filed this issue to track this task.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): SPARK-45250
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 38:46.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kuyo:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Mapstatus location type changed from external shuffle service to executor after decommission migration
Issue key: SPARK-45310
Issue id: 13551859
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: Ngone51
Reporter: Ngone51
Creator: Ngone51
Created: 9/25/23 8:33
Updated: 10/11/23 7:29
Last Viewed: 7/17/24 20:45
Resolved: 10/11/23 4:05
Affects Version/s: 3.0.3, 3.1.3, 3.2.4, 3.3.2, 3.4.1, 3.5.0
Fix Version/s: 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: When migrating shuffle blocks during decommission, the updated mapstatus location doesn't respect the external shuffle service location when external shuffle service is enabled.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Oct 11 04:05:04 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kk88:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 11/Oct/23 04:05;dongjoon;Issue resolved by pull request 43112
[https://github.com/apache/spark/pull/43112];;;
Affects Version/s.1: 3.1.3
Affects Version/s.2: 3.2.4
Affects Version/s.3: 3.3.2
Affects Version/s.4: 3.4.1
Comment.1:

Summary: Support stage level task resource profile for yarn cluster when dynamic allocation disabled
Issue key: SPARK-45250
Issue id: 13551521
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: wbo4958
Reporter: wbo4958
Creator: wbo4958
Created: 9/21/23 11:50
Updated: 10/11/23 0:38
Last Viewed: 7/17/24 20:45
Resolved: 10/3/23 4:01
Affects Version/s: 3.4.1
Fix Version/s: 3.5.1, 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: [https://github.com/apache/spark/pull/37268] has introduced a new feature that supports stage-level schedule task resource profile for standalone cluster when dynamic allocation is disabled. It's really cool feature, especially for ML/DL cases, more details can be found in that PR.

 

The problem here is that the feature is only available for standalone cluster for now, but most users would also expect it can be used for other spark clusters like yarn and k8s.

 

So I file this issue to track this task.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): SPARK-45495
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Oct 03 04:01:10 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ki54:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 21/Sep/23 12:02;wbo4958;I made a PR to fix it [https://github.com/apache/spark/pull/43030.] Could someone help to review it?;;;, 21/Sep/23 12:07;wbo4958;Hi [~ivoson], May I ask why your previous PR [https://github.com/apache/spark/pull/37268]  supports task resource profile only for standalone cluster. what's your concern about not enabling this feature for yarn or k8s?;;;, 03/Oct/23 04:01;mridulm80;Issue resolved by pull request 43030
[https://github.com/apache/spark/pull/43030];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 21/Sep/23 12:07;wbo4958;Hi [~ivoson], May I ask why your previous PR [https://github.com/apache/spark/pull/37268]  supports task resource profile only for standalone cluster. what's your concern about not enabling this feature for yarn or k8s?;;;

Summary: Add more tests for Scala foreachBatch and streaming listeners 
Issue key: SPARK-44434
Issue id: 13543591
Parent id: 
Issue Type: Task
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: rangadi
Creator: rangadi
Created: 7/14/23 17:58
Updated: 10/10/23 1:49
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Connect, Structured Streaming
Due Date: 
Votes: 0
Labels: 
Description: Currently there are very few tests for Scala foreachBatch. Consider adding more tests and covering more test scenarios (multiple queries etc). 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): SPARK-42938
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Oct 10 01:49:34 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j5l4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 10/Oct/23 01:49;bcarlsonprogram;I'd like to work on this.;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: DataSourceV2 cannot report KeyGroupedPartitioning with multiple keys per partition
Issue key: SPARK-42716
Issue id: 13527620
Parent id: 
Issue Type: Bug
Status: In Progress
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: enricomi
Creator: enricomi
Created: 3/8/23 11:14
Updated: 10/10/23 0:17
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.3.0, 3.3.1, 3.3.2, 3.4.0, 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: From Spark 3.0.0 until 3.2.3, a DataSourceV2 could report its partitioning as {{KeyGroupedPartitioning}} via {{SupportsReportPartitioning}}, even if multiple keys belong to a partition.

With SPARK-37377, only if all partitions implement {{HasPartitionKey}}, the partition information reported through {{SupportsReportPartitioning}} is considered by catalyst. But this limits the number of keys per partition to 1.

Spark should continue to support the more general situation of {{KeyGroupedPartitioning}} with multiple keys per partition, like {{HashPartitioning}}.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Mar 08 11:23:06 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1gfi8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 08/Mar/23 11:22;apachespark;User 'EnricoMi' has created a pull request for this issue:
https://github.com/apache/spark/pull/40334;;;, 08/Mar/23 11:23;apachespark;User 'EnricoMi' has created a pull request for this issue:
https://github.com/apache/spark/pull/40334;;;
Affects Version/s.1: 3.3.1
Affects Version/s.2: 3.3.2
Affects Version/s.3: 3.4.0
Affects Version/s.4: 3.4.1
Comment.1: 08/Mar/23 11:23;apachespark;User 'EnricoMi' has created a pull request for this issue:
https://github.com/apache/spark/pull/40334;;;

Summary: DS V2 supports push down V2 UDF that has magic method
Issue key: SPARK-44913
Issue id: 13548254
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: coneyliu
Reporter: coneyliu
Creator: coneyliu
Created: 8/22/23 14:58
Updated: 10/9/23 4:47
Last Viewed: 7/17/24 20:45
Resolved: 9/29/23 23:37
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Right now we only support pushing down the V2 UDF that has not a magic method. Because the V2 UDF will be analyzed into the `ApplyFunctionExpression` which could be translated and pushed down. However, a V2 UDF that has the magic method will be analyzed into `StaticInvoke` or `Invoke` that can not be translated into V2 expression and then can not be pushed down to the data source. The magic method is suggested. So this PR adds the support of pushing down the V2 UDF that has a magic method.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Sep 29 23:37:03 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jxzc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 23/Aug/23 03:29;snoot;User 'ConeyLiu' has created a pull request for this issue:
https://github.com/apache/spark/pull/42612;;;, 29/Sep/23 23:37;csun;Issue resolved by pull request 42612
[https://github.com/apache/spark/pull/42612];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 29/Sep/23 23:37;csun;Issue resolved by pull request 42612
[https://github.com/apache/spark/pull/42612];;;

Summary: Decimal precision exceeds max precision error when using unary minus on min Decimal values on Scala 2.13 Spark
Issue key: SPARK-45438
Issue id: 13553173
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: navkumar
Creator: navkumar
Created: 10/6/23 17:46
Updated: 10/6/23 17:48
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.2.0, 3.2.1, 3.2.2, 3.2.3, 3.2.4, 3.3.0, 3.3.1, 3.3.2, 3.3.3, 3.4.0, 3.4.1, 3.5.0
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: scala
Description: When submitting an application to Spark built with Scala 2.13, there are issues with Decimal overflow that show up when using unary minus (and also {{abs()}} which uses unary minus under the hood.

Here is an example PySpark reproduce use case:

{code}
from decimal import Decimal

from pyspark.sql import SparkSession
from pyspark.sql.types import StructType,StructField, DecimalType

spark = SparkSession.builder \
      .master("local[*]") \
      .appName("decimal_precision") \
      .config("spark.rapids.sql.explain", "ALL") \
      .config("spark.sql.ansi.enabled", "true") \
      .config("spark.sql.legacy.allowNegativeScaleOfDecimal", 'true') \
      .getOrCreate()  

precision = 38
scale = 0
DECIMAL_MIN = Decimal('-' + ('9' * precision) + 'e' + str(-scale))

data = [[DECIMAL_MIN]]

schema = StructType([
    StructField("a", DecimalType(precision, scale), True)])
df = spark.createDataFrame(data=data, schema=schema)

df.selectExpr("a", "-a").show()
{code}

This particular example will run successfully on Spark built with Scala 2.12, but throw a java.math.ArithmeticException on Spark built with Scala 2.13. 

If you change the value of {{DECIMAL_MIN}} in the previous code to something just ahead of the original DECIMAL_MIN, you will not get an exception thrown, but instead you will get an incorrect answer (possibly due to overflow):

{code}
...
DECIMAL_MIN = Decimal('-8' + ('9' * (precision-1)) + 'e' + str(-scale))
...
{code} 

Output:
{code}
+--------------------+--------------------+
|                   a|               (- a)|
+--------------------+--------------------+
|-8999999999999999...|90000000000000000...|
+--------------------+--------------------+
{code}

It looks like the code in {{Decimal.scala}} uses {{scala.math.BigDecimal}}. See https://github.com/scala/bug/issues/11590 with updates on how Scala 2.13 handles BigDecimal. It looks like there is {{java.math.MathContext}} missing when performing these operations. 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 46:16.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ksb4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.2.1, 3.4.1, 3.5.0
Affects Version/s.2: 3.2.2
Affects Version/s.3: 3.2.3
Affects Version/s.4: 3.2.4
Comment.1:

Summary: Add extra per-rule validation for optimization rewrites.
Issue key: SPARK-44219
Issue id: 13541636
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: outis
Reporter: outis
Creator: outis
Created: 6/27/23 21:47
Updated: 10/6/23 3:20
Last Viewed: 7/17/24 20:45
Resolved: 10/6/23 3:20
Affects Version/s: 3.4.0, 3.4.1
Fix Version/s: 4.0.0
Component/s: Optimizer
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Adds per-rule validation checks for the following:

1.  aggregate expressions in Aggregate plans are valid.
2. Grouping key types in Aggregate plans cannot by of type Map. 
3. No dangling references have been generated.

This is validation is by default enabled for all tests or selectively using the spark.sql.planChangeValidation=true flag.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Oct 06 03:20:51 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1itlc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): cloud_fan
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 23/Aug/23 09:00;githubbot;User 'YannisSismanis' has created a pull request for this issue:
https://github.com/apache/spark/pull/41763;;;, 06/Oct/23 03:20;cloud_fan;Issue resolved by pull request 41763
[https://github.com/apache/spark/pull/41763];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 06/Oct/23 03:20;cloud_fan;Issue resolved by pull request 41763
[https://github.com/apache/spark/pull/41763];;;

Summary: MLlib GBTClassifier has wrong impurity method 'variance' instead of 'gini' or 'entropy'. 
Issue key: SPARK-44848
Issue id: 13547715
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: lisi
Creator: lisi
Created: 8/17/23 12:04
Updated: 10/3/23 11:40
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: MLlib
Due Date: 
Votes: 1
Labels: 
Description: Impurity method 'variance' should only be used for regressors, *not* classifiers. For classifiers gini and entropy should be available as it is already the case for the RandomForestClassifier [https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.ml.classification.RandomForestClassifier.html] .

Because of this bug 'minInfoGain' hyperparameter cannot be tuned to combat overfitting. 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Oct 03 11:40:48 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1juns:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 03/Oct/23 11:40;oumarnour;Hello,

I have the same issue. I want to know if that issue is solved ?

Thanks;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Deadlock caused by rdd replication level of 2
Issue key: SPARK-45057
Issue id: 13549452
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: warrenzhu25
Reporter: warrenzhu25
Creator: warrenzhu25
Created: 9/1/23 23:32
Updated: 9/28/23 23:53
Last Viewed: 7/17/24 20:45
Resolved: 9/28/23 23:52
Affects Version/s: 3.4.1
Fix Version/s: 3.3.4, 3.4.2, 3.5.1, 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description:  
When 2 tasks try to compute same rdd with replication level of 2 and running on only 2 executors. Deadlock will happen.

Task only release lock after writing into local machine and replicate to remote executor.

 
||Time||Exe 1 (Task Thread T1)||Exe 1 (Shuffle Server Thread T2)||Exe 2 (Task Thread T3)||Exe 2 (Shuffle Server Thread T4)||
|T0|write lock of rdd| | | |
|T1| | |write lock of rdd| |
|T2|replicate -> UploadBlockSync (blocked by T4)| | | |
|T3| | | |Received UploadBlock request from T1 (blocked by T4)|
|T4| | |replicate -> UploadBlockSync (blocked by T2)| |
|T5| |Received UploadBlock request from T3 (blocked by T1)| | |
|T6|Deadlock|Deadlock|Deadlock|Deadlock|
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Sep 28 23:52:57 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k5dk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 27/Sep/23 06:37;Ngone51;In the case of "Received UploadBlock request from T1 (blocked by T4)", shouldn't it be blocked by T3?;;;, 28/Sep/23 23:52;mridulm80;Issue resolved by pull request 43067
[https://github.com/apache/spark/pull/43067];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 28/Sep/23 23:52;mridulm80;Issue resolved by pull request 43067
[https://github.com/apache/spark/pull/43067];;;

Summary: Switch languages consistently across docs for all code snippets
Issue key: SPARK-44820
Issue id: 13547434
Parent id: 13546596
Issue Type: Sub-task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: panbingkun
Reporter: allisonwang-db
Creator: allisonwang-db
Created: 8/15/23 18:57
Updated: 9/25/23 2:34
Last Viewed: 7/17/24 20:45
Resolved: 8/25/23 0:49
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 3.5.0, 4.0.0
Component/s: Documentation
Due Date: 
Votes: 0
Labels: 
Description: When a user chooses a different language for a code snippet, all code snippets on that page should switch to the chosen language. This was the behavior for, for example, Spark 2.0 doc: [https://spark.apache.org/docs/2.0.0/structured-streaming-programming-guide.html]

But it was broken for later docs, for example the Spark 3.4.1 doc: [https://spark.apache.org/docs/latest/quick-start.html]

We should fix this behavior change and possibly add test cases to prevent future regressions.
Environment: 
Log Work: allisonwang-db commented on PR #474:
URL: https://github.com/apache/spark-website/pull/474#issuecomment-1730342331

   Hi @panbingkun this is an important bug fix and we should merge it! Shall we re-open this?


;21/Sep/23 21:44;githubbot;600, panbingkun commented on PR #474:
URL: https://github.com/apache/spark-website/pull/474#issuecomment-1730705788

   > Hi @panbingkun this is an important bug fix and we should merge it! Shall we re-open this?
   
   Actually, this feature has been fixed in `Spark` project, https://github.com/apache/spark/pull/42657
   The current fixes are: master, branch-3.5 (https://github.com/apache/spark/pull/42657), and branch-3.4 (https://github.com/apache/spark/pull/42989)


;22/Sep/23 02:07;githubbot;600, allisonwang-db commented on PR #474:
URL: https://github.com/apache/spark-website/pull/474#issuecomment-1730748815

   Yea we should apply the change in the `spark` repo to the actual released Spark website docs here. @panbingkun which option do you think is better?


;22/Sep/23 03:22;githubbot;600, panbingkun commented on PR #474:
URL: https://github.com/apache/spark-website/pull/474#issuecomment-1730757033

   > Yea we should apply the change in the `spark` repo to the actual released Spark website docs here. @panbingkun which option do you think is better?
   
   If we are not suitable for republishing historically published documents, we can only manually update them on Spark website. If possible, I can complete it.


;22/Sep/23 03:37;githubbot;600, allisonwang-db commented on PR #474:
URL: https://github.com/apache/spark-website/pull/474#issuecomment-1731741985

   @panbingkun yes let's update the spark website (this repo) to fix this UI issue for published docs.


;22/Sep/23 16:55;githubbot;600, panbingkun commented on PR #474:
URL: https://github.com/apache/spark-website/pull/474#issuecomment-1732813770

   > @panbingkun yes let's update the spark website (this repo) to fix this UI issue for published docs.
   
   Okay, let me to fix it.


;25/Sep/23 02:34;githubbot;600
Original Estimate: 
Remaining Estimate: 0
Time Spent: 3600
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 0
Σ Time Spent: 3600
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Aug 25 00:49:22 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jsxc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 16/Aug/23 06:26;podongfeng;update:

this issue emerged since 3.1.1 (note that we don't have an official 3.1.0, since 3.1.0 was a mistake https://spark.apache.org/news/index.html)

3.0.3 works well: https://spark.apache.org/docs/3.0.3/structured-streaming-programming-guide.html

3.1.1 was broken: https://spark.apache.org/docs/3.1.1/structured-streaming-programming-guide.html

;;;, 24/Aug/23 02:28;panbingkun;Let me try to investigate it.;;;, 25/Aug/23 00:49;Gengliang.Wang;Resolved in https://github.com/apache/spark/pull/42657;;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 24/Aug/23 02:28;panbingkun;Let me try to investigate it.;;;

Summary: Arrow DurationWriter fails when vector is at capacity
Issue key: SPARK-45256
Issue id: 13551547
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: sgoos-db
Reporter: sgoos-db
Creator: sgoos-db
Created: 9/21/23 15:04
Updated: 9/22/23 16:17
Last Viewed: 7/17/24 20:45
Resolved: 9/22/23 16:17
Affects Version/s: 3.4.0, 3.4.1, 3.4.2, 3.5.0, 3.5.1
Fix Version/s: 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: The DurationWriter fails if more values are written than the initial capacity of the DurationVector (4032). Fix by using `setSafe` instead of `set` method. 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Sep 22 16:17:36 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kiaw:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 22/Sep/23 16:17;dongjoon;Issue resolved by pull request 43035
[https://github.com/apache/spark/pull/43035];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.4.2
Affects Version/s.3: 3.5.0
Affects Version/s.4: 3.5.1
Comment.1:

Summary: Improve error handling in Connect foreachBatch worker.
Issue key: SPARK-44463
Issue id: 13543838
Parent id: 
Issue Type: Task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: 
Reporter: rangadi
Creator: rangadi
Created: 7/17/23 19:23
Updated: 9/20/23 3:45
Last Viewed: 7/17/24 20:45
Resolved: 9/20/23 3:44
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: Connect, Structured Streaming
Due Date: 
Votes: 0
Labels: 
Description: An error in user code inside foreachBatch worker is not propagated correctly to the user. We should. 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): SPARK-42938
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Sep 20 03:45:08 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j740:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 20/Sep/23 03:44;gurwls223;Issue resolved by pull request 42986
[https://github.com/apache/spark/pull/42986];;;, 20/Sep/23 03:45;snoot;User 'bogao007' has created a pull request for this issue:
https://github.com/apache/spark/pull/42986;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 20/Sep/23 03:45;snoot;User 'bogao007' has created a pull request for this issue:
https://github.com/apache/spark/pull/42986;;;

Summary: Switch languages consistently across docs for all code snippets (Spark 3.4 and below)
Issue key: SPARK-45210
Issue id: 13551170
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: gurwls223
Reporter: gurwls223
Creator: gurwls223
Created: 9/19/23 2:56
Updated: 9/19/23 5:52
Last Viewed: 7/17/24 20:45
Resolved: 9/19/23 5:52
Affects Version/s: 3.1.3, 3.2.4, 3.3.2, 3.4.1
Fix Version/s: 3.3.4, 3.4.2
Component/s: Documentation
Due Date: 
Votes: 0
Labels: 
Description: Similar with SPARK-44820 but needs different change as they were refactored at https://github.com/apache/spark/commit/12b9b771c7ad75cb90c0a51cd2d0581dd3c719e2
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Sep 19 05:52:49 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kfz4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 19/Sep/23 05:52;gurwls223;Issue resolved by pull request 42989
[https://github.com/apache/spark/pull/42989];;;
Affects Version/s.1: 3.2.4
Affects Version/s.2: 3.3.2
Affects Version/s.3: 3.4.1
Affects Version/s.4: 
Comment.1:

Summary: The ArrayInsert function should make explicit casting when element type not equals derived component type
Issue key: SPARK-45078
Issue id: 13549654
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: fanjia
Reporter: taoran
Creator: taoran
Created: 9/5/23 11:24
Updated: 9/18/23 18:56
Last Viewed: 7/17/24 20:45
Resolved: 9/17/23 8:17
Affects Version/s: 3.4.1
Fix Version/s: 3.4.2, 3.5.1, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Generally speaking, array_insert has same insert semantic with  array_prepend/array_append. however, if we run sql use element cast like below, array_prepend/array_append can get right result. but array_insert failed.
{code:java}
spark-sql (default)> select array_prepend(array(1), cast(2 as tinyint));
[2,1]
Time taken: 0.123 seconds, Fetched 1 row(s) {code}
{code:java}
spark-sql (default)> select array_append(array(1), cast(2 as tinyint)); 
[1,2] 
Time taken: 0.206 seconds, Fetched 1 row(s)
{code}
{code:java}
spark-sql (default)> select array_insert(array(1), 2, cast(2 as tinyint));
[DATATYPE_MISMATCH.ARRAY_FUNCTION_DIFF_TYPES] Cannot resolve "array_insert(array(1), 2, CAST(2 AS TINYINT))" due to data type mismatch: Input to `array_insert` should have been "ARRAY" followed by a value with same element type, but it's ["ARRAY<INT>", "TINYINT"].; line 1 pos 7;
'Project [unresolvedalias(array_insert(array(1), 2, cast(2 as tinyint)), None)]
+- OneRowRelation {code}
The reported error is clear, however, we may should do explicit casting here. because multiset type such as array or map allow the operands of same type family  to coexist.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Sep 18 18:56:22 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k6mg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 17/Sep/23 08:17;maxgekk;Issue resolved by pull request 42951
[https://github.com/apache/spark/pull/42951];;;, 18/Sep/23 18:56;dongjoon;This is resolved via https://github.com/apache/spark/pull/42960;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 18/Sep/23 18:56;dongjoon;This is resolved via https://github.com/apache/spark/pull/42960;;;

Summary: Parquet reads fail with "RuntimeException: Unable to create Parquet converter for data type "timestamp_ntz" due to incorrect schema inference
Issue key: SPARK-45194
Issue id: 13550996
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: ivan.sadikov
Creator: ivan.sadikov
Created: 9/18/23 4:59
Updated: 9/18/23 5:03
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: I found that Parquet reads could fail due to incorrect schema inference with two conflicting types exist in files. This is caused by the fact that schema inference only considers one file by default which could contain different types than what in other file.

We have {{spark.sql.parquet.mergeSchema}} is set to `false` by default. This causes schema inference to pick a file (depending on the order the file system returns files) and infer schema based on that file. However, if you have conflicting types or a smaller/narrower type is selected, instead of failing during schema inference, an exception is thrown during the subsequent read.

In this case, we infer schema based on the file with TIMESTAMP_NTZ and fail to read the file that contains TIMESTAMP_LTZ:
{code:java}
[info]   Cause: java.lang.RuntimeException: Unable to create Parquet converter for data type "timestamp_ntz" whose Parquet type is int64 time(TIMESTAMP(MILLIS,true))
[info]   at org.apache.spark.sql.execution.datasources.parquet.ParquetVectorUpdaterFactory.convertErrorForTimestampNTZ(ParquetVectorUpdaterFactory.java:209)
[info]   at org.apache.spark.sql.execution.datasources.parquet.ParquetVectorUpdaterFactory.validateTimestampType(ParquetVectorUpdaterFactory.java:203)
[info]   at org.apache.spark.sql.execution.datasources.parquet.ParquetVectorUpdaterFactory.getUpdater(ParquetVectorUpdaterFactory.java:121)
[info]   at org.apache.spark.sql.execution.datasources.parquet.VectorizedColumnReader.readBatch(VectorizedColumnReader.java:175){code}
Note that if the file with TIMESTAMP_LTZ is selected, the read succeeds.

 

Here is the repro as a unit test that you can run in Spark master. Just add the test to ParquetIOSuite or some other test suite.
{code:java}
import org.apache.hadoop.conf._
import org.apache.hadoop.fs._
import org.apache.parquet.example.data.simple._
import org.apache.parquet.hadoop.example._
import org.apache.parquet.schema._

// Creates a Parquet file with two simple columns: integer and timestamp.
// Depending on isUTC flag, the timestamp is either NTZ or LTZ.
private def createParquetFile(path: String, isUTC: Boolean): Unit = {
  val schema = MessageTypeParser.parseMessageType(
    s"""
    message schema {
      optional int32 a;
      optional int64 ts (TIMESTAMP(MILLIS, $isUTC));
    }
    """
  )
  val conf = new Configuration(false)
  conf.set("parquet.example.schema", schema.toString)
  val writer = ExampleParquetWriter.builder(new Path(path)).withConf(conf).build()
  for (i <- 0 until 2) {
    val group = new SimpleGroup(schema)
    group.add("a", 1)
    group.add("ts", System.currentTimeMillis)
    writer.write(group)
  }
  writer.close()
}

test("repro") {
  withTempPath { dir =>
    createParquetFile(dir + "/file-1.parquet", false) // NTZ
    createParquetFile(dir + "/file-2.parquet", true) // LTZ    

    val df = spark.read.parquet(dir.getAbsolutePath)
    df.show() // fails
  }
} {code}
If you run the repro as is, you will get: 
{code:java}
[info]   Cause: java.lang.RuntimeException: Unable to create Parquet converter for data type "timestamp_ntz" whose Parquet type is int64 time(TIMESTAMP(MILLIS,true)) {code}
If you swap the files (file names), the read succeeds.
{code:java}
+---+--------------------+
|  a|                  ts|
+---+--------------------+
|  1|2023-09-17 21:59:...|
|  1|2023-09-17 21:59:...|
|  1|2023-09-17 21:59:...|
|  1|2023-09-17 21:59:...|
+---+--------------------+ {code}
If you set spark.sql.parquet.mergeSchema to true, the schema inference fails with
{code:java}
[info]   org.apache.spark.SparkException: [CANNOT_MERGE_SCHEMAS] Failed merging schemas:
[info] Initial schema:
[info] "STRUCT<a: INT, ts: TIMESTAMP_NTZ>"
[info] Schema that cannot be merged with the initial schema:
[info] "STRUCT<a: INT, ts: TIMESTAMP>". {code}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Sep 18 05:00:22 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kewg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 18/Sep/23 05:00;ivan.sadikov;cc [~gengliang] [~cloud_fan];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 4.0.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: AggregatingAccumulator with TypedImperativeAggregate throwing ClassCastException
Issue key: SPARK-45176
Issue id: 13550779
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: hcampbell
Creator: hcampbell
Created: 9/15/23 3:48
Updated: 9/15/23 3:50
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.0, 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: Probably related to SPARK-39044. But potentially also this comment in Executor.scala.
{quote}// TODO: do not serialize value twice
val directResult = new DirectTaskResult(valueByteBuffer, accumUpdates, metricPeaks)
{quote}
The class cast exception I'm seeing is
{quote}
java.lang.ClassCastException: class [B cannot be cast to class org.apache.spark.sql.catalyst.expressions.aggregate.Reservoir
{quote}
But I've seen it with other aggregation buffers like QuantileSummaries as well.

It's my belief that withBufferSerialized() for the Aggregating Accumulator is being called twice, leading to on serializeAggregateBuffernPlace(buffer)
also being called twice for the an Imperative aggregate, the second time round, the buffer is already a byte array and the asInstanceOf[T] in getBufferObject is throwing.

This doesn't appear to happen on all runs, and it might be its only occurring when there's a transitive exception. I have a further suspicion that the cause might originate with
{quote}
SerializationDebugger.improveException
{quote}
which is traversing the task and forcing writeExternal, to be called.

Setting
|spark.serializer.extraDebugInfo|false|

Seems to make things a bit more reliable (I haven't seen the error while this setting is on), and points strongly in that direction.

Stack trace:
{quote}
Job aborted due to stage failure: Authorized committer (attemptNumber=0, stage=15, partition=10) failed; but task commit success, data duplication may happen. reason=ExceptionFailure(java.io.IOException,java.lang.ClassCastException: class [B cannot be cast to class org.apache.spark.sql.catalyst.expressions.aggregate.Reservoir ([B is in module java.base of loader 'bootstrap'; org.apache.spark.sql.catalyst.expressions.aggregate.Reservoir is in unnamed module of loader 'app'),[Ljava.lang.StackTraceElement;@7fe2f462,java.io.IOException: java.lang.ClassCastException: class [B cannot be cast to class org.apache.spark.sql.catalyst.expressions.aggregate.Reservoir ([B is in module java.base of loader 'bootstrap'; org.apache.spark.sql.catalyst.expressions.aggregate.Reservoir is in unnamed module of loader 'app')
at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1502)
at org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:59)
at java.base/java.io.ObjectOutputStream.writeExternalData(Unknown Source)
at java.base/java.io.ObjectOutputStream.writeOrdinaryObject(Unknown Source)
at java.base/java.io.ObjectOutputStream.writeObject0(Unknown Source)
at java.base/java.io.ObjectOutputStream.writeObject(Unknown Source)
at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)
at org.apache.spark.serializer.SerializerHelper$.serializeToChunkedBuffer(SerializerHelper.scala:42)
at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:643)
at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
at java.base/java.lang.Thread.run(Unknown Source)
Caused by: java.lang.ClassCastException: class [B cannot be cast to class org.apache.spark.sql.catalyst.expressions.aggregate.Reservoir ([B is in module java.base of loader 'bootstrap'; org.apache.spark.sql.catalyst.expressions.aggregate.Reservoir is in unnamed module of loader 'app')
at org.apache.spark.sql.catalyst.expressions.aggregate.ReservoirSample.serialize(ReservoirSample.scala:33)
at org.apache.spark.sql.catalyst.expressions.aggregate.TypedImperativeAggregate.serializeAggregateBufferInPlace(interfaces.scala:624)
at org.apache.spark.sql.execution.AggregatingAccumulator.withBufferSerialized(AggregatingAccumulator.scala:206)
at org.apache.spark.sql.execution.AggregatingAccumulator.withBufferSerialized(AggregatingAccumulator.scala:33)
at org.apache.spark.util.AccumulatorV2.writeReplace(AccumulatorV2.scala:186)
at jdk.internal.reflect.GeneratedMethodAccessor62.invoke(Unknown Source)
at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
at java.base/java.lang.reflect.Method.invoke(Unknown Source)
at java.base/java.io.ObjectStreamClass.invokeWriteReplace(Unknown Source)
at java.base/java.io.ObjectOutputStream.writeObject0(Unknown Source)
at java.base/java.io.ObjectOutputStream.writeObject(Unknown Source)
at org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$2(TaskResult.scala:62)
at org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$2$adapted(TaskResult.scala:62)
at scala.collection.immutable.Vector.foreach(Vector.scala:1856)
at org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:62)
at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1495)
... 11 more
 
{quote}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 48:59.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kdk8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Data lost after union using spark.sql.parquet.enableNestedColumnVectorizedReader=true
Issue key: SPARK-44805
Issue id: 13547273
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: bersprockets
Reporter: jwozniak
Creator: jwozniak
Created: 8/14/23 14:46
Updated: 9/13/23 15:32
Last Viewed: 7/17/24 20:45
Resolved: 9/8/23 20:11
Affects Version/s: 3.3.1, 3.4.1
Fix Version/s: 3.3.4, 3.4.2, 3.5.1, 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: correctness, pull-request-available
Description: When union-ing two DataFrames read from parquet containing nested structures (2 fields of array types where one is double and second is integer) data from the second field seems to be lost (zeros are set instead). 

This seems to be the case only if nested vectorised reader is used (spark.sql.parquet.enableNestedColumnVectorizedReader=true). 

The following Python code reproduces the problem: 
{code:java}
from pyspark.sql import SparkSession
from pyspark.sql.types import *

# PREPARING DATA
data1 = []
data2 = []

for i in range(2): 
    data1.append( (([1,2,3],[1,1,2]),i))
    data2.append( (([1.0,2.0,3.0],[1,1]),i+10))

schema1 = StructType([
        StructField('value', StructType([
             StructField('f1', ArrayType(IntegerType()), True),
             StructField('f2', ArrayType(IntegerType()), True)             
             ])),
         StructField('id', IntegerType(), True)
])

schema2 = StructType([
        StructField('value', StructType([
             StructField('f1', ArrayType(DoubleType()), True),
             StructField('f2', ArrayType(IntegerType()), True)             
             ])),
         StructField('id', IntegerType(), True)
])

spark = SparkSession.builder.getOrCreate()
data_dir = "/user/<user>/"

df1 = spark.createDataFrame(data1, schema1)
df1.write.mode('overwrite').parquet(data_dir + "data1") 
df2 = spark.createDataFrame(data2, schema2)
df2.write.mode('overwrite').parquet(data_dir + "data2") 


# READING DATA
parquet1 = spark.read.parquet(data_dir + "data1")
parquet2 = spark.read.parquet(data_dir + "data2")


# UNION
out = parquet1.union(parquet2)


parquet1.select("value.f2").distinct().show()
out.select("value.f2").distinct().show()
print(parquet1.collect())
print(out.collect()) {code}
Output: 
{code:java}
+---------+
|       f2|
+---------+
|[1, 1, 2]|
+---------+

+---------+
|       f2|
+---------+
|[0, 0, 0]|
|   [1, 1]|
+---------+


[
Row(value=Row(f1=[1, 2, 3], f2=[1, 1, 2]), id=0), 
Row(value=Row(f1=[1, 2, 3], f2=[1, 1, 2]), id=1)
]

[
Row(value=Row(f1=[1.0, 2.0, 3.0], f2=[0, 0, 0]), id=0), 
Row(value=Row(f1=[1.0, 2.0, 3.0], f2=[0, 0, 0]), id=1), 
Row(value=Row(f1=[1.0, 2.0, 3.0], f2=[1, 1]), id=10), 
Row(value=Row(f1=[1.0, 2.0, 3.0], f2=[1, 1]), id=11)
] {code}
Please notice that values for the field f2 are lost after the union is done. This only happens when this data is read from parquet files. 

Could you please look into this? 

Best regards,

Jakub
Environment: pySpark, linux, hadoop, parquet. 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Sep 08 20:11:31 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jrxk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 15/Aug/23 00:14;bersprockets;[~sunchao] 

It seems to be some weird interaction between Parquet nested vectorization and the {{Cast}} expression:
{noformat}
drop table if exists t1;

create table t1 using parquet as
select * from values
(named_struct('f1', array(1, 2, 3), 'f2', array(1, 1, 2)))
as (value);

select value from t1;
{"f1":[1,2,3],"f2":[1,1,2]}         <== this is expected
Time taken: 0.126 seconds, Fetched 1 row(s)

select cast(value as struct<f1:array<double>,f2:array<int>>) AS value from t1;
{"f1":[1.0,2.0,3.0],"f2":[0,0,0]}   <== this is not expected
Time taken: 0.102 seconds, Fetched 1 row(s)

set spark.sql.parquet.enableNestedColumnVectorizedReader=false;

select cast(value as struct<f1:array<double>,f2:array<int>>) AS value from t1;
{"f1":[1.0,2.0,3.0],"f2":[1,1,2]}   <== now has expected value
Time taken: 0.244 seconds, Fetched 1 row(s)
{noformat}
The union operation adds this {{Cast}} expression because {{value}} has different datatypes between your two dataframes.;;;, 28/Aug/23 15:21;jwozniak;Hello,

Is it possible to know any ETA on this one?

Is this something that could potentially be fixed in the next version of Spark or rather not? 

Thanks,

Jakub;;;, 05/Sep/23 23:50;bersprockets;I looked at this yesterday and I think I have a handle on what's going on. I will make a PR in the coming days.;;;, 06/Sep/23 07:30;jwozniak;Would be great, thanks! ;;;, 07/Sep/23 15:47;bersprockets;PR here: https://github.com/apache/spark/pull/42850;;;, 08/Sep/23 03:23;snoot;User 'bersprockets' has created a pull request for this issue:
https://github.com/apache/spark/pull/42850;;;, 08/Sep/23 20:11;dongjoon;Issue resolved by pull request 42850
[https://github.com/apache/spark/pull/42850];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 28/Aug/23 15:21;jwozniak;Hello,

Is it possible to know any ETA on this one?

Is this something that could potentially be fixed in the next version of Spark or rather not? 

Thanks,

Jakub;;;

Summary: Implement missing otherCopyArgs for the MultiCommutativeOp expression
Issue key: SPARK-45117
Issue id: 13550258
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: scnakandala
Reporter: scnakandala
Creator: scnakandala
Created: 9/11/23 17:28
Updated: 9/12/23 15:53
Last Viewed: 7/17/24 20:45
Resolved: 9/12/23 15:53
Affects Version/s: 3.4.1
Fix Version/s: 3.5.1, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Calling toJSON on a `MultiCommutativeOp` throws an assertion error as it does not implement the `otherCopyArgs` method.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Sep 12 15:53:05 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kacg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 12/Sep/23 15:53;cloud_fan;Issue resolved by pull request 42873
[https://github.com/apache/spark/pull/42873];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: create hive table with invalid column should return error class
Issue key: SPARK-44911
Issue id: 13548206
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: Zing
Reporter: Zing
Creator: Zing
Created: 8/22/23 12:33
Updated: 9/12/23 8:55
Last Viewed: 7/17/24 20:45
Resolved: 9/12/23 8:55
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Sep 12 08:55:22 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jxow:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 06/Sep/23 13:29;Zing;https://github.com/apache/spark/pull/42609;;;, 12/Sep/23 08:55;maxgekk;Issue resolved by pull request 42609
[https://github.com/apache/spark/pull/42609];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 12/Sep/23 08:55;maxgekk;Issue resolved by pull request 42609
[https://github.com/apache/spark/pull/42609];;;

Summary: Alter table with invalid default value will not report error
Issue key: SPARK-45075
Issue id: 13549612
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: fanjia
Reporter: fanjia
Creator: fanjia
Created: 9/5/23 3:49
Updated: 9/12/23 6:33
Last Viewed: 7/17/24 20:45
Resolved: 9/8/23 20:18
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 3.4.2, 3.5.1, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: create table t(i boolean, s bigint);
alter table t alter column s set default badvalue;
 
The code wouldn't report error on DataSource V2, not align with V1.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Sep 12 06:29:08 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k6d4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 05/Sep/23 14:18;ignitetcbot;User 'Hisoka-X' has created a pull request for this issue:
https://github.com/apache/spark/pull/42810;;;, 08/Sep/23 20:18;dongjoon;Issue resolved by pull request 42810
[https://github.com/apache/spark/pull/42810];;;, 12/Sep/23 06:29;dongjoon;This landed at branch-3.4 via https://github.com/apache/spark/pull/42876;;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 08/Sep/23 20:18;dongjoon;Issue resolved by pull request 42810
[https://github.com/apache/spark/pull/42810];;;

Summary: Multi-tenant history server
Issue key: SPARK-45126
Issue id: 13550308
Parent id: 
Issue Type: Wish
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: ramuramaiah
Creator: ramuramaiah
Created: 9/12/23 4:48
Updated: 9/12/23 4:48
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: Spark history server makes use of the configuration "spark.history.fs.logDirectory" to locate the log events. This works well for a single tenant. When it is used for a multi-tenant deployment, the log events of multiple tenants are stored in a single directory which does not provide a logical separation of events for each tenant.

The proposal/wish is to have a support for Multi-tenant history server, where-in the configuration "spark.history.fs.logDirectory" can be a base directory. The sub-directories can contain the log events for each tenant. The sub-directories can be named after each tenant, for e.g. "tenant1", "tenant2" etc.

When it is combined to work with Spark Driver/Executor which makes use of the property "spark.eventLog.dir", the value of this property can be appropriately set for each tenant.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 48:56.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kank:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Spark 3.4 multi-column sum slows with many columns
Issue key: SPARK-44912
Issue id: 13548238
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: 
Reporter: brbickel
Creator: brbickel
Created: 8/22/23 14:16
Updated: 9/11/23 19:43
Last Viewed: 7/17/24 20:45
Resolved: 9/11/23 19:43
Affects Version/s: 3.4.0, 3.4.1
Fix Version/s: 
Component/s: PySpark
Due Date: 
Votes: 0
Labels: 
Description: The code below is a minimal reproducible example of an issue I discovered with Pyspark 3.4.x. I want to sum the values of multiple columns and put the sum of those columns (per row) into a new column. This code works and returns in a reasonable amount of time in Pyspark 3.3.x, but is extremely slow in Pyspark 3.4.x when the number of columns grows. See below for execution timing summary as N varies.
{code:java}
import pyspark.sql.functions as F
import random
import string
from functools import reduce
from operator import add
from pyspark.sql import SparkSession

spark = SparkSession.builder.getOrCreate()

# generate a dataframe N columns by M rows with random 8 digit column 
# names and random integers in [-5,10]
N = 30
M = 100
columns = [''.join(random.choices(string.ascii_uppercase +
                                  string.digits, k=8))
           for _ in range(N)]
data = [tuple([random.randint(-5,10) for _ in range(N)])
        for _ in range(M)]

df = spark.sparkContext.parallelize(data).toDF(columns)
# 3 ways to add a sum column, all of them slow for high N in spark 3.4
df = df.withColumn("col_sum1", sum(df[col] for col in columns))
df = df.withColumn("col_sum2", reduce(add, [F.col(col) for col in columns]))
df = df.withColumn("col_sum3", F.expr("+".join(columns))) {code}
Timing results for Spark 3.3:
||N||Exe Time (s)||
|5|0.514|
|10|0.248|
|15|0.327|
|20|0.403|
|25|0.279|
|30|0.322|
|50|0.430|

Timing results for Spark 3.4:
||N||Exe Time (s)||
|5|0.379|
|10|0.318|
|15|0.405|
|20|1.32|
|25|28.8|
|30|448|
|50|>10000 (did not finish)|
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): SPARK-45071
Inward issue link (Duplicate): 
Outward issue link (Duplicate): SPARK-45071
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Sep 11 19:43:46 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jxvs:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 10/Sep/23 17:15;bersprockets;It looks like this was fixed with SPARK-45071. Your issue was reported earlier, but missed somehow.;;;, 11/Sep/23 19:43;brbickel;Verified build containing linked issue fix solved the problem.;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 11/Sep/23 19:43;brbickel;Verified build containing linked issue fix solved the problem.;;;

Summary:  percentile_cont gets internal error when user input fails runtime replacement's input type check
Issue key: SPARK-45106
Issue id: 13550053
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: bersprockets
Reporter: bersprockets
Creator: bersprockets
Created: 9/8/23 14:19
Updated: 9/8/23 19:40
Last Viewed: 7/17/24 20:45
Resolved: 9/8/23 19:40
Affects Version/s: 3.3.2, 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.5.1
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: This query throws an internal error rather than producing a useful error message:
{noformat}
select percentile_cont(b) WITHIN GROUP (ORDER BY a DESC) as x 
from (values (12, 0.25), (13, 0.25), (22, 0.25)) as (a, b);

[INTERNAL_ERROR] Cannot resolve the runtime replaceable expression "percentile_cont(a, b)". The replacement is unresolved: "percentile(a, b, 1)".
org.apache.spark.SparkException: [INTERNAL_ERROR] Cannot resolve the runtime replaceable expression "percentile_cont(a, b)". The replacement is unresolved: "percentile(a, b, 1)".
	at org.apache.spark.SparkException$.internalError(SparkException.scala:92)
	at org.apache.spark.SparkException$.internalError(SparkException.scala:96)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6(CheckAnalysis.scala:313)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$6$adapted(CheckAnalysis.scala:277)
...
{noformat}
It should instead inform the user that the input expression must be foldable.

{{PercentileCont}} does not check the user's input. If the runtime replacement (an instance of {{Percentile}}) rejects the user's input, the runtime replacement ends up unresolved.

Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Sep 08 19:40:13 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k934:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 08/Sep/23 19:40;dongjoon;This is resolved via https://github.com/apache/spark/pull/42857;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 4.0.0
Affects Version/s.4: 
Comment.1:

Summary: reflect() fails with an internal error on NULL class and method
Issue key: SPARK-45100
Issue id: 13549931
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: maxgekk
Reporter: maxgekk
Creator: maxgekk
Created: 9/7/23 13:22
Updated: 9/8/23 16:00
Last Viewed: 7/17/24 20:45
Resolved: 9/8/23 8:13
Affects Version/s: 3.3.2, 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.3.4, 3.4.2, 3.5.0, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: The example below demonstrates the issue:

{code:sql}
spark-sql (default)> select reflect('java.util.UUID', CAST(NULL AS STRING));
[INTERNAL_ERROR] The Spark SQL phase analysis failed with an internal error. You hit a bug in Spark or the Spark plugins you use. Please, report this bug to the corresponding communities or vendors, and provide the full stack trace.
{code}

Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): SPARK-45079
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Sep 08 15:09:18 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k8c0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 08/Sep/23 08:13;maxgekk;Issue resolved by pull request 42849
[https://github.com/apache/spark/pull/42849];;;, 08/Sep/23 15:09;dongjoon;This is backported to branch-3.4 via https://github.com/apache/spark/pull/42855;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 4.0.0
Affects Version/s.4: 
Comment.1: 08/Sep/23 15:09;dongjoon;This is backported to branch-3.4 via https://github.com/apache/spark/pull/42855;;;

Summary: percentile_approx() fails with an internal error on NULL accuracy
Issue key: SPARK-45079
Issue id: 13549658
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: maxgekk
Reporter: maxgekk
Creator: maxgekk
Created: 9/5/23 11:46
Updated: 9/7/23 13:22
Last Viewed: 7/17/24 20:45
Resolved: 9/6/23 7:33
Affects Version/s: 3.3.2, 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.3.4, 3.4.2, 3.5.0, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: The example below demonstrates the issue:

{code:sql}
spark-sql (default)> SELECT percentile_approx(col, array(0.5, 0.4, 0.1), NULL) FROM VALUES (0), (1), (2), (10) AS tab(col);
[INTERNAL_ERROR] The Spark SQL phase analysis failed with an internal error. You hit a bug in Spark or the Spark plugins you use. Please, report this bug to the corresponding communities or vendors, and provide the full stack trace.
{code}

Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): SPARK-45100
Outward issue link (Cloners): SPARK-45060
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Sep 06 10:33:07 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k6nc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 05/Sep/23 11:59;aparna.garg;User 'MaxGekk' has created a pull request for this issue:
https://github.com/apache/spark/pull/42817;;;, 06/Sep/23 07:33;maxgekk;Issue resolved by pull request 42817
[https://github.com/apache/spark/pull/42817];;;, 06/Sep/23 10:33;aparna.garg;User 'MaxGekk' has created a pull request for this issue:
https://github.com/apache/spark/pull/42835;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 4.0.0
Affects Version/s.4: 
Comment.1: 06/Sep/23 07:33;maxgekk;Issue resolved by pull request 42817
[https://github.com/apache/spark/pull/42817];;;

Summary: Display hexadecimal for thread lock hash code
Issue key: SPARK-45086
Issue id: 13549731
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: yao
Reporter: yao
Creator: yao
Created: 9/6/23 4:06
Updated: 9/7/23 7:18
Last Viewed: 7/17/24 20:45
Resolved: 9/7/23 7:18
Affects Version/s: 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 4.0.0
Component/s: Web UI
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Sep 07 07:18:50 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k73k:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 06/Sep/23 04:15;snoot;User 'yaooqinn' has created a pull request for this issue:
https://github.com/apache/spark/pull/42826;;;, 07/Sep/23 07:18;yao;Issue resolved by pull request 42826
[https://github.com/apache/spark/pull/42826];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 4.0.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 07/Sep/23 07:18;yao;Issue resolved by pull request 42826
[https://github.com/apache/spark/pull/42826];;;

Summary: spark job copies jars repeatedly if fs.defaultFS and application jar are same url
Issue key: SPARK-44845
Issue id: 13547678
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: zheju_he
Reporter: zheju_he
Creator: zheju_he
Created: 8/17/23 7:22
Updated: 9/7/23 4:16
Last Viewed: 7/17/24 20:45
Resolved: 9/7/23 4:16
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: YARN
Due Date: 
Votes: 0
Labels: 
Description: In the org.apache.spark.deploy.yarn.Client#compareUri method, hdfs://hadoop81:8020 and hdfs://192.168.0.81:8020 are regarded as different file systems (hadoop81 corresponds to 192.168.0.81). The specific reason is that in the last pr, different URIs of user information are also regarded as different file systems. Uri.getauthority is used to determine the user information, but authority contains the host so the URI above must be different from authority. To determine whether the user authentication information is different, you only need to determine URI.getUserInfo.

 

the last pr and issue link:
https://issues.apache.org/jira/browse/SPARK-22587

https://github.com/apache/spark/pull/19885
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Sep 07 04:16:30 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jufk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 17/Aug/23 07:34;zheju_he;my pr https://github.com/apache/spark/pull/42529;;;, 21/Aug/23 03:56;snoot;User 'zekai-li' has created a pull request for this issue:
https://github.com/apache/spark/pull/42529;;;, 21/Aug/23 03:57;snoot;User 'zekai-li' has created a pull request for this issue:
https://github.com/apache/spark/pull/42529;;;, 07/Sep/23 04:16;mridulm80;Issue resolved by pull request 42529
[https://github.com/apache/spark/pull/42529];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 21/Aug/23 03:56;snoot;User 'zekai-li' has created a pull request for this issue:
https://github.com/apache/spark/pull/42529;;;

Summary: SQL Page does not capture failed queries in analyzer 
Issue key: SPARK-44801
Issue id: 13547185
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: yao
Reporter: yao
Creator: yao
Created: 8/14/23 6:16
Updated: 9/6/23 4:15
Last Viewed: 7/17/24 20:45
Resolved: 8/24/23 15:32
Affects Version/s: 3.2.4, 3.3.2, 3.4.1, 3.5.0
Fix Version/s: 4.0.0
Component/s: SQL, Web UI
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Sep 06 04:15:51 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jre0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 15/Aug/23 03:13;snoot;User 'yaooqinn' has created a pull request for this issue:
https://github.com/apache/spark/pull/42481;;;, 24/Aug/23 15:32;Qin Yao;Issue resolved by pull request 42481
[https://github.com/apache/spark/pull/42481];;;, 06/Sep/23 04:15;snoot;User 'yaooqinn' has created a pull request for this issue:
https://github.com/apache/spark/pull/42825;;;
Affects Version/s.1: 3.3.2
Affects Version/s.2: 3.4.1
Affects Version/s.3: 3.5.0
Affects Version/s.4: 
Comment.1: 24/Aug/23 15:32;Qin Yao;Issue resolved by pull request 42481
[https://github.com/apache/spark/pull/42481];;;

Summary: Introduce simpe conf system for sql/api
Issue key: SPARK-44284
Issue id: 13542350
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/3/23 22:41
Updated: 9/5/23 14:42
Last Viewed: 7/17/24 20:45
Resolved: 7/6/23 12:23
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: Create a simple conf system for classes in sql/api. This is needed for a number of classes that are moved from sql/catalyst to sql/api that require configuration access (e.g. timeZone, parsing behavior, ...).

The change will add a small common interface that allows you to read the needed configurations, this interface is implemented by SQLConf and SQLConf will be used when we are executing on the driver, and there will be an implementation using the default values for when we are in Connect mode.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Sep 05 14:42:48 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ixzk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 04/Jul/23 03:52;snoot;User 'hvanhovell' has created a pull request for this issue:
https://github.com/apache/spark/pull/41838;;;, 04/Jul/23 03:53;snoot;User 'hvanhovell' has created a pull request for this issue:
https://github.com/apache/spark/pull/41838;;;, 05/Sep/23 14:09;tgraves;Can we get a description on this? This seems like a fairly significant change for a one line without description here or in the pr.;;;, 05/Sep/23 14:42;hvanhovell;I added a description. IMO the change itself not too spectacular.;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 04/Jul/23 03:53;snoot;User 'hvanhovell' has created a pull request for this issue:
https://github.com/apache/spark/pull/41838;;;

Summary: PushFoldableIntoBranches in complex grouping expressions may cause bindReference error
Issue key: SPARK-44846
Issue id: 13547697
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: zhuml
Reporter: zhuml
Creator: zhuml
Created: 8/17/23 9:05
Updated: 9/4/23 12:48
Last Viewed: 7/17/24 20:45
Resolved: 9/4/23 12:48
Affects Version/s: 3.4.1
Fix Version/s: 3.4.2, 3.5.0, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: SQL:
{code:java}
select c*2 as d from
(select if(b > 1, 1, b) as c from
(select if(a < 0, 0 ,a) as b from t group by b) t1
group by c) t2 {code}
ERROR:
{code:java}
Couldn't find _groupingexpression#15 in [if ((_groupingexpression#15 > 1)) 1 else _groupingexpression#15#16]
java.lang.IllegalStateException: Couldn't find _groupingexpression#15 in [if ((_groupingexpression#15 > 1)) 1 else _groupingexpression#15#16]
    at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:80)
    at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:73)
    at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
    at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
    at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
    at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$3(TreeNode.scala:466)
    at org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)
    at org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)
    at org.apache.spark.sql.catalyst.expressions.BinaryExpression.mapChildren(Expression.scala:653)
    at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:466)
    at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$3(TreeNode.scala:466)
    at org.apache.spark.sql.catalyst.trees.TernaryLike.mapChildren(TreeNode.scala:1272)
    at org.apache.spark.sql.catalyst.trees.TernaryLike.mapChildren$(TreeNode.scala:1271)
    at org.apache.spark.sql.catalyst.expressions.If.mapChildren(conditionalExpressions.scala:41)
    at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:466)
    at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$3(TreeNode.scala:466)
    at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)
    at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)
    at org.apache.spark.sql.catalyst.expressions.UnaryExpression.mapChildren(Expression.scala:533)
    at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:466)
    at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
    at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:405)
    at org.apache.spark.sql.catalyst.expressions.BindReferences$.bindReference(BoundAttribute.scala:73)
    at org.apache.spark.sql.catalyst.expressions.BindReferences$.$anonfun$bindReferences$1(BoundAttribute.scala:94)
    at scala.collection.immutable.List.map(List.scala:293)
    at org.apache.spark.sql.catalyst.expressions.BindReferences$.bindReferences(BoundAttribute.scala:94)
    at org.apache.spark.sql.execution.aggregate.HashAggregateExec.generateResultFunction(HashAggregateExec.scala:360)
    at org.apache.spark.sql.execution.aggregate.HashAggregateExec.doProduceWithKeys(HashAggregateExec.scala:538)
    at org.apache.spark.sql.execution.aggregate.AggregateCodegenSupport.doProduce(AggregateCodegenSupport.scala:69)
    at org.apache.spark.sql.execution.aggregate.AggregateCodegenSupport.doProduce$(AggregateCodegenSupport.scala:65)
    at org.apache.spark.sql.execution.aggregate.HashAggregateExec.doProduce(HashAggregateExec.scala:49)
    at org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:97)
    at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)
    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
    at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)
    at org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:92)
    at org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:92)
    at org.apache.spark.sql.execution.aggregate.HashAggregateExec.produce(HashAggregateExec.scala:49)
    at org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:660)
    at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:723)
    at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:195)
    at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)
    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
    at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)
    at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:191)
    at org.apache.spark.sql.execution.DeserializeToObjectExec.doExecute(objects.scala:93)
    at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:195)
    at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)
    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
    at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)
    at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:191)
    at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$doExecute$1(AdaptiveSparkPlanExec.scala:386)
    at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:402)
    at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.doExecute(AdaptiveSparkPlanExec.scala:386)
    at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:195)
    at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)
    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
    at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)
    at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:191)
    at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:207)
    at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:206)
    at org.apache.spark.sql.Dataset.rdd$lzycompute(Dataset.scala:3857)
    at org.apache.spark.sql.Dataset.rdd(Dataset.scala:3855)
    at org.apache.spark.sql.QueryTest$.$anonfun$getErrorMessageInCheckAnswer$1(QueryTest.scala:266)
    at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
    at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:209)
    at org.apache.spark.sql.QueryTest$.getErrorMessageInCheckAnswer(QueryTest.scala:266)
    at org.apache.spark.sql.QueryTest$.checkAnswer(QueryTest.scala:243)
    at org.apache.spark.sql.QueryTest.checkAnswer(QueryTest.scala:151)
    at org.apache.spark.sql.DataFrameSuite.$anonfun$new$737(DataFrameSuite.scala:3676)
    at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
    at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
    at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
    at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:95)
    at org.apache.spark.sql.test.SQLTestUtilsBase.withTempView(SQLTestUtils.scala:276)
    at org.apache.spark.sql.test.SQLTestUtilsBase.withTempView$(SQLTestUtils.scala:274)
    at org.apache.spark.sql.DataFrameSuite.withTempView(DataFrameSuite.scala:60)
    at org.apache.spark.sql.DataFrameSuite.$anonfun$new$736(DataFrameSuite.scala:3667)
    at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
    at org.scalatest.enablers.Timed$$anon$1.timeoutAfter(Timed.scala:127)
    at org.scalatest.concurrent.TimeLimits$.failAfterImpl(TimeLimits.scala:282)
    at org.scalatest.concurrent.TimeLimits.failAfter(TimeLimits.scala:231)
    at org.scalatest.concurrent.TimeLimits.failAfter$(TimeLimits.scala:230)
    at org.apache.spark.SparkFunSuite.failAfter(SparkFunSuite.scala:69)
    at org.apache.spark.SparkFunSuite.$anonfun$test$2(SparkFunSuite.scala:155)
    at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)
    at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)
    at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
    at org.scalatest.Transformer.apply(Transformer.scala:22)
    at org.scalatest.Transformer.apply(Transformer.scala:20)
    at org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)
    at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:227)
    at org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)
    at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)
    at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
    at org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)
    at org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)
    at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterEach$$super$runTest(SparkFunSuite.scala:69)
    at org.scalatest.BeforeAndAfterEach.runTest(BeforeAndAfterEach.scala:234)
    at org.scalatest.BeforeAndAfterEach.runTest$(BeforeAndAfterEach.scala:227)
    at org.apache.spark.SparkFunSuite.runTest(SparkFunSuite.scala:69)
    at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)
    at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)
    at scala.collection.immutable.List.foreach(List.scala:431)
    at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
    at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)
    at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)
    at org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)
    at org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)
    at org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)
    at org.scalatest.Suite.run(Suite.scala:1114)
    at org.scalatest.Suite.run$(Suite.scala:1096)
    at org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1564)
    at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)
    at org.scalatest.SuperEngine.runImpl(Engine.scala:535)
    at org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)
    at org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)
    at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$super$run(SparkFunSuite.scala:69)
    at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)
    at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)
    at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)
    at org.apache.spark.SparkFunSuite.run(SparkFunSuite.scala:69)
    at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:47)
    at org.scalatest.tools.Runner$.$anonfun$doRunRunRunDaDoRunRun$13(Runner.scala:1321)
    at org.scalatest.tools.Runner$.$anonfun$doRunRunRunDaDoRunRun$13$adapted(Runner.scala:1315)
    at scala.collection.immutable.List.foreach(List.scala:431)
    at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:1315)
    at org.scalatest.tools.Runner$.$anonfun$runOptionallyWithPassFailReporter$24(Runner.scala:992)
    at org.scalatest.tools.Runner$.$anonfun$runOptionallyWithPassFailReporter$24$adapted(Runner.scala:970)
    at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:1481)
    at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:970)
    at org.scalatest.tools.Runner$.run(Runner.scala:798)
    at org.scalatest.tools.Runner.run(Runner.scala)
    at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2or3(ScalaTestRunner.java:38)
    at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:25)
 {code}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Sep 04 12:48:17 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jujs:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 23/Aug/23 09:17;githubbot;User 'zml1206' has created a pull request for this issue:
https://github.com/apache/spark/pull/42531;;;, 31/Aug/23 16:52;ignitetcbot;User 'zml1206' has created a pull request for this issue:
https://github.com/apache/spark/pull/42633;;;, 04/Sep/23 12:48;yumwang;Issue resolved by pull request 42633
[https://github.com/apache/spark/pull/42633];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 31/Aug/23 16:52;ignitetcbot;User 'zml1206' has created a pull request for this issue:
https://github.com/apache/spark/pull/42633;;;

Summary: HiveExternalCatalog.listPartitions should restore Spark SQL stats
Issue key: SPARK-45054
Issue id: 13549437
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: csun
Reporter: csun
Creator: csun
Created: 9/1/23 18:14
Updated: 9/2/23 3:25
Last Viewed: 7/17/24 20:45
Resolved: 9/2/23 3:22
Affects Version/s: 3.2.4, 3.3.2, 3.4.1
Fix Version/s: 3.4.2, 3.5.0, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: If partitions are stored in HMS with Spark populated stats such as {{spark.sql.statistics.totalSize}}, currently {{HiveExternalCatalog.listPartitions}} doesn't call {{restorePartitionMetadata}} to restore those stats.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sat Sep 02 03:22:50 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k5a8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 02/Sep/23 03:22;csun;Issue resolved by pull request 42777
[https://github.com/apache/spark/pull/42777];;;
Affects Version/s.1: 3.3.2
Affects Version/s.2: 3.4.1
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: CSV conversion performance severely degraded for null fields
Issue key: SPARK-44990
Issue id: 13548875
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: 
Reporter: atulpayapilly_amazon
Creator: atulpayapilly_amazon
Created: 8/28/23 18:40
Updated: 9/1/23 16:39
Last Viewed: 7/17/24 20:45
Resolved: 8/30/23 17:55
Affects Version/s: 3.3.0, 3.3.1, 3.3.2, 3.3.3, 3.3.4, 3.4.0, 3.4.1, 3.5.0, 3.5.1, 4.0.0
Fix Version/s: 3.3.4, 3.4.2, 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description:  
[https://github.com/apache/spark/pull/36110/files]
 introduced a SQLConf access in a critical section for every field processed in a record that is null.

This causes severe degradation of performance causing one workload that was completing in a couple of seconds to now take around 8 minutes.

This conf needs to be moved out of the critical path, there's no need for it to be in this location.

The version of Spark prior to this commit didn't exhibit the slowdown. I also generated a patch on an affected version with the suspected line removed and the problem went away.
Environment: Ran on Spark 3.3.1/EMR 6.10.0 with driver r5.xlarge and 4 x r5.16xlarge core nodes. The workload was:

spark.read.parquet("<redacted HDFS location>").repartition(100).write.format("com.databricks.spark.csv").option("compression","gzip").option("header", "true").option("encoding","utf-8").option("charset","utf-8").option("escape", "").option("quote", "").option("quote", "\u0000").option("emptyValue", "").option("delimiter", "\t").mode("overwrite").save("<redacted HDFS location>")

Input data contained 5 parquet data files 41MB each.

Most of the fields were null values.

Schema was very wide (1099 columns).
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Sep 01 16:39:22 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k1tc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 30/Aug/23 17:55;dongjoon;Issue resolved by pull request 42738
[https://github.com/apache/spark/pull/42738];;;, 31/Aug/23 04:28;snoot;User 'Hisoka-X' has created a pull request for this issue:
https://github.com/apache/spark/pull/42744;;;, 31/Aug/23 04:28;snoot;User 'Hisoka-X' has created a pull request for this issue:
https://github.com/apache/spark/pull/42744;;;, 01/Sep/23 16:39;atulpayapilly_amazon;Thanks for fixing this. I see that a null test was added and removed. While I agree that an all null test is not very meaningful a mostly null test is still valid and would be good to avoid this regression again.;;;
Affects Version/s.1: 3.3.1
Affects Version/s.2: 3.3.2
Affects Version/s.3: 3.3.3
Affects Version/s.4: 3.3.4
Comment.1: 31/Aug/23 04:28;snoot;User 'Hisoka-X' has created a pull request for this issue:
https://github.com/apache/spark/pull/42744;;;

Summary: Reflect function behavior different from Hive
Issue key: SPARK-44743
Issue id: 13546705
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: fanjia
Reporter: nownikhil
Creator: nownikhil
Created: 8/9/23 17:54
Updated: 9/1/23 12:25
Last Viewed: 7/17/24 20:45
Resolved: 9/1/23 12:24
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: PySpark, SQL
Due Date: 
Votes: 0
Labels: 
Description: Spark reflect function will fail if underlying method call throws exception. This causes the whole job to fail.

In Hive however the exception is caught and null is returned. Simple test to reproduce the behavior
{code:java}
select reflect('java.net.URLDecoder', 'decode', '%') {code}
The workaround would be to wrap this call in a try
[https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/CallMethodViaReflection.scala#L136]


We can support this by adding a new UDF `try_reflect` which mimics the Hive's behavior. Please share your thoughts on this.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Sep 01 12:24:22 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1josg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 25/Aug/23 03:35;snoot;User 'Hisoka-X' has created a pull request for this issue:
https://github.com/apache/spark/pull/42661;;;, 01/Sep/23 12:24;cloud_fan;Issue resolved by pull request 42661
[https://github.com/apache/spark/pull/42661];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 01/Sep/23 12:24;cloud_fan;Issue resolved by pull request 42661
[https://github.com/apache/spark/pull/42661];;;

Summary: Make direct Arrow encoding work with SQL/API
Issue key: SPARK-44450
Issue id: 13543703
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/16/23 23:21
Updated: 8/30/23 1:30
Last Viewed: 7/17/24 20:45
Resolved: 8/29/23 17:39
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Aug 30 01:30:15 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j6a0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 29/Aug/23 21:37;h-vetinari;[~hvanhovell], what was the outcome here? I cannot find a reference for SPARK-44450 on github, so I'm wondering if this feature has been abandoned, and if so, why?;;;, 29/Aug/23 22:22;hvanhovell;[~h-vetinari] this was mostly about making sure we moved all needed classes to sql/api module, and that was done about a month ago in SPARK-44532 (https://github.com/apache/spark/pull/42156).

I assume you are mostly interested in the actual encoders. Those can be found here: https://github.com/apache/spark/tree/master/connector/connect/common/src/main/scala/org/apache/spark/sql/connect/client/arrow;;;, 29/Aug/23 22:38;h-vetinari;Thanks for the quick response! Are there any docs for using this? I've checked the [rc3 docs|https://dist.apache.org/repos/dist/dev/spark/v3.5.0-rc3-docs/_site/api/scala/org/apache/spark/sql/] (not easily searchable, so only in API for now), and there's no section/page for {{apache.spark.sql.connect.client}}.;;;, 30/Aug/23 01:30;hvanhovell;It is not really part of the public API, and we don't write user facing documentation for that. The use case is main that we can encode  directly between user objects and arrow batches. We needed this to get rid of the Catalyst dependency. You can check how it is integrated with the Spark Connect Scala Client, look at SparkResult for deserialization, and look at SparkSession.createDataset for serialization. Alternatively you can look at the ArrowEncoder suite.;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 29/Aug/23 22:22;hvanhovell;[~h-vetinari] this was mostly about making sure we moved all needed classes to sql/api module, and that was done about a month ago in SPARK-44532 (https://github.com/apache/spark/pull/42156).

I assume you are mostly interested in the actual encoders. Those can be found here: https://github.com/apache/spark/tree/master/connector/connect/common/src/main/scala/org/apache/spark/sql/connect/client/arrow;;;

Summary: Prepare RowEncoder for the move to sql/api
Issue key: SPARK-44344
Issue id: 13542880
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/8/23 12:55
Updated: 8/29/23 17:39
Last Viewed: 7/17/24 20:45
Resolved: 8/29/23 17:39
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect, SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 55:28.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j17s:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Unescape and consist error summary across UI pages
Issue key: SPARK-44960
Issue id: 13548608
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: yao
Reporter: yao
Creator: yao
Created: 8/25/23 6:37
Updated: 8/28/23 5:52
Last Viewed: 7/17/24 20:45
Resolved: 8/28/23 5:52
Affects Version/s: 3.3.2, 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 4.0.0
Component/s: Web UI
Due Date: 
Votes: 0
Labels: 
Description: We escape html4 for error summary for some pages., it's not necessary
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Aug 28 05:52:21 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k060:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 28/Aug/23 05:52;yao;Issue resolved by pull request 42674
[https://github.com/apache/spark/pull/42674];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 4.0.0
Affects Version/s.4: 
Comment.1:

Summary: Deterministic ApplyFunctionExpression should be foldable
Issue key: SPARK-44930
Issue id: 13548349
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: coneyliu
Reporter: coneyliu
Creator: coneyliu
Created: 8/23/23 8:58
Updated: 8/25/23 7:02
Last Viewed: 7/17/24 20:45
Resolved: 8/25/23 7:02
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: Currently, ApplyFunctionExpression is unfoldable because inherits the default value from Expression.  However, it should be foldable for a deterministic ApplyFunctionExpression. This could help optimize the usage for V2 UDF applying to constant expressions.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Aug 25 07:02:10 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jykg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 23/Aug/23 09:04;githubbot;User 'ConeyLiu' has created a pull request for this issue:
https://github.com/apache/spark/pull/42629;;;, 25/Aug/23 07:02;cloud_fan;Issue resolved by pull request 42629
[https://github.com/apache/spark/pull/42629];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 25/Aug/23 07:02;cloud_fan;Issue resolved by pull request 42629
[https://github.com/apache/spark/pull/42629];;;

Summary: BlockManagerDecommissioner throws exceptions when migrating RDD cached blocks to fallback storage
Issue key: SPARK-44547
Issue id: 13544848
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: ukby1234
Reporter: ukby1234
Creator: ukby1234
Created: 7/25/23 18:53
Updated: 8/25/23 5:20
Last Viewed: 7/17/24 20:45
Resolved: 8/25/23 5:20
Affects Version/s: 3.4.1
Fix Version/s: 3.3.4, 3.4.2, 3.5.0, 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: Looks like the RDD cache doesn't support fallback storage and we should stop the migration if the only viable peer is the fallback storage. 

  [^spark-error.log] 23/07/25 05:12:58 WARN BlockManager: Failed to replicate rdd_18_25 to BlockManagerId(fallback, remote, 7337, None), failure #0
java.io.IOException: Failed to connect to remote:7337
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:288)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230)
	at org.apache.spark.network.netty.NettyBlockTransferService.uploadBlock(NettyBlockTransferService.scala:168)
	at org.apache.spark.network.BlockTransferService.uploadBlockSync(BlockTransferService.scala:121)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$replicate(BlockManager.scala:1784)
	at org.apache.spark.storage.BlockManager.$anonfun$replicateBlock$2(BlockManager.scala:1721)
	at org.apache.spark.storage.BlockManager.$anonfun$replicateBlock$2$adapted(BlockManager.scala:1707)
	at scala.Option.forall(Option.scala:390)
	at org.apache.spark.storage.BlockManager.replicateBlock(BlockManager.scala:1707)
	at org.apache.spark.storage.BlockManagerDecommissioner.migrateBlock(BlockManagerDecommissioner.scala:356)
	at org.apache.spark.storage.BlockManagerDecommissioner.$anonfun$decommissionRddCacheBlocks$3(BlockManagerDecommissioner.scala:340)
	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.map(TraversableLike.scala:286)
	at scala.collection.TraversableLike.map$(TraversableLike.scala:279)
	at scala.collection.AbstractTraversable.map(Traversable.scala:108)
	at org.apache.spark.storage.BlockManagerDecommissioner.decommissionRddCacheBlocks(BlockManagerDecommissioner.scala:339)
	at org.apache.spark.storage.BlockManagerDecommissioner$$anon$1.run(BlockManagerDecommissioner.scala:214)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.base/java.util.concurrent.FutureTask.run(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)
Caused by: java.net.UnknownHostException: remote
	at java.base/java.net.InetAddress$CachedAddresses.get(Unknown Source)
	at java.base/java.net.InetAddress.getAllByName0(Unknown Source)
	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
	at java.base/java.net.InetAddress.getAllByName(Unknown Source)
	at java.base/java.net.InetAddress.getByName(Unknown Source)
	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:156)
	at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:153)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:153)
	at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:41)
	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:61)
	at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:53)
	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:55)
	at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:31)
	at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:106)
	at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:206)
	at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:46)
	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:180)
	at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:166)
	at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:578)
	at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:552)
	at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:491)
	at io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:616)
	at io.netty.util.concurrent.DefaultPromise.setSuccess0(DefaultPromise.java:605)
	at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)
	at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:84)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:990)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:516)
	at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:429)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:486)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:469)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 25/Jul/23 18:54;ukby1234;spark-error.log;https://issues.apache.org/jira/secure/attachment/13061620/spark-error.log
Custom field (Affects version (Component)): 
Custom field (Attachment count): 1
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Aug 25 05:20:22 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jdcg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 27/Jul/23 20:59;ignitetcbot;User 'ukby1234' has created a pull request for this issue:
https://github.com/apache/spark/pull/42155;;;, 25/Aug/23 05:20;dongjoon;Issue resolved by pull request 42155
[https://github.com/apache/spark/pull/42155];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 25/Aug/23 05:20;dongjoon;Issue resolved by pull request 42155
[https://github.com/apache/spark/pull/42155];;;

Summary: Add more tests for Python foreachBatch and StreamingQueryListener
Issue key: SPARK-44435
Issue id: 13543592
Parent id: 
Issue Type: Task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: 
Reporter: rangadi
Creator: rangadi
Created: 7/14/23 17:59
Updated: 8/24/23 17:35
Last Viewed: 7/17/24 20:45
Resolved: 8/24/23 10:19
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: Connect, Structured Streaming
Due Date: 
Votes: 0
Labels: 
Description: Currently there are few few tests included for ForeachBatch and StreamingQueryListener.

Add more tests covering more scenarios (multiple queries, different error conditions, process termination, etc).
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): SPARK-42938
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Aug 24 10:19:05 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j5lc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 24/Aug/23 10:19;gurwls223;Issue resolved by pull request 42521
[https://github.com/apache/spark/pull/42521];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Fix `RELEASE` file to have the correct information in Docker images
Issue key: SPARK-44935
Issue id: 13548438
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: dongjoon
Reporter: dongjoon
Creator: dongjoon
Created: 8/23/23 21:23
Updated: 8/23/23 23:01
Last Viewed: 7/17/24 20:45
Resolved: 8/23/23 23:01
Affects Version/s: 2.4.8, 3.0.3, 3.1.3, 3.2.4, 3.3.2, 3.4.1, 3.5.0
Fix Version/s: 3.3.4, 3.4.2, 3.5.0, 4.0.0
Component/s: Kubernetes
Due Date: 
Votes: 0
Labels: 
Description: {code}
$ docker run -it --rm apache/spark:latest ls -al /opt/spark/RELEASE
-rw-r--r-- 1 spark spark 0 Jun 25 03:13 /opt/spark/RELEASE

$ docker run -it --rm apache/spark:v3.1.3 ls -al /opt/spark/RELEASE | tail -n1
-rw-r--r-- 1 root root 0 Feb 21  2022 /opt/spark/RELEASE
{code}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Aug 23 23:01:39 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jz48:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 23/Aug/23 23:01;dongjoon;Issue resolved by pull request 42636
[https://github.com/apache/spark/pull/42636];;;
Affects Version/s.1: 3.0.3
Affects Version/s.2: 3.1.3
Affects Version/s.3: 3.2.4
Affects Version/s.4: 3.3.2
Comment.1:

Summary: Continuous Structured Streaming not reporting streaming metrics
Issue key: SPARK-44932
Issue id: 13548418
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: bryanqiang
Creator: bryanqiang
Created: 8/23/23 16:22
Updated: 8/23/23 16:25
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Structured Streaming
Due Date: 
Votes: 0
Labels: 
Description: Hello, we've been running spark continuous structured streaming on standalone cluster and happy with the performance however we noticed streaming metrics like input rate and process rate are not updated by the `ProgressReporter` in `ContinuousExecution` because the [`finishTrigger`|https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/MicroBatchExecution.scala#L293] function is never invoked in `ContinuousExecution`. I'm wondering why and how may get metrics like in micro-batch structured streaming.

 

!https://preview.redd.it/mzh4oc0cbojb1.png?width=1901&format=png&auto=webp&s=8d649ae515e6adb7d6ce853802e0a4134c9fa277!!https://preview.redd.it/8ou3uyuofojb1.png?width=1523&format=png&auto=webp&s=ac6bf7fa05cb90b09cb10b9ac815f64b5e97175e!
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 22:52.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jyzs:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Support correlated references under window functions
Issue key: SPARK-44549
Issue id: 13544879
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: gubichev
Reporter: gubichev
Creator: gubichev
Created: 7/26/23 0:27
Updated: 8/23/23 14:50
Last Viewed: 7/17/24 20:45
Resolved: 8/23/23 14:50
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: We should support subqueries with correlated references under a window function operator
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Aug 23 14:50:10 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jdjc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 23/Aug/23 14:50;cloud_fan;Issue resolved by pull request 42383
[https://github.com/apache/spark/pull/42383];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: K8s default service token file should not be materialized into token
Issue key: SPARK-44925
Issue id: 13548314
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: dongjoon
Reporter: dongjoon
Creator: dongjoon
Created: 8/23/23 3:08
Updated: 8/23/23 5:52
Last Viewed: 7/17/24 20:45
Resolved: 8/23/23 5:52
Affects Version/s: 2.4.8, 3.0.3, 3.1.3, 3.2.4, 3.3.2, 3.4.1, 3.5.0
Fix Version/s: 3.3.4, 3.4.2, 3.5.0, 4.0.0
Component/s: Kubernetes
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Aug 23 05:52:24 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jyco:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 23/Aug/23 03:20;snoot;User 'dongjoon-hyun' has created a pull request for this issue:
https://github.com/apache/spark/pull/42624;;;, 23/Aug/23 03:20;snoot;User 'dongjoon-hyun' has created a pull request for this issue:
https://github.com/apache/spark/pull/42624;;;, 23/Aug/23 05:52;dongjoon;Issue resolved by pull request 42624
[https://github.com/apache/spark/pull/42624];;;
Affects Version/s.1: 3.0.3
Affects Version/s.2: 3.1.3
Affects Version/s.3: 3.2.4
Affects Version/s.4: 3.3.2
Comment.1: 23/Aug/23 03:20;snoot;User 'dongjoon-hyun' has created a pull request for this issue:
https://github.com/apache/spark/pull/42624;;;

Summary: NullPointerException on stateful expression evaluation
Issue key: SPARK-44905
Issue id: 13548142
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: yao
Reporter: yao
Creator: yao
Created: 8/22/23 5:46
Updated: 8/23/23 5:49
Last Viewed: 7/17/24 20:45
Resolved: 8/23/23 5:49
Affects Version/s: 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Aug 23 05:49:16 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jxao:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 22/Aug/23 09:11;githubbot;User 'yaooqinn' has created a pull request for this issue:
https://github.com/apache/spark/pull/42601;;;, 23/Aug/23 05:49;yao;Issue resolved by https://github.com/apache/spark/pull/42601;;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 4.0.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 23/Aug/23 05:49;yao;Issue resolved by https://github.com/apache/spark/pull/42601;;;

Summary: Set io.connectionTimeout/connectionCreationTimeout to zero or negative will cause executor incessantes cons/destructions
Issue key: SPARK-44241
Issue id: 13541900
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: yao
Reporter: yao
Creator: yao
Created: 6/29/23 8:03
Updated: 8/23/23 0:41
Last Viewed: 7/17/24 20:45
Resolved: 6/30/23 10:34
Affects Version/s: 3.3.2, 3.4.1, 3.5.0
Fix Version/s: 3.3.3, 3.4.2, 3.5.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: {code:java}
2023-06-28 14:57:23 CST Bootstrap WARN - Failed to set channel option 'CONNECT_TIMEOUT_MILLIS' with value '-1000' for channel '[id: 0xf4b54a73]'
java.lang.IllegalArgumentException: connectTimeoutMillis : -1000 (expected: >= 0)
	at io.netty.util.internal.ObjectUtil.checkPositiveOrZero(ObjectUtil.java:144) ~[netty-common-4.1.74.Final.jar:4.1.74.Final] {code}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): SPARK-44920
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Jun 30 10:34:59 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1iv80:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 29/Jun/23 09:23;githubbot;User 'yaooqinn' has created a pull request for this issue:
https://github.com/apache/spark/pull/41785;;;, 30/Jun/23 10:34;Qin Yao;Issue resolved by pull request 41785
[https://github.com/apache/spark/pull/41785];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 30/Jun/23 10:34;Qin Yao;Issue resolved by pull request 41785
[https://github.com/apache/spark/pull/41785];;;

Summary: NullPointerException is thrown when column with ROWID type contains NULL values
Issue key: SPARK-44885
Issue id: 13547998
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: tnieradzik
Reporter: tnieradzik
Creator: tnieradzik
Created: 8/20/23 19:47
Updated: 8/22/23 10:49
Last Viewed: 7/17/24 20:45
Resolved: 8/22/23 10:48
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0, 4.0.0
Component/s: Spark Core, SQL
Due Date: 
Votes: 0
Labels: 
Description: A row ID may be NULL in an Oracle table. When this is the case, the following exception is thrown:

{{[info] Cause: java.lang.NullPointerException:}}
{{{}[info] at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$12(JdbcUtils.scala:452){}}}{{{}[info] at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$makeGetter$12$adapted(JdbcUtils.scala:451){}}}
{{{}[info] at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:361){}}}{{{}[info] at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:343){}}}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): Scala
Custom field (Last public comment date): Tue Aug 22 10:48:30 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jweo:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 20/Aug/23 19:54;tnieradzik;PR submitted: https://github.com/apache/spark/pull/42576;;;, 22/Aug/23 10:48;gurwls223;Issue resolved by pull request 42576
[https://github.com/apache/spark/pull/42576];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 22/Aug/23 10:48;gurwls223;Issue resolved by pull request 42576
[https://github.com/apache/spark/pull/42576];;;

Summary: Remove unnecessary curly braces at the end of the thread locks info
Issue key: SPARK-44880
Issue id: 13547952
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: yao
Reporter: yao
Creator: yao
Created: 8/19/23 16:52
Updated: 8/20/23 1:41
Last Viewed: 7/17/24 20:45
Resolved: 8/20/23 1:41
Affects Version/s: 3.3.2, 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.5.1, 4.0.0
Component/s: Web UI
Due Date: 
Votes: 0
Labels: 
Description: Remove unnecessary curly braces at the end of the thread locks info
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sun Aug 20 01:41:08 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jw4g:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 20/Aug/23 01:41;yumwang;Issue resolved by pull request 42571
[https://github.com/apache/spark/pull/42571];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 4.0.0
Affects Version/s.4: 
Comment.1:

Summary: Alter nested view fails because of HMS client
Issue key: SPARK-44873
Issue id: 13547889
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: kyle.rong
Reporter: kyle.rong
Creator: kyle.rong
Created: 8/18/23 16:30
Updated: 8/19/23 1:34
Last Viewed: 7/17/24 20:45
Resolved: 8/18/23 18:07
Affects Version/s: 3.1.0, 3.1.1, 3.1.2, 3.1.3, 3.2.0, 3.2.1, 3.2.2, 3.2.3, 3.2.4, 3.3.0, 3.3.1, 3.3.2, 3.3.3, 3.3.4, 3.4.0, 3.4.1, 3.4.2, 3.5.0, 3.5.1
Fix Version/s: 3.5.0, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: Currently, 
{code:java}
CREATE OR REPLACE VIEW t AS SELECT " +
        "struct(id AS `$col2`, struct(id AS `$col`) AS s1) AS s2 FROM RANGE(5)
ALTER VIEW t SET TBLPROPERTIES ('x' = 'y'){code}
would fail when calling HMS's updateTable, because HMS does not support nested struct in view. We can fix this by passing HMS an empty schema, since we store the actual view schema in the table's properties already. This fix is similar to https://github.com/apache/spark/pull/37364
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sat Aug 19 01:34:09 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jvqg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): Gengliang.Wang
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 18/Aug/23 18:07;Gengliang.Wang;Issue resolved by pull request 42532
[https://github.com/apache/spark/pull/42532];;;, 19/Aug/23 01:34;paulk;User 'kylerong-db' has created a pull request for this issue:
https://github.com/apache/spark/pull/42566;;;
Affects Version/s.1: 3.1.1, 3.3.1, 3.3.2, 3.3.3, 3.3.4, 3.4.0, 3.4.1, 3.4.2, 3.5.0, 3.5.1
Affects Version/s.2: 3.1.2
Affects Version/s.3: 3.1.3
Affects Version/s.4: 3.2.0
Comment.1: 19/Aug/23 01:34;paulk;User 'kylerong-db' has created a pull request for this issue:
https://github.com/apache/spark/pull/42566;;;

Summary: Implement termination of Python process for foreachBatch & streaming listener
Issue key: SPARK-44433
Issue id: 13543588
Parent id: 
Issue Type: Task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: WweiL
Reporter: rangadi
Creator: rangadi
Created: 7/14/23 17:55
Updated: 8/18/23 17:41
Last Viewed: 7/17/24 20:45
Resolved: 8/5/23 2:43
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect, Structured Streaming
Due Date: 
Votes: 0
Labels: 
Description: In the first implementation of Python support for foreachBatch, the python process termination is not handled correctly. 

 

See the long TODO in [https://github.com/apache/spark/blob/master/connector/connect/server/src/main/scala/org/apache/spark/sql/connect/planner/StreamingForeachBatchHelper.scala] 

about an outline of the feature to terminate the runners by registering StreamingQueryListners. 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): SPARK-42938
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Aug 18 17:41:29 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j5kg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 05/Aug/23 02:43;ueshin;Issue resolved by pull request 42283
https://github.com/apache/spark/pull/42283;;;, 16/Aug/23 18:19;awsthni;User 'rangadi' has created a pull request for this issue:
https://github.com/apache/spark/pull/42460;;;, 16/Aug/23 18:34;awsthni;User 'WweiL' has created a pull request for this issue:
https://github.com/apache/spark/pull/42283;;;, 18/Aug/23 17:41;ignitetcbot;User 'rangadi' has created a pull request for this issue:
https://github.com/apache/spark/pull/42555;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 16/Aug/23 18:19;awsthni;User 'rangadi' has created a pull request for this issue:
https://github.com/apache/spark/pull/42460;;;

Summary: Do not combine multiple Generate operators in the same WholeStageCodeGen node because it can  easily cause OOM failures if arrays are relatively large
Issue key: SPARK-44759
Issue id: 13546803
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: tafranky@gmail.com
Creator: tafranky@gmail.com
Created: 8/10/23 9:23
Updated: 8/13/23 6:03
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.0.0, 3.0.1, 3.0.2, 3.0.3, 3.1.0, 3.1.1, 3.1.2, 3.1.3, 3.2.0, 3.2.1, 3.2.2, 3.2.3, 3.2.4, 3.3.0, 3.3.1, 3.3.2, 3.4.0, 3.4.1
Fix Version/s: 
Component/s: Deploy, Optimizer, Spark Core
Due Date: 
Votes: 0
Labels: 
Description: This is an issue since the WSCG  implementation of the generate node. 

Because WSCG compute rows in batches , the combination of WSCG and the explode operation consume a lot of the dedicated executor memory. This is even more true when the WSCG node contains multiple explode nodes. This is the case when flattening a nested array.

The generate node used to flatten array generally  produces an amount of output rows that is significantly higher than the input rows.

the number of output rows generated is even drastically higher when flattening a nested array .

When we combine more that 1 generate node in the same WholeStageCodeGen  node, we run  a high risk of running out of memory for multiple reasons. 

1- As you can see from snapshots added in the comments ,  the rows created in the nested loop are saved in a writer buffer.  In this case because the rows were big , the job failed with an Out Of Memory Exception error .

2_ The generated WholeStageCodeGen result in a nested loop that for each row  , will explode the parent array and then explode the inner array.  The rows are accumulated in the writer buffer without accounting for the row size.

Please view the attached Spark Gui and Spark Dag 

In my case the wholestagecodegen includes 2 explode nodes. 

Because the array elements are large , we end up with an Out Of Memory error. 

 

I recommend that we do not merge  multiple explode nodes in the same whole stage code gen node . Doing so leads to potential memory issues.

In our case , the job execution failed with an  OOM error because the the WSCG executed  into a nested for loop . 

 

 

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 10/Aug/23 16:27;tafranky@gmail.com;image-2023-08-10-09-27-24-124.png;https://issues.apache.org/jira/secure/attachment/13062036/image-2023-08-10-09-27-24-124.png, 10/Aug/23 16:29;tafranky@gmail.com;image-2023-08-10-09-29-24-804.png;https://issues.apache.org/jira/secure/attachment/13062037/image-2023-08-10-09-29-24-804.png, 10/Aug/23 16:32;tafranky@gmail.com;image-2023-08-10-09-32-46-163.png;https://issues.apache.org/jira/secure/attachment/13062038/image-2023-08-10-09-32-46-163.png, 10/Aug/23 16:33;tafranky@gmail.com;image-2023-08-10-09-33-47-788.png;https://issues.apache.org/jira/secure/attachment/13062039/image-2023-08-10-09-33-47-788.png, 10/Aug/23 09:25;tafranky@gmail.com;wholestagecodegen_wc1_debug_wholecodegen_passed;https://issues.apache.org/jira/secure/attachment/13062030/wholestagecodegen_wc1_debug_wholecodegen_passed
Custom field (Affects version (Component)): 
Custom field (Attachment count): 5
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): Important
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Aug 10 16:34:45 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jpe8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 10/Aug/23 16:27;tafranky@gmail.com;WSCG  generated code that calls  generate_doConsume_0

!image-2023-08-10-09-27-24-124.png!;;;, 10/Aug/23 16:29;tafranky@gmail.com;WSCG  generated code for first Generate node 

!image-2023-08-10-09-29-24-804.png!;;;, 10/Aug/23 16:33;tafranky@gmail.com;WSCG  generated code for second Generate node 

!image-2023-08-10-09-32-46-163.png!;;;, 10/Aug/23 16:34;tafranky@gmail.com;Spark Dag for the use case . The failure is from the execution of WholeStageCodeGen(2)

!image-2023-08-10-09-33-47-788.png!;;;
Affects Version/s.1: 3.0.1, 3.2.2, 3.2.3, 3.2.4, 3.3.0, 3.3.1, 3.3.2, 3.4.0, 3.4.1
Affects Version/s.2: 3.0.2
Affects Version/s.3: 3.0.3
Affects Version/s.4: 3.1.0
Comment.1: 10/Aug/23 16:29;tafranky@gmail.com;WSCG  generated code for first Generate node 

!image-2023-08-10-09-29-24-804.png!;;;

Summary: Spark job submission failed because Xmx string is available on one parameter provided into spark.driver.extraJavaOptions
Issue key: SPARK-44242
Issue id: 13541901
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: nfraison.datadog
Reporter: nfraison.datadog
Creator: nfraison.datadog
Created: 6/29/23 8:16
Updated: 8/12/23 0:09
Last Viewed: 7/17/24 20:45
Resolved: 8/12/23 0:09
Affects Version/s: 3.3.2, 3.4.1
Fix Version/s: 4.0.0
Component/s: Spark Submit
Due Date: 
Votes: 0
Labels: 
Description: The spark-submit command failed if Xmx string is found on any parameters provided to spark.driver.extraJavaOptions.

For ex. running this spark-submit command line
{code:java}
./bin/spark-submit --class org.apache.spark.examples.SparkPi --conf "spark.driver.extraJavaOptions=-Dtest=Xmx"  examples/jars/spark-examples_2.12-3.4.1.jar 100{code}
failed due to
{code:java}
Error: Not allowed to specify max heap(Xmx) memory settings through java options (was -Dtest=Xmx). Use the corresponding --driver-memory or spark.driver.memory configuration instead.{code}
The check performed in [https://github.com/apache/spark/blob/master/launcher/src/main/java/org/apache/spark/launcher/SparkSubmitCommandBuilder.java#L314] seems to broad
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sat Aug 12 00:09:27 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1iv88:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 12/Aug/23 00:09;mridulm80;Issue resolved by pull request 41806
[https://github.com/apache/spark/pull/41806];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: SaveMode.ErrorIfExists does not work with kafka-sql
Issue key: SPARK-44774
Issue id: 13546956
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: dolfinus
Creator: dolfinus
Created: 8/11/23 9:46
Updated: 8/11/23 9:48
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: I' trying to write batch dataframe to Kafka topic with {{mode="error"}}, but when topic exists it does not raise exception. Instead it appends data to a topic.

Steps to reproduce:

1. Start Kafka:

docker-compose.yml
{code:yaml}
version: '3.9'

services:
  zookeeper:
    image: bitnami/zookeeper:3.8
    environment:
      ALLOW_ANONYMOUS_LOGIN: 'yes'

  kafka:
    image: bitnami/kafka:latest
    restart: unless-stopped
    ports:
    - 9093:9093
    environment:
      ALLOW_PLAINTEXT_LISTENER: 'yes'
      KAFKA_ENABLE_KRAFT: 'no'
      KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: INTERNAL_PLAINTEXT_ANONYMOUS
      KAFKA_CFG_LISTENERS: INTERNAL_PLAINTEXT_ANONYMOUS://:9092,EXTERNAL_PLAINTEXT_ANONYMOUS://:9093
      KAFKA_CFG_ADVERTISED_LISTENERS: INTERNAL_PLAINTEXT_ANONYMOUS://kafka:9092,EXTERNAL_PLAINTEXT_ANONYMOUS://localhost:9093
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL_PLAINTEXT_ANONYMOUS:PLAINTEXT,EXTERNAL_PLAINTEXT_ANONYMOUS:PLAINTEXT
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: 'true'
    depends_on:
    - zookeeper
{code}

{code:bash}
docker-compose up -d
{code}

2. Start Spark session:

{code:bash}
pip install pyspark[sql]==3.4.1
{code}


{code:python}
from pyspark.sql import SparkSession

spark = SparkSession.builder.config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1").getOrCreate()
{code}

3. Create DataFrame and write it to Kafka. First write using {{mode="append"}} to create topic, then with {{mode="error"}} to raise because topic already exist:
{code}
df = spark.createDataFrame([{"value": "string"}])
df.write.format("kafka").option("kafka.bootstrap.servers", "localhost:9093").option("topic", "new_topic").mode("append").save()

# no exception is raised
df.write.format("kafka").option("kafka.bootstrap.servers", "localhost:9093").option("topic", "new_topic").mode("error").save()
{code}

4. Check topic content - 2 rows are added to topic instead of one:
{code:python}
spark.read.format("kafka").option("kafka.bootstrap.servers", "localhost:9093").option("subscribe", "new_topic").load().show(10, False)
{code}
{code}
+----+-------------------+---------+---------+------+-----------------------+-------------+
|key |value              |topic    |partition|offset|timestamp              |timestampType|
+----+-------------------+---------+---------+------+-----------------------+-------------+
|null|[73 74 72 69 6E 67]|new_topic|0        |0     |2023-08-11 09:39:35.813|0            |
|null|[73 74 72 69 6E 67]|new_topic|0        |1     |2023-08-11 09:39:36.122|0            |
+----+-------------------+---------+---------+------+-----------------------+-------------+
{code}

It looks like mode is checked by KafkaSourceProvider, but is not used at all:
https://github.com/apache/spark/blob/v3.4.1/connector/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala#L172-L178

So data is always appended to topic.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 46:54.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jqc8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Improve WSCG handling of row buffer by accounting for executor memory  .  Exploding nested arrays can easily lead to out of memory errors. 
Issue key: SPARK-44768
Issue id: 13546887
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: tafranky@gmail.com
Creator: tafranky@gmail.com
Created: 8/10/23 22:36
Updated: 8/11/23 3:36
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.3.2, 3.4.0, 3.4.1
Fix Version/s: 
Component/s: Optimizer
Due Date: 
Votes: 0
Labels: 
Description: The code sample below is to showcase the wholestagecodegen generated when exploding nested arrays.  The data sample in the dataframe is quite small so it will not trigger the Out of Memory error . 

However if the array is larger and the row size is large , you will definitely end up with an OOM error .  

 

consider a scenario where you flatten  a nested array 

// e.g you can use the following steps to create the dataframe 

//create a partClass case class
case class partClass (PARTNAME: String , PartNumber: String , PartPrice : Double )

//create a nested array array class
case  class array_array_class (
 col_int: Int,
 arr_arr_string : Seq[Seq[String]],
 arr_arr_bigint : Seq[Seq[Long]],
 col_string     : String,
 parts_s        : Seq[Seq[partClass]]
 
)

//create a dataframe
var df_array_array = sc.parallelize(
 Seq(
 (1,Seq(Seq("a","b" ,"c" ,"d") ,Seq("aa","bb" ,"cc","dd")) , Seq(Seq(1000,20000), Seq(30000,-10000)),"ItemPart1",
  Seq(Seq(partClass("PNAME1","P1",20.75),partClass("PNAME1_1","P1_1",30.75)))
 ) ,
 
 (2,Seq(Seq("ab","bc" ,"cd" ,"de") ,Seq("aab","bbc" ,"ccd","dde"),Seq("aaaaaabbbbb")) , Seq(Seq(-1000,-20000,-1,-2), Seq(0,30000,-10000)),"ItemPart2",
  Seq(Seq(partClass("PNAME2","P2",170.75),partClass("PNAME2_1","P2_1",33.75),partClass("PNAME2_2","P2_2",73.75)))
 )
  
 )

).toDF("c1" ,"c2" ,"c3" ,"c4" ,"c5")

//explode a nested array 

var  result   =  df_array_array.select( col("c1"), explode(col("c2"))).select('c1 , explode('col))

result.explain

 

The physical for this operator is seen below.

-------------------------------------
Physical plan 

== Physical Plan ==
*(1) Generate explode(col#27), [c1#17|#17], false, [col#30|#30]
+- *(1) Filter ((size(col#27, true) > 0) AND isnotnull(col#27))
   +- *(1) Generate explode(c2#18), [c1#17|#17], false, [col#27|#27]
      +- *(1) Project [_1#6 AS c1#17, _2#7 AS c2#18|#6 AS c1#17, _2#7 AS c2#18]
         +- *(1) Filter ((size(_2#7, true) > 0) AND isnotnull(_2#7))
            +- *(1) SerializeFromObject [knownnotnull(assertnotnull(input[0, scala.Tuple5, true]))._1 AS _1#6, mapobjects(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -1), mapobjects(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -2), staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, validateexternaltype(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -2), StringType, ObjectType(class java.lang.String)), true, false, true), validateexternaltype(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -1), ArrayType(StringType,true), ObjectType(interface scala.collection.Seq)), None), knownnotnull(assertnotnull(input[0, scala.Tuple5, true]))._2, None) AS _2#7, mapobjects(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -3), mapobjects(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -4), assertnotnull(validateexternaltype(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -4), IntegerType, IntegerType)), validateexternaltype(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -3), ArrayType(IntegerType,false), ObjectType(interface scala.collection.Seq)), None), knownnotnull(assertnotnull(input[0, scala.Tuple5, true]))._3, None) AS _3#8, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, scala.Tuple5, true]))._4, true, false, true) AS _4#9, mapobjects(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -5), mapobjects(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -6), if (isnull(validateexternaltype(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -6), StructField(PARTNAME,StringType,true), StructField(PartNumber,StringType,true), StructField(PartPrice,DoubleType,false), ObjectType(class $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$partClass)))) null else named_struct(PARTNAME, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(validateexternaltype(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -6), StructField(PARTNAME,StringType,true), StructField(PartNumber,StringType,true), StructField(PartPrice,DoubleType,false), ObjectType(class $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$partClass))).PARTNAME, true, false, true), PartNumber, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(validateexternaltype(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -6), StructField(PARTNAME,StringType,true), StructField(PartNumber,StringType,true), StructField(PartPrice,DoubleType,false), ObjectType(class $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$partClass))).PartNumber, true, false, true), PartPrice, knownnotnull(validateexternaltype(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -6), StructField(PARTNAME,StringType,true), StructField(PartNumber,StringType,true), StructField(PartPrice,DoubleType,false), ObjectType(class $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$partClass))).PartPrice), validateexternaltype(lambdavariable(MapObject, ObjectType(class java.lang.Object), true, -5), ArrayType(StructType(StructField(PARTNAME,StringType,true),StructField(PartNumber,StringType,true),StructField(PartPrice,DoubleType,false)),true), ObjectType(interface scala.collection.Seq)), None), knownnotnull(assertnotnull(input[0, scala.Tuple5, true]))._5, None) AS _5#10]
               +- Scan[obj#5|#5]

 

 

Because the explode function can create multiple rows from a single row  , we should account for the memory available when adding rows to the buffer .  

 

This is even more important when we are exploding nested arrays . 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 11/Aug/23 03:32;tafranky@gmail.com;image-2023-08-10-20-32-55-684.png;https://issues.apache.org/jira/secure/attachment/13062044/image-2023-08-10-20-32-55-684.png, 11/Aug/23 00:21;tafranky@gmail.com;spark-jira_wscg_code.txt;https://issues.apache.org/jira/secure/attachment/13062043/spark-jira_wscg_code.txt
Custom field (Affects version (Component)): 
Custom field (Attachment count): 2
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Aug 11 03:33:02 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jpww:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 11/Aug/23 03:33;tafranky@gmail.com;!image-2023-08-10-20-32-55-684.png!;;;
Affects Version/s.1: 3.4.0
Affects Version/s.2: 3.4.1
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: "pyspark.pandas.resample" is incorrect when DST is overlapped and setting "spark.sql.timestampType" to TIMESTAMP_NTZ does not help
Issue key: SPARK-44717
Issue id: 13546451
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: gurwls223
Reporter: attilapiros
Creator: attilapiros
Created: 8/8/23 4:01
Updated: 8/9/23 2:04
Last Viewed: 7/17/24 20:45
Resolved: 8/9/23 2:04
Affects Version/s: 3.4.0, 3.4.1, 4.0.0
Fix Version/s: 3.5.0, 4.0.0
Component/s: Pandas API on Spark
Due Date: 
Votes: 0
Labels: 
Description: Use one of the existing test:
- "11H" case of test_dataframe_resample (pyspark.pandas.tests.test_resample.ResampleTests) 
- "1001H" case of test_series_resample (pyspark.pandas.tests.test_resample.ResampleTests) 

After setting the TZ for example to New York (like by using the following python code in a "setUpClass":  
{noformat}
os.environ["TZ"] = 'America/New_York'
{noformat})

You will get the error for the latter mentioned test:

{noformat}
======================================================================
FAIL [4.219s]: test_series_resample (pyspark.pandas.tests.test_resample.ResampleTests)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/__w/spark/spark/python/pyspark/pandas/tests/test_resample.py", line 276, in test_series_resample
    self._test_resample(self.pdf3.A, self.psdf3.A, ["1001H"], "right", "right", "sum")
  File "/__w/spark/spark/python/pyspark/pandas/tests/test_resample.py", line 259, in _test_resample
    self.assert_eq(
  File "/__w/spark/spark/python/pyspark/testing/pandasutils.py", line 457, in assert_eq
    _assert_pandas_almost_equal(lobj, robj)
  File "/__w/spark/spark/python/pyspark/testing/pandasutils.py", line 228, in _assert_pandas_almost_equal
    raise PySparkAssertionError(
pyspark.errors.exceptions.base.PySparkAssertionError: [DIFFERENT_PANDAS_SERIES] Series are not almost equal:
Left:
Freq: 1001H
float64
Right:
float64
{noformat}

The problem is the in the pyspark resample there will be more resampled rows in the result. The DST change will cause those extra lines as the computed __tmp_resample_bin_col__ be something like:

{noformat}
| __index_level_0__  | __tmp_resample_bin_col__ | A
.....
|2011-03-08 00:00:00|2011-03-26 11:00:00     |0.3980551570183919  |
|2011-03-09 00:00:00|2011-03-26 11:00:00     |0.6511376673995046  |
|2011-03-10 00:00:00|2011-03-26 11:00:00     |0.6141085426890365  |
|2011-03-11 00:00:00|2011-03-26 11:00:00     |0.11557638066163867 |
|2011-03-12 00:00:00|2011-03-26 11:00:00     |0.4517788243490799  |
|2011-03-13 00:00:00|2011-03-26 11:00:00     |0.8637060550157284  |
|2011-03-14 00:00:00|2011-03-26 10:00:00     |0.8169499149450166  |
|2011-03-15 00:00:00|2011-03-26 10:00:00     |0.4585916249356583  |
|2011-03-16 00:00:00|2011-03-26 10:00:00     |0.8362472880832088  |
|2011-03-17 00:00:00|2011-03-26 10:00:00     |0.026716901748386812|
|2011-03-18 00:00:00|2011-03-26 10:00:00     |0.9086816462089563  |
{noformat}

You can see the extra lines around when the DST kicked in on 2011-03-13 in New York.

Even setting the conf "spark.sql.timestampType" to"TIMESTAMP_NTZ" does not help.

You can see my tests here:
https://github.com/attilapiros/spark/pull/5

Pandas timestamps are TZ less:
`
{noformat}
import pandas as pd
a = pd.Timestamp(year=2011, month=3, day=13, hour=1)
b = pd.Timedelta(hours=1)

>> a 
Timestamp('2011-03-13 01:00:00')
>>> a+b
Timestamp('2011-03-13 02:00:00')
>>> a+b+b
Timestamp('2011-03-13 03:00:00')
{noformat}

But pyspark TimestampType uses TZ and DST:

{noformat}
>>> sql("select  TIMESTAMP '2011-03-13 01:00:00'").show()
+-------------------------------+
|TIMESTAMP '2011-03-13 01:00:00'|
+-------------------------------+
|            2011-03-13 01:00:00|
+-------------------------------+

>>> sql("select  TIMESTAMP '2011-03-13 01:00:00' + make_interval(0,0,0,0,1,0,0)").show()
+--------------------------------------------------------------------+
|TIMESTAMP '2011-03-13 01:00:00' + make_interval(0, 0, 0, 0, 1, 0, 0)|
+--------------------------------------------------------------------+
|                                                 2011-03-13 03:00:00|
+--------------------------------------------------------------------+
{noformat}

The current resample code uses the above interval based calculation.

Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Aug 09 02:04:12 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jn7s:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 08/Aug/23 04:05;attilapiros;cc [~itholic] [~gurwls223]
;;;, 08/Aug/23 04:14;gurwls223;cc [~podongfeng];;;, 08/Aug/23 05:26;gurwls223;I think we should at least make this respects {{spark.sql.timestampType}} when it;s set to {{TIMESTAMP_NTZ}}. Took a quick look, and I think there's some problem in calculation logic in https://github.com/apache/spark/blob/master/python/pyspark/pandas/resample.py#L277-L310 especially date_trunc returns always {{TimestampType}}. We might need a dedicated internal expression cc [~podongfeng];;;, 08/Aug/23 07:51;gurwls223;[~attilapiros] which time zone are you in? Would you mind trying this one below:

{code}
sql("select  TIMESTAMP_NTZ '2011-03-13 01:00:00' + make_interval(0,0,0,0,1,0,0)").show()
{code};;;, 08/Aug/23 08:54;attilapiros;The TIMESTAMP_NTZ would work for sure.

Here is the test:

{noformat}
$ export TZ="America/New_York"
$ ./bin/pyspark
....
>>> sql("select  TIMESTAMP_NTZ '2011-03-13 01:00:00' + make_interval(0,0,0,0,1,0,0)").show()

+------------------------------------------------------------------------+
|TIMESTAMP_NTZ '2011-03-13 01:00:00' + make_interval(0, 0, 0, 0, 1, 0, 0)|
+------------------------------------------------------------------------+
|                                                     2011-03-13 02:00:00|
+------------------------------------------------------------------------+

>>> sql("select  TIMESTAMP '2011-03-13 01:00:00' + make_interval(0,0,0,0,1,0,0)").show()
+--------------------------------------------------------------------+
|TIMESTAMP '2011-03-13 01:00:00' + make_interval(0, 0, 0, 0, 1, 0, 0)|
+--------------------------------------------------------------------+
|                                                 2011-03-13 03:00:00|
+--------------------------------------------------------------------+
{noformat}

;;;, 08/Aug/23 11:17;gurwls223;Made a quick fix: https://github.com/apache/spark/pull/42392. I believe there are other corner cases like this a lot .. but the PR fixes this one alone for now.;;;, 09/Aug/23 02:04;gurwls223;Issue resolved by pull request 42392
[https://github.com/apache/spark/pull/42392];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 4.0.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 08/Aug/23 04:14;gurwls223;cc [~podongfeng];;;

Summary: Even `spark.sql.codegen.factoryMode` is NO_CODEGEN, the WholeStageCodegen also will be generated.
Issue key: SPARK-44236
Issue id: 13541871
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: fanjia
Reporter: fanjia
Creator: fanjia
Created: 6/29/23 2:28
Updated: 8/8/23 9:46
Last Viewed: 7/17/24 20:45
Resolved: 8/8/23 9:46
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: The `spark.sql.codegen.factoryMode` is NO_CODEGEN, but Spark always generate WholeStageCodegen plan when set `spark.sql.codegen.wholeStage` to `true`.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Aug 08 09:46:39 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1iv1k:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 08/Aug/23 09:46;cloud_fan;Issue resolved by pull request 41779
[https://github.com/apache/spark/pull/41779];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Incorrect limit handling and config parsing in Arrow collect
Issue key: SPARK-44657
Issue id: 13545991
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: vicennial
Reporter: vicennial
Creator: vicennial
Created: 8/3/23 12:46
Updated: 8/8/23 8:32
Last Viewed: 7/17/24 20:45
Resolved: 8/8/23 8:32
Affects Version/s: 3.4.0, 3.4.1, 3.4.2, 3.5.0
Fix Version/s: 3.4.2, 3.5.0, 4.0.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: In the arrow writer [code|https://github.com/apache/spark/blob/6161bf44f40f8146ea4c115c788fd4eaeb128769/sql/core/src/main/scala/org/apache/spark/sql/execution/arrow/ArrowConverters.scala#L154-L163] , the conditions don’t seem to hold what the documentation says regd "{_}maxBatchSize and maxRecordsPerBatch, respect whatever smaller"{_} since it seems to actually respect the conf which is "larger" (i.e less restrictive) due to _||_ operator.

 

Further, when the `{_}CONNECT_GRPC_ARROW_MAX_BATCH_SIZE{_}` conf is read, the value is not converted to bytes from Mib ([example|https://github.com/apache/spark/blob/3e5203c64c06cc8a8560dfa0fb6f52e74589b583/connector/connect/server/src/main/scala/org/apache/spark/sql/connect/execution/SparkConnectPlanExecution.scala#L103]).
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Aug 08 08:32:04 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jkds:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 08/Aug/23 08:32;gurwls223;Issue resolved by pull request 42321
[https://github.com/apache/spark/pull/42321];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.4.2
Affects Version/s.3: 3.5.0
Affects Version/s.4: 
Comment.1:

Summary: Log eventLog rewrite duration when compact old event log files
Issue key: SPARK-44703
Issue id: 13546336
Parent id: 
Issue Type: Task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: shuyouZZ
Reporter: shuyouZZ
Creator: shuyouZZ
Created: 8/7/23 10:55
Updated: 8/8/23 3:18
Last Viewed: 7/17/24 20:45
Resolved: 8/8/23 3:18
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: When enable {{spark.eventLog.rolling.enabled}} and the number of eventLog files exceeds the value of {{{}spark.history.fs.eventLog.rolling.maxFilesToRetain{}}},
HistoryServer will compact the old event log files into one compact file.

Currently there is no log the rewrite duration in {{rewrite}} method, this metric is useful for understand the compact duration, so we need add logs in the method.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Aug 08 03:18:09 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jmig:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 08/Aug/23 03:18;kabhwan;Issue resolved by pull request 42378
[https://github.com/apache/spark/pull/42378];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Support deal with microsecond for `from_json` function
Issue key: SPARK-44696
Issue id: 13546289
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: 1365976815@qq.com
Creator: 1365976815@qq.com
Created: 8/7/23 3:47
Updated: 8/7/23 3:47
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: Currently, `from_json` function will treat all input timestamp as second precise.
However, if the input is millisecond or microsecond, this function will return wrong result and throw no exception, which will lead to misunderstanding.

Example:
{code:java}
spark-sql> SELECT from_json('{"a":1, "b":1691241070}', 'a INT, b TIMESTAMP');
{"a":1,"b":2023-08-05 21:11:10}

spark-sql> SELECT from_json('{"a":1, "b":1691241070000}', 'a INT, b TIMESTAMP');
{"a":1,"b":+55563-04-19 18:06:40}

spark-sql> SELECT from_json('{"a":1, "b":1691241070000000}', 'a INT, b TIMESTAMP');
{"a":1,"b":-183707-06-27 20:24:24.251328}{code}
 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 47:44.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jm80:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: DataSourceStrategy#selectFilters returns predicates in non-deterministic order
Issue key: SPARK-41636
Issue id: 13514992
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: fanjia
Reporter: jwserencsa
Creator: jwserencsa
Created: 12/21/22 0:04
Updated: 8/7/23 0:08
Last Viewed: 7/17/24 20:45
Resolved: 8/7/23 0:08
Affects Version/s: 3.1.0, 3.4.0, 3.4.1
Fix Version/s: 3.5.0, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: Method org.apache.spark.sql.execution.datasources.DataSourceStrategy#selectFilters, which is used to determine "pushdown-able" filters, does not preserve the order of the input {{Seq[Expression]}} nor does it return the same order across the same plans (modulo ExprId differences). This is resulting in CodeGenerator cache misses even when the exact same LogicalPlan is executed. 

The aforementioned method does not attempt to maintain the order of the input predicates, though it happens to do so when there are less than 5 pushdown-able {{Expression}} in the input (due to some "small maps" logic in {{{}scala.collection.TraversableOnce#toMap{}}}). 

Returning in the same order as the input will reduce churn on the CodeGenerator cache under prolonged workloads that execute queries that are very similar. 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Aug 07 00:08:10 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1e9zs:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 03/Aug/23 03:28;snoot;User 'Hisoka-X' has created a pull request for this issue:
https://github.com/apache/spark/pull/42265;;;, 03/Aug/23 03:29;snoot;User 'Hisoka-X' has created a pull request for this issue:
https://github.com/apache/spark/pull/42265;;;, 07/Aug/23 00:08;gurwls223;Issue resolved by pull request 42265
[https://github.com/apache/spark/pull/42265];;;
Affects Version/s.1: 3.4.0
Affects Version/s.2: 3.4.1
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 03/Aug/23 03:29;snoot;User 'Hisoka-X' has created a pull request for this issue:
https://github.com/apache/spark/pull/42265;;;

Summary: Support partition operation on dataframe in Spark Connect Go Client
Issue key: SPARK-44368
Issue id: 13543098
Parent id: 13534768
Issue Type: Sub-task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: bobyangbo
Reporter: bobyangbo
Creator: bobyangbo
Created: 7/11/23 3:32
Updated: 8/3/23 0:13
Last Viewed: 7/17/24 20:45
Resolved: 8/3/23 0:13
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: Connect Contrib
Due Date: 
Votes: 0
Labels: 
Description: Support partition operation on dataframe in Spark Connect Go Client
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Aug 03 00:13:19 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j2js:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 03/Aug/23 00:13;podongfeng;Issue resolved by pull request 13
[https://github.com/apache/spark-connect-go/pull/13];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Revert SPARK-43043 Improve the performance of MapOutputTracker.updateMapOutput
Issue key: SPARK-44630
Issue id: 13545781
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: dongjoon
Reporter: dongjoon
Creator: dongjoon
Created: 8/2/23 2:41
Updated: 8/2/23 6:16
Last Viewed: 7/17/24 20:45
Resolved: 8/2/23 6:16
Affects Version/s: 3.4.1
Fix Version/s: 3.4.2
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Aug 02 06:16:03 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jj34:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 02/Aug/23 06:16;gurwls223;Issue resolved by pull request 42285
[https://github.com/apache/spark/pull/42285];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Add Encoders.scala to Spark Connect Scala Client
Issue key: SPARK-44613
Issue id: 13545573
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/31/23 18:40
Updated: 8/1/23 18:54
Last Viewed: 7/17/24 20:45
Resolved: 8/1/23 18:54
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Aug 01 11:38:15 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jhsw:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 01/Aug/23 11:38;ignitetcbot;User 'hvanhovell' has created a pull request for this issue:
https://github.com/apache/spark/pull/42264;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: UDF should support function taking value classes
Issue key: SPARK-44311
Issue id: 13542539
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: eejbyfeldt
Reporter: eejbyfeldt
Creator: eejbyfeldt
Created: 7/5/23 12:46
Updated: 8/1/23 14:52
Last Viewed: 7/17/24 20:45
Resolved: 8/1/23 14:50
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: Running the following code in a spark 
```
final case class ValueClass(a: Int) extends AnyVal
final case class Wrapper(v: ValueClass)

val f = udf((a: ValueClass) => a.a > 0)

spark.createDataset(Seq(Wrapper(ValueClass(1)))).filter(f(col("v"))).show()
```

fails with
```
java.lang.ClassCastException: class org.apache.spark.sql.types.IntegerType$ cannot be cast to class org.apache.spark.sql.types.StructType (org.apache.spark.sql.types.IntegerType$ and org.apache.spark.sql.types.StructType are in unnamed module of loader 'app')
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveEncodersInUDF$$anonfun$apply$42$$anonfun$applyOrElse$218.$anonfun$applyOrElse$220(Analyzer.scala:3241)
  at scala.Option.map(Option.scala:242)
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveEncodersInUDF$$anonfun$apply$42$$anonfun$applyOrElse$218.$anonfun$applyOrElse$219(Analyzer.scala:3239)
  at scala.collection.immutable.List.map(List.scala:246)
  at scala.collection.immutable.List.map(List.scala:79)
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveEncodersInUDF$$anonfun$apply$42$$anonfun$applyOrElse$218.applyOrElse(Analyzer.scala:3237)
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveEncodersInUDF$$anonfun$apply$42$$anonfun$applyOrElse$218.applyOrElse(Analyzer.scala:3234)
  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUpWithPruning$2(TreeNode.scala:566)
  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)
  at org.apache.spark.sql.catalyst.trees.TreeNode.transformUpWithPruning(TreeNode.scala:566)
```
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): SPARK-44621
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 46:17.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1iz4g:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Remove exclusion for scala-xml for Spark Connect Scala Client
Issue key: SPARK-44611
Issue id: 13545561
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/31/23 15:35
Updated: 8/1/23 1:02
Last Viewed: 7/17/24 20:45
Resolved: 8/1/23 1:02
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 35:28.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jhq8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Terminate streaming queries when a session times out in Spark Connect
Issue key: SPARK-44432
Issue id: 13543587
Parent id: 
Issue Type: Task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: rangadi
Reporter: rangadi
Creator: rangadi
Created: 7/14/23 17:51
Updated: 7/30/23 1:42
Last Viewed: 7/17/24 20:45
Resolved: 7/30/23 1:42
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0, 4.0.0
Component/s: Connect, Structured Streaming
Due Date: 
Votes: 0
Labels: 
Description: Spark Connect server keeps a session id at connect server alive as long as a streaming query is alive. This may not be desirable. If the client disconnects long enough and times out in server, we should let the session mapping to be removed and terminate the streaming queries. 

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): SPARK-42938
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sun Jul 30 01:42:15 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j5k8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 30/Jul/23 01:42;gurwls223;Issue resolved by pull request 42193
[https://github.com/apache/spark/pull/42193];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Remove ToJsonUtil
Issue key: SPARK-44538
Issue id: 13544730
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/25/23 1:20
Updated: 7/29/23 1:32
Last Viewed: 7/17/24 20:45
Resolved: 7/29/23 1:32
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect, SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Jul 27 06:06:44 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jcm8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 27/Jul/23 06:06;awsthni;User 'hvanhovell' has created a pull request for this issue:
https://github.com/apache/spark/pull/42164;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Spark Connect DataFrame does not allow to add custom instance attributes and check for it
Issue key: SPARK-44528
Issue id: 13544702
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: grundprinzip-db
Reporter: grundprinzip-db
Creator: grundprinzip-db
Created: 7/24/23 20:32
Updated: 7/26/23 23:54
Last Viewed: 7/17/24 20:45
Resolved: 7/26/23 23:54
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0, 4.0.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: ```
df = spark.range(10)
df._test = 10

assert(hasattr(df, "_test"))
assert(!hasattr(df, "_test_no"))
```

Treats `df._test` like a column
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Jul 26 23:54:23 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jcg0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 26/Jul/23 23:54;gurwls223;Issue resolved by pull request 42132
[https://github.com/apache/spark/pull/42132];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Move encoder inference to sql/api
Issue key: SPARK-44531
Issue id: 13544710
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/24/23 22:01
Updated: 7/26/23 11:16
Last Viewed: 7/17/24 20:45
Resolved: 7/26/23 11:16
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect, SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 01:36.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jchs:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Move Streaming API to sql/api
Issue key: SPARK-44535
Issue id: 13544726
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/24/23 23:47
Updated: 7/26/23 3:58
Last Viewed: 7/17/24 20:45
Resolved: 7/26/23 3:58
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect, SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Jul 26 03:58:48 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jclc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 26/Jul/23 03:58;snoot;User 'hvanhovell' has created a pull request for this issue:
https://github.com/apache/spark/pull/42140;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Move ArrowUtil to sql/api
Issue key: SPARK-44532
Issue id: 13544711
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/24/23 22:14
Updated: 7/26/23 3:51
Last Viewed: 7/17/24 20:45
Resolved: 7/26/23 3:51
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect, SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 14:36.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jci0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Move SparkBuildInfo to common/util
Issue key: SPARK-44530
Issue id: 13544709
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/24/23 21:43
Updated: 7/26/23 0:52
Last Viewed: 7/17/24 20:45
Resolved: 7/26/23 0:52
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 43:06.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jchk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Cleanup .spark-staging directories when yarn application fails
Issue key: SPARK-44543
Issue id: 13544805
Parent id: 
Issue Type: New Feature
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: dipayandev
Creator: dipayandev
Created: 7/25/23 12:21
Updated: 7/25/23 12:35
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Spark Core, Spark Shell
Due Date: 
Votes: 0
Labels: 
Description: Spark creates the staging directories like .hive-staging, .spark-staging etc which get created when you run an dynamic insert overwrite to a partitioned table. Spark spends maximum time in renaming the partitioned files, and because GCS renaming are too slow, there are frequent scenarios where YARN fails due to network error etc.

Such directories will remain forever in Google Cloud Storage, in case the yarn application manager gets killed.
 
Over time this pileup and incurs a lot of cloud storage cost.
 
Can we update our File committer to clean up the temporary directories in case the job commit fails.

PS : This request is specifically for GCS.
Image for reference 
 

!image-2023-07-25-17-52-55-006.png|width=458,height=177!
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 25/Jul/23 12:22;dipayandev;image-2023-07-25-17-52-55-006.png;https://issues.apache.org/jira/secure/attachment/13061612/image-2023-07-25-17-52-55-006.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 1
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Jul 25 12:31:00 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jd2w:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 25/Jul/23 12:31;dipayandev;Happy to contribute to this development of this feature. ;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Exclude configs starting with SPARK_DRIVER_PREFIX and SPARK_EXECUTOR_PREFIX from modifiedConfigs
Issue key: SPARK-44466
Issue id: 13543869
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: yumwang
Reporter: yumwang
Creator: yumwang
Created: 7/18/23 2:38
Updated: 7/25/23 2:46
Last Viewed: 7/17/24 20:45
Resolved: 7/25/23 2:46
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: Should not include this value: 
!screenshot-1.png! 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 18/Jul/23 02:38;yumwang;screenshot-1.png;https://issues.apache.org/jira/secure/attachment/13061380/screenshot-1.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 1
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Jul 25 02:46:31 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j7aw:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 18/Jul/23 02:48;yumwang;https://github.com/apache/spark/pull/42049;;;, 25/Jul/23 02:46;yumwang;Issue resolved by pull request 42049
[https://github.com/apache/spark/pull/42049];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 25/Jul/23 02:46;yumwang;Issue resolved by pull request 42049
[https://github.com/apache/spark/pull/42049];;;

Summary: Add upcasting to Arrow deserializers
Issue key: SPARK-44449
Issue id: 13543702
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/16/23 23:17
Updated: 7/25/23 0:46
Last Viewed: 7/17/24 20:45
Resolved: 7/25/23 0:46
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): SPARK-44396
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 17:34.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j69s:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: parse_url treats key as regular expression
Issue key: SPARK-44500
Issue id: 13544306
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: revans2
Creator: revans2
Created: 7/20/23 14:36
Updated: 7/24/23 23:41
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.2.0, 3.3.0, 3.4.0, 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: To be clear I am not 100% sure that this is a bug. It might be a feature, but I don't see anywhere that it is used as a feature. If it is a feature it really should be documented, because there are pitfalls. If it is a bug it should be fixed because it is really confusing and it is simple to shoot yourself in the foot.

```scala
> val urls = Seq("http://foo/bar?abc=BAD&a.c=GOOD", "http://foo/bar?a.c=GOOD&abc=BAD").toDF
> urls.selectExpr("parse_url(value, 'QUERY', 'a.c')").show(false)

+----------------------------+
|parse_url(value, QUERY, a.c)|
+----------------------------+
|BAD                         |
|GOOD                        |
+----------------------------+

> urls.selectExpr("parse_url(value, 'QUERY', 'a[c')").show(false)
java.util.regex.PatternSyntaxException: Unclosed character class near index 15
(&|^)a[c=([^&]*)
               ^
  at java.util.regex.Pattern.error(Pattern.java:1969)
  at java.util.regex.Pattern.clazz(Pattern.java:2562)
  at java.util.regex.Pattern.sequence(Pattern.java:2077)
  at java.util.regex.Pattern.expr(Pattern.java:2010)
  at java.util.regex.Pattern.compile(Pattern.java:1702)
  at java.util.regex.Pattern.<init>(Pattern.java:1352)
  at java.util.regex.Pattern.compile(Pattern.java:1028)

```

The simple fix is to quote the key when making the pattern.

```scala
  private def getPattern(key: UTF8String): Pattern = {
    Pattern.compile(REGEXPREFIX + Pattern.quote(key.toString) + REGEXSUBFIX)
  }
```
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Jul 24 23:41:37 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ja00:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 24/Jul/23 23:41;planga82;[~jan.chou.wu@gmail.com] What do you think?;;;
Affects Version/s.1: 3.3.0
Affects Version/s.2: 3.4.0
Affects Version/s.3: 3.4.1
Affects Version/s.4: 
Comment.1:

Summary: SHOW CREATE TABLE does not quote identifiers with special characters
Issue key: SPARK-44455
Issue id: 13543721
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: runyao
Reporter: runyao
Creator: runyao
Created: 7/17/23 6:32
Updated: 7/24/23 22:20
Last Viewed: 7/17/24 20:45
Resolved: 7/24/23 22:20
Affects Version/s: 3.4.0, 3.4.1
Fix Version/s: 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: Create a table with special characters:

```

CREATE CATALOG `a_catalog-with+special^chars`; CREATE SCHEMA `a_catalog-with+special^chars`.`a_schema-with+special^chars`; CREATE TABLE `a_catalog-with+special^chars`.`a_schema-with+special^chars`.`table1` ( id int, feat1 varchar(255), CONSTRAINT pk PRIMARY KEY (id,feat1) );

```

Then run SHOW CREATE TABLE:

```

SHOW CREATE TABLE `a_catalog-with+special^chars`.`a_schema-with+special^chars`.`table1`;

```

The response is:

```

createtab_stmt "CREATE TABLE a_catalog-with+special^chars.a_schema-with+special^chars.table1 ( id INT NOT NULL, feat1 VARCHAR(255) NOT NULL, CONSTRAINT pk PRIMARY KEY (id, feat1)) USING delta TBLPROPERTIES ( 'delta.minReaderVersion' = '1', 'delta.minWriterVersion' = '2') "

```

As you can see, the table name in the response is not properly escaped with backticks. As a result, if a user copies and pastes this create table command to recreate the table, it will fail:

{{[INVALID_IDENTIFIER] The identifier a_catalog-with is invalid. Please, consider quoting it with back-quotes as `a_catalog-with`.(line 1, pos 22)}}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Jul 24 22:20:34 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j6e0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 17/Jul/23 06:39;runyao;Fix in https://github.com/apache/spark/pull/42034;;;, 24/Jul/23 22:20;Gengliang.Wang;Issue resolved by pull request 42034
[https://github.com/apache/spark/pull/42034];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 24/Jul/23 22:20;Gengliang.Wang;Issue resolved by pull request 42034
[https://github.com/apache/spark/pull/42034];;;

Summary: optimize generateTreeString code path
Issue key: SPARK-44485
Issue id: 13544186
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: liuzq12
Reporter: liuzq12
Creator: liuzq12
Created: 7/19/23 21:25
Updated: 7/22/23 7:44
Last Viewed: 7/17/24 20:45
Resolved: 7/22/23 7:44
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0, 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: In `TreeNode.generateTreeString`, we observed inefficiency in scala collection operations and virtual function call.

This inefficiency become significant in large plan (we hit a example of more than 1000 nodes). So {*}it’s worth optimizing the super hot code path{*}. By rewriting into native Java code(not so sweet as scala syntax sugar though), we should be able to get rid of most of the overhead.

 

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sat Jul 22 07:44:01 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j99c:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 22/Jul/23 07:44;gurwls223;Issue resolved by pull request 42095
[https://github.com/apache/spark/pull/42095];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: KubernetesSuite report NPE when not set spark.kubernetes.test.unpackSparkDir
Issue key: SPARK-44487
Issue id: 13544200
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: fanjia
Reporter: fanjia
Creator: fanjia
Created: 7/20/23 1:56
Updated: 7/21/23 1:48
Last Viewed: 7/17/24 20:45
Resolved: 7/21/23 1:48
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: Kubernetes, Tests
Due Date: 
Votes: 0
Labels: 
Description: KubernetesSuite report NPE when not set spark.kubernetes.test.unpackSparkDir

 

Exception encountered when invoking run on a nested suite.
java.lang.NullPointerException
    at sun.nio.fs.UnixPath.normalizeAndCheck(UnixPath.java:77)
    at sun.nio.fs.UnixPath.<init>(UnixPath.java:71)
    at sun.nio.fs.UnixFileSystem.getPath(UnixFileSystem.java:281)
    at java.nio.file.Paths.get(Paths.java:84)
    at org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite.$anonfun$beforeAll$4(KubernetesSuite.scala:164)
    at org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite.$anonfun$beforeAll$4$adapted(KubernetesSuite.scala:163)
    at scala.collection.LinearSeqOptimized.find(LinearSeqOptimized.scala:115)
    at scala.collection.LinearSeqOptimized.find$(LinearSeqOptimized.scala:112)
    at scala.collection.immutable.List.find(List.scala:91)
    at org.apache.spark.deploy.k8s.integrationtest.KubernetesSuite.beforeAll(KubernetesSuite.scala:163)
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Jul 21 01:48:03 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j9cg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 21/Jul/23 01:48;gurwls223;Issue resolved by pull request 42081
[https://github.com/apache/spark/pull/42081];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: FileSourceScanExec OutputPartitioning for non bucketed scan
Issue key: SPARK-44499
Issue id: 13544302
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: tushar.mahale
Creator: tushar.mahale
Created: 7/20/23 13:42
Updated: 7/20/23 13:42
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: FileSourceScanExec.outputPartitioning currently is calculated for bucketed scan only and for non-bucketed scan, we return UnknownPartitioning(0). This may result into unnecessary empty tasks creation, based on the SQLConf defaultParallelism setting even though the actual file may have very low number of partitions.

We need to also calculate and set the number of output partitions correctly for non-bucketed scan.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 42:21.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j9z4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Add direct Arrow deserialization
Issue key: SPARK-44396
Issue id: 13543336
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/12/23 19:23
Updated: 7/19/23 13:28
Last Viewed: 7/17/24 20:45
Resolved: 7/19/23 13:28
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect, SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): SPARK-44449
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): SPARK-42554
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Jul 18 09:10:18 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j40o:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 18/Jul/23 09:10;githubbot;User 'hvanhovell' has created a pull request for this issue:
https://github.com/apache/spark/pull/42011;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Handle char/varchar in Dataset.to to keep consistent with others
Issue key: SPARK-44409
Issue id: 13543408
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: yao
Reporter: yao
Creator: yao
Created: 7/13/23 9:45
Updated: 7/17/23 5:35
Last Viewed: 7/17/24 20:45
Resolved: 7/17/23 5:35
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): SPARK-33641
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Jul 17 05:35:43 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j4gg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 17/Jul/23 05:35;Qin Yao;Issue resolved by pull request 41992
[https://github.com/apache/spark/pull/41992];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: DistributionAndOrderingUtils should apply ResolveTimeZone
Issue key: SPARK-44180
Issue id: 13541305
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: chengpan
Reporter: chengpan
Creator: chengpan
Created: 6/25/23 12:31
Updated: 7/14/23 1:26
Last Viewed: 7/17/24 20:45
Resolved: 7/14/23 1:26
Affects Version/s: 3.4.1
Fix Version/s: 3.4.2, 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Jul 14 01:26:11 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1irk8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 26/Jun/23 03:39;snoot;User 'pan3793' has created a pull request for this issue:
https://github.com/apache/spark/pull/41725;;;, 14/Jul/23 01:26;cloud_fan;Issue resolved by pull request 41725
[https://github.com/apache/spark/pull/41725];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 14/Jul/23 01:26;cloud_fan;Issue resolved by pull request 41725
[https://github.com/apache/spark/pull/41725];;;

Summary: Scala foreachBatch API in Streaming Spark Connect
Issue key: SPARK-44398
Issue id: 13543339
Parent id: 
Issue Type: Task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: rangadi
Reporter: rangadi
Creator: rangadi
Created: 7/12/23 20:26
Updated: 7/13/23 17:48
Last Viewed: 7/17/24 20:45
Resolved: 7/13/23 17:48
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: Implement foreachBatch API in Scala Spark Connect
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): SPARK-42938
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Jul 13 17:48:19 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j41c:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 13/Jul/23 17:48;XinrongM;Issue resolved by pull request 41969
[https://github.com/apache/spark/pull/41969];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Remove toAttributes from StructType
Issue key: SPARK-44353
Issue id: 13543003
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/10/23 12:01
Updated: 7/12/23 6:27
Last Viewed: 7/17/24 20:45
Resolved: 7/12/23 6:27
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect, SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 01:44.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j1z4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Status of execution w/ error and w/o jobs shall be FAILED not COMPLETED
Issue key: SPARK-44334
Issue id: 13542788
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: yao
Reporter: yao
Creator: yao
Created: 7/7/23 9:37
Updated: 7/12/23 5:35
Last Viewed: 7/17/24 20:45
Resolved: 7/12/23 5:35
Affects Version/s: 3.3.2, 3.4.1, 3.5.0
Fix Version/s: 3.5.0
Component/s: SQL, Web UI
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Jul 12 05:35:21 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j0nc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 12/Jul/23 05:35;Qin Yao;Issue resolved by pull request 41891
[https://github.com/apache/spark/pull/41891];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Migrate Buf remote generation alpha to remote plugins
Issue key: SPARK-44370
Issue id: 13543106
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: fanjia
Reporter: fanjia
Creator: fanjia
Created: 7/11/23 6:17
Updated: 7/12/23 4:45
Last Viewed: 7/17/24 20:45
Resolved: 7/12/23 4:45
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: Buf unsupported remote generation alpha at now. Please refer [https://buf.build/docs/migration-guides/migrate-remote-generation-alpha/] . We should migrate Buf remote generation alpha to remote plugins by follow the guide.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Jul 12 04:45:11 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j2lk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 12/Jul/23 04:26;snoot;User 'Hisoka-X' has created a pull request for this issue:
https://github.com/apache/spark/pull/41933;;;, 12/Jul/23 04:45;gurwls223;Issue resolved by pull request 41933
[https://github.com/apache/spark/pull/41933];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 12/Jul/23 04:45;gurwls223;Issue resolved by pull request 41933
[https://github.com/apache/spark/pull/41933];;;

Summary: Broadcast Joins taking up too much memory
Issue key: SPARK-44379
Issue id: 13543178
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: shardulm
Creator: shardulm
Created: 7/11/23 18:02
Updated: 7/11/23 18:05
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: Context: After migrating to Spark 3 with AQE, we saw a significant increase in driver and executor memory usage in our jobs which contains star joins. By analyzing heapdump, we saw that majority of the memory was being taken up by {{UnsafeHashedRelation}} used for broadcast joins; in this case there were 92 broadcast joins in the query.

!screenshot-1.png|width=851,height=70!

This took up over 6GB of total memory, even though every table being broadcasted was around ~1MB and hence should only have been ~100MB total. I found that this is because {{BytesToBytesMap}} used within {{UnsafeHashedRelation}} allocates memory in ["pageSize" increments|https://github.com/apache/spark/blob/37aa62f629e652ed70505620473530cd9611018e/core/src/main/java/org/apache/spark/memory/MemoryConsumer.java#L117] which in our case was 64MB. Based on the [default page size calculation|https://github.com/apache/spark/blob/37aa62f629e652ed70505620473530cd9611018e/core/src/main/scala/org/apache/spark/memory/MemoryManager.scala#L251], this should be the case for any container with > 1 GB of memory (assuming executor.cores = 1) which is far too common. Thus in our case, most of the memory requested by {{BytesToBytesMap}} was un-utilized with just trailing 0s.

!screenshot-2.png|width=389,height=101!

I think this is a major inefficiency for broadcast joins (especially star joins). I think there are a few ways to tackle the problem.
1) Reduce {{spark.buffer.pageSize}} globally to a lower value. This does reduce the memory consumption of broadcast joins, but I am not sure what it implies for the rest of Spark machinery
2) Add a "finalize" operation to {{BytesToBytesMap}} which is called after all values are added to the map and allocates a new page only for the required bytes. 
3) Enhance the serialization of {{BytesToBytesMap}} to record the number of keys and values, and use those during deserialization to only request the required memory.
4) Use a lower page size for certain {{BytesToBytesMap}} based on the estimated data size of broadcast joins.

I believe Option 3 would be simple enough to implement and I have a POC PR which I will post soon, but I am interested in knowing other people's thoughts here. 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 11/Jul/23 18:03;shardulm;screenshot-1.png;https://issues.apache.org/jira/secure/attachment/13061250/screenshot-1.png, 11/Jul/23 18:03;shardulm;screenshot-2.png;https://issues.apache.org/jira/secure/attachment/13061251/screenshot-2.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 2
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Jul 11 18:05:47 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j31k:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 11/Jul/23 18:05;shardulm;cc: [~cloud_fan] [~joshrosen] [~mridul] Would be interested in knowing your thoughts here.;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Allow ChannelBuilder extensions -- Scala
Issue key: SPARK-44263
Issue id: 13542094
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: cdkrot
Reporter: cdkrot
Creator: cdkrot
Created: 6/30/23 12:31
Updated: 7/11/23 8:34
Last Viewed: 7/17/24 20:45
Resolved: 7/11/23 8:34
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: Follow up to https://issues.apache.org/jira/browse/SPARK-43332

Provide similar extension capabilities in Scala
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Jul 11 08:34:11 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1iweo:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 04/Jul/23 09:04;githubbot;User 'cdkrot' has created a pull request for this issue:
https://github.com/apache/spark/pull/41807;;;, 07/Jul/23 11:20;ggintegration;User 'cdkrot' has created a pull request for this issue:
https://github.com/apache/spark/pull/41880;;;, 11/Jul/23 08:34;gurwls223;Issue resolved by pull request 41880
[https://github.com/apache/spark/pull/41880];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 07/Jul/23 11:20;ggintegration;User 'cdkrot' has created a pull request for this issue:
https://github.com/apache/spark/pull/41880;;;

Summary: Potential for incorrect results or NPE when full outer USING join has null key value
Issue key: SPARK-44251
Issue id: 13541996
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: bersprockets
Reporter: bersprockets
Creator: bersprockets
Created: 6/29/23 19:53
Updated: 7/11/23 3:22
Last Viewed: 7/17/24 20:45
Resolved: 7/11/23 3:21
Affects Version/s: 3.3.2, 3.4.1, 3.5.0
Fix Version/s: 3.3.3, 3.4.2, 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: correctness
Description: The following query produces incorrect results:
{noformat}
create or replace temp view v1 as values (1, 2), (null, 7) as (c1, c2);
create or replace temp view v2 as values (2, 3) as (c1, c2);

select explode(array(c1)) as x
from v1
full outer join v2
using (c1);

-1   <== should be null
1
2
{noformat}
The following query fails with a {{NullPointerException}}:
{noformat}
create or replace temp view v1 as values ('1', 2), (null, 7) as (c1, c2);
create or replace temp view v2 as values ('2', 3) as (c1, c2);

select explode(array(c1)) as x
from v1
full outer join v2
using (c1);

23/06/25 17:06:39 ERROR Executor: Exception in task 0.0 in stage 14.0 (TID 11)
java.lang.NullPointerException
	at org.apache.spark.sql.catalyst.expressions.codegen.UnsafeWriter.write(UnsafeWriter.java:110)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.generate_doConsume_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.smj_consumeFullOuterJoinRow_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.wholestagecodegen_findNextJoinRows_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)
...
{noformat}

Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Jul 11 03:21:22 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ivsw:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 29/Jun/23 19:57;bersprockets;This is similar to, but not quite the same as SPARK-43718, and the fix will be similar too.

I will make a PR shortly.
 ;;;, 30/Jun/23 17:17;bersprockets;PR can be found here: https://github.com/apache/spark/pull/41809;;;, 11/Jul/23 03:21;yumwang;Issue resolved by pull request 41809
[https://github.com/apache/spark/pull/41809];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 30/Jun/23 17:17;bersprockets;PR can be found here: https://github.com/apache/spark/pull/41809;;;

Summary: Move sameType back to DataType
Issue key: SPARK-44352
Issue id: 13542998
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/10/23 11:22
Updated: 7/10/23 18:46
Last Viewed: 7/17/24 20:45
Resolved: 7/10/23 18:46
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect, SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Jul 10 12:01:30 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j1y0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 10/Jul/23 12:01;awsthni;User 'hvanhovell' has created a pull request for this issue:
https://github.com/apache/spark/pull/41921;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Separate encoder inference from expression encoder generation in ScalaReflection
Issue key: SPARK-44343
Issue id: 13542876
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/8/23 12:17
Updated: 7/10/23 18:45
Last Viewed: 7/17/24 20:45
Resolved: 7/10/23 18:45
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect, SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 17:56.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j16w:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Any fields set to Any.getDefaultInstance cause exceptions.
Issue key: SPARK-44337
Issue id: 13542859
Parent id: 
Issue Type: Task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: rangadi
Reporter: rangadi
Creator: rangadi
Created: 7/8/23 1:01
Updated: 7/10/23 6:41
Last Viewed: 7/17/24 20:45
Resolved: 7/10/23 6:41
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Protobuf
Due Date: 
Votes: 0
Labels: 
Description: Protobuf functions added support for converting `Any` fields to json strings. 

It uses Protobuf's built in `JsonFormat` to covert to JSON.

JsonFormat fails to handled the fields when they are set to `Any.getDefaultInstance()` in the original message. This fails only while using descriptor set, but does not fail while using Java classes. Since using descriptor files is the common case, this can be blocker. 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): SPARK-40653
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Jul 10 06:41:10 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j134:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 10/Jul/23 06:41;gurwls223;Issue resolved by pull request 41897
[https://github.com/apache/spark/pull/41897];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Move EnhancedLogicalPlan out of ParserUtils
Issue key: SPARK-44333
Issue id: 13542769
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/7/23 7:35
Updated: 7/7/23 17:37
Last Viewed: 7/17/24 20:45
Resolved: 7/7/23 17:37
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 35:18.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j0j4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Make parser use SqlApiConf
Issue key: SPARK-44322
Issue id: 13542694
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/6/23 12:28
Updated: 7/7/23 17:36
Last Viewed: 7/17/24 20:45
Resolved: 7/7/23 17:36
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 28:35.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j02o:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: [PYTHON][CONNECT] Use SPARK_CONNECT_USER_AGENT environment variable for the user agent
Issue key: SPARK-44312
Issue id: 13542590
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: dillitz
Reporter: dillitz
Creator: dillitz
Created: 7/5/23 20:53
Updated: 7/7/23 2:58
Last Viewed: 7/17/24 20:45
Resolved: 7/7/23 2:58
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: Allow us to prepend a Spark Connect user agent with an environment variable: *SPARK_CONNECT_USER_AGENT*
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Jul 07 02:58:13 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1izfk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 07/Jul/23 02:58;gurwls223;Issue resolved by pull request 41866
[https://github.com/apache/spark/pull/41866];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Move Origin to api
Issue key: SPARK-44283
Issue id: 13542347
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/3/23 22:07
Updated: 7/6/23 12:26
Last Viewed: 7/17/24 20:45
Resolved: 7/6/23 12:26
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 07:34.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ixyw:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Add tests to ensure error-classes.json and docs are in sync
Issue key: SPARK-44268
Issue id: 13542203
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: fanjia
Reporter: fanjia
Creator: fanjia
Created: 7/1/23 15:24
Updated: 7/6/23 3:45
Last Viewed: 7/17/24 20:45
Resolved: 7/2/23 15:51
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: We should add tests to ensure error-classes.json and docs are in sync, docs and error-classes.json are always up to date before the PR is committed.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Jul 06 03:45:20 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ix2w:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 02/Jul/23 15:51;maxgekk;Issue resolved by pull request 41813
[https://github.com/apache/spark/pull/41813];;;, 03/Jul/23 10:22;ignitetcbot;User 'Hisoka-X' has created a pull request for this issue:
https://github.com/apache/spark/pull/41813;;;, 06/Jul/23 03:45;snoot;User 'Hisoka-X' has created a pull request for this issue:
https://github.com/apache/spark/pull/41865;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 03/Jul/23 10:22;ignitetcbot;User 'Hisoka-X' has created a pull request for this issue:
https://github.com/apache/spark/pull/41813;;;

Summary: Generated column expression validation fails if there is a char/varchar column anywhere in the schema
Issue key: SPARK-44313
Issue id: 13542601
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: allison-portis
Reporter: allison-portis
Creator: allison-portis
Created: 7/5/23 22:37
Updated: 7/6/23 2:27
Last Viewed: 7/17/24 20:45
Resolved: 7/6/23 2:27
Affects Version/s: 3.4.0, 3.4.1
Fix Version/s: 3.4.2, 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: When validating generated column expressions, this call https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/util/GeneratedColumn.scala#L123 to checkAnalysis fails when there are char or varchar columns anywhere in the schema.

 

For example, this query will fail
{code:java}
CREATE TABLE default.example (
    name VARCHAR(64),
    tstamp TIMESTAMP,
    tstamp_date DATE GENERATED ALWAYS AS (CAST(tstamp as DATE))
){code}
 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): SPARK-41290
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Jul 06 02:27:18 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1izi0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 06/Jul/23 02:27;Qin Yao;Issue resolved by pull request 41868
[https://github.com/apache/spark/pull/41868];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Split of DataType parsing for Connect
Issue key: SPARK-44282
Issue id: 13542346
Parent id: 
Issue Type: New Feature
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: hvanhovell
Reporter: hvanhovell
Creator: hvanhovell
Created: 7/3/23 21:58
Updated: 7/5/23 20:23
Last Viewed: 7/17/24 20:45
Resolved: 7/5/23 20:23
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 58:19.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ixyo:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: [CONNECT][SCALA] range query returns incorrect schema
Issue key: SPARK-44291
Issue id: 13542365
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: nija
Reporter: nija
Creator: nija
Created: 7/4/23 5:58
Updated: 7/5/23 19:13
Last Viewed: 7/17/24 20:45
Resolved: 7/5/23 19:13
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: The following code on Spark Connect produces the following output

Code:

 
{code:java}
val df = spark.range(3)

df.show()
df.printSchema(){code}
 

Output:
{code:java}
+---+
| id|
+---+
|  0|
|  1|
|  2|
+---+

root
 |-- value: long (nullable = true) {code}
The mismatch is that one shows the column as "id" while the other shows this as "value".
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 58:14.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1iy2w:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: CacheManager refreshes the fileIndex unnecessarily
Issue key: SPARK-44199
Issue id: 13541463
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: vihangk1
Reporter: vihangk1
Creator: vihangk1
Created: 6/26/23 18:30
Updated: 7/3/23 23:08
Last Viewed: 7/17/24 20:45
Resolved: 7/3/23 23:08
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: The CacheManager on this line [https://github.com/apache/spark/blob/680ca2e56f2c8fc759743ad6755f6e3b1a19c629/sql/core/src/main/scala/org/apache/spark/sql/execution/CacheManager.scala#L372] uses a prefix based matching to decide which file index needs to be refreshed. However, that can be incorrect if the users have paths which are not subdirectories but share prefixes. For example, in the function below:

 
{code:java}
  private def refreshFileIndexIfNecessary(
      fileIndex: FileIndex,
      fs: FileSystem,
      qualifiedPath: Path): Boolean = {
    val prefixToInvalidate = qualifiedPath.toString
    val needToRefresh = fileIndex.rootPaths
      .map(_.makeQualified(fs.getUri, fs.getWorkingDirectory).toString)
      .exists(_.startsWith(prefixToInvalidate))
    if (needToRefresh) fileIndex.refresh()
    needToRefresh
  } {code}
{{If the prefixToInvalidate is s3://bucket/mypath/table_dir and the file index has one of the root paths as s3://bucket/mypath/table_dir_2/part=1, then the needToRefresh will be true and the file index gets refreshed unnecessarily. This is not just wasted CPU cycles but can cause query failures as well, if there are access restrictions to the path being refreshed.}}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Jun 29 16:52:55 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1isjc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 29/Jun/23 16:52;ignitetcbot;User 'vihangk1' has created a pull request for this issue:
https://github.com/apache/spark/pull/41749;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Inconsistent path qualifying between catalog and data operations
Issue key: SPARK-44185
Issue id: 13541343
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: yao
Reporter: yao
Creator: yao
Created: 6/26/23 3:49
Updated: 7/3/23 9:27
Last Viewed: 7/17/24 20:45
Resolved: 7/3/23 9:27
Affects Version/s: 3.2.4, 3.3.2, 3.4.1, 3.5.0
Fix Version/s: 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: For example
 * CREATE TABLE statement with relative LOCATION will infer schema from files from the directory relative to the current working directory and store the directory relative to the warehouse path. 
 * CTAS statement with relative LOCATION cannot assert empty root path as it checks the wrong path it will finally use.
 * DataframeWriter does not qualify the path before checking
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Jul 03 09:27:20 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1irso:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 03/Jul/23 09:27;yumwang;Issue resolved by pull request https://github.com/apache/spark/pull/41733;;;
Affects Version/s.1: 3.3.2
Affects Version/s.2: 3.4.1
Affects Version/s.3: 3.5.0
Affects Version/s.4: 
Comment.1:

Summary: Potential memory leak when temp views created from DF created by structured streaming
Issue key: SPARK-44253
Issue id: 13542000
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: attilapiros
Creator: attilapiros
Created: 6/29/23 20:22
Updated: 6/29/23 20:41
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 2.4.8, 3.0.3, 3.1.3, 3.2.4, 3.3.2, 3.4.0, 3.4.1
Fix Version/s: 
Component/s: Structured Streaming
Due Date: 
Votes: 0
Labels: 
Description: If the user registers a temporary view from a dataframe created by Structured Streaming and tries to drop the temporary view via his original SparkSession then memory will be leaking.

The reason is Structured streaming has its own SparkSession (as a clone of the original SparkSession, for details see https://issues.apache.org/jira/browse/SPARK-26586 and [https://github.com/apache/spark/blob/branch-3.4/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/StreamExecution.scala#L193-L194]) the created temporary view belongs the cloned SparkSession and the dropping of the temporary view must be done via the cloned SparkSession.

Example for the {*}memory leak{*}:
{noformat}
streamingDF.writeStream.foreachBatch { (batchDF: DataFrame, batchId: Long) =>
  val view = s“tempView_$batchId” 
  batchDF.createOrReplaceTempView(view)
  ...
  spark.catalog.dropTempView(view)
}
{noformat}
*Workaround* (the _dropTempView_ must be called on SparkSession accessed from dataframe created by streaming):
{noformat}
streamingDF.writeStream.foreachBatch { (batchDF: DataFrame, batchId: Long) =>
  val view = s“tempView_$batchId” 
  batchDF.createOrReplaceTempView(view)
  ...
  batchDF.sparkSession.catalog.dropTempView(view)
 }
{noformat}
h4. Example heap dump

The SparkSession with the leak:

!1.png|width=807,height=120!

The two SparkSession instances where the first one was is the original SparkSession created by the user and the second is the clone:
!2.png|width=813,height=157!
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 29/Jun/23 20:22;attilapiros;1.png;https://issues.apache.org/jira/secure/attachment/13060978/1.png, 29/Jun/23 20:23;attilapiros;2.png;https://issues.apache.org/jira/secure/attachment/13060979/2.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 2
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 22:46.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ivts:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.0.3
Affects Version/s.2: 3.1.3
Affects Version/s.3: 3.2.4
Affects Version/s.4: 3.3.2
Comment.1:

Summary: Exception when reading parquet file with TIME fields
Issue key: SPARK-44165
Issue id: 13541242
Parent id: 
Issue Type: New Feature
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: ramon_garcia_fer
Creator: ramon_garcia_fer
Created: 6/24/23 11:41
Updated: 6/29/23 16:52
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.0, 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: When one reads a parquet file containing TIME fields (either with INT32 or INT64 storage) and exception is thrown. From spark shell

 

{{> val df = spark.read.parquet("timeonly.parquet")}}

{color:#de350b}23/06/24 13:24:54 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)/ 1]{color}
{color:#de350b}org.apache.spark.sql.AnalysisException: Illegal Parquet type: INT32 (TIME(MILLIS,true)).{color}
{color:#de350b}    at org.apache.spark.sql.errors.QueryCompilationErrors$.illegalParquetTypeError(QueryCompilationErrors.scala:1762){color}
{color:#de350b}    at org.apache.spark.sql.execution.datasources.parquet.ParquetToSparkSchemaConverter.illegalType$1(ParquetSchemaConverter.scala:206){color}
{color:#de350b}    at org.apache.spark.sql.execution.datasources.parquet.ParquetToSparkSchemaConverter.$anonfun$convertPrimitiveField$2(ParquetSchemaConverter.scala:252){color}
{color:#de350b}    at scala.Option.getOrElse(Option.scala:189){color}
{color:#de350b}    at org.apache.spark.sql.execution.datasources.parquet.ParquetToSparkSchemaConverter.convertPrimitiveField(ParquetSchemaConverter.scala:224){color}
{color:#de350b}    at org.apache.spark.sql.execution.datasources.parquet.ParquetToSparkSchemaConverter.convertField(ParquetSchemaConverter.scala:187){color}
{color:#de350b}    at org.apache.spark.sql.execution.datasources.parquet.ParquetToSparkSchemaConverter.$anonfun$convertInternal$3(ParquetSchemaConverter.scala:147){color}
Environment: Spark 3.4.0 downloaded from apache.spark.org

Also reproduced with latest build.
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 24/Jun/23 11:41;ramon_garcia_fer;timeonly.parquet;https://issues.apache.org/jira/secure/attachment/13060833/timeonly.parquet
Custom field (Affects version (Component)): 
Custom field (Attachment count): 1
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Jun 29 16:52:46 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ir68:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 26/Jun/23 17:06;ramon_garcia_fer;Added [pull request 41717|https://github.com/apache/spark/pull/41717] to support TIME columns.;;;, 29/Jun/23 16:52;ignitetcbot;User 'ramon-garcia' has created a pull request for this issue:
https://github.com/apache/spark/pull/41717;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 29/Jun/23 16:52;ignitetcbot;User 'ramon-garcia' has created a pull request for this issue:
https://github.com/apache/spark/pull/41717;;;

Summary: Add Apache Spark 3.4.1 Dockerfiles
Issue key: SPARK-44168
Issue id: 13541268
Parent id: 13482511
Issue Type: Sub-task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: yikunkero
Reporter: yikunkero
Creator: yikunkero
Created: 6/25/23 1:29
Updated: 6/29/23 8:05
Last Viewed: 7/17/24 20:45
Resolved: 6/25/23 7:07
Affects Version/s: 3.4.1
Fix Version/s: 3.4.1
Component/s: Spark Docker
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 29:06.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1irc0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: CTAS missing the child info on UI when groupSQLSubExecutionEnabled is enabled
Issue key: SPARK-44213
Issue id: 13541605
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: yumwang
Creator: yumwang
Created: 6/27/23 16:36
Updated: 6/27/23 16:39
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.0, 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: {code:sql}
create table tbl using parquet as select t1.id from range(10) as t1 join range(100) as t2 on t1.id = t2.id;
{code}
Enabled:
 !enabled.png! 
Disabled:
 !screenshot-1.png! 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 27/Jun/23 16:36;yumwang;enabled.png;https://issues.apache.org/jira/secure/attachment/13060897/enabled.png, 27/Jun/23 16:36;yumwang;screenshot-1.png;https://issues.apache.org/jira/secure/attachment/13060898/screenshot-1.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 2
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Jun 27 16:39:25 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1iteg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 27/Jun/23 16:37;yumwang;cc [~linhongliu-db];;;, 27/Jun/23 16:39;yumwang;Related issue ticket: SPARK-41752.;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 27/Jun/23 16:39;yumwang;Related issue ticket: SPARK-41752.;;;

Summary: Remove a wrong doc about ARROW_PRE_0_15_IPC_FORMAT
Issue key: SPARK-44184
Issue id: 13541334
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: dongjoon
Reporter: dongjoon
Creator: dongjoon
Created: 6/25/23 22:21
Updated: 6/26/23 1:53
Last Viewed: 7/17/24 20:45
Resolved: 6/26/23 1:53
Affects Version/s: 3.0.3, 3.1.3, 3.2.4, 3.3.2, 3.4.1, 3.5.0
Fix Version/s: 3.3.3, 3.4.2, 3.5.0
Component/s: Documentation, PySpark
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Jun 26 01:53:57 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1irqo:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 26/Jun/23 01:53;dongjoon;Issue resolved by pull request 41730
[https://github.com/apache/spark/pull/41730];;;
Affects Version/s.1: 3.1.3
Affects Version/s.2: 3.2.4
Affects Version/s.3: 3.3.2
Affects Version/s.4: 3.4.1
Comment.1:

Summary: Update the incorrect sql example of insert table documentation
Issue key: SPARK-44072
Issue id: 13540295
Parent id: 
Issue Type: Documentation
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: yoha.zy
Reporter: yoha.zy
Creator: yoha.zy
Created: 6/16/23 2:15
Updated: 6/16/23 5:26
Last Viewed: 7/17/24 20:45
Resolved: 6/16/23 3:08
Affects Version/s: 3.3.3, 3.4.1, 3.5.0
Fix Version/s: 3.5.0
Component/s: Documentation
Due Date: 
Votes: 0
Labels: 
Description: Latest docs of insert table has an incorrect sql example about 'Insert Using a Typed Date Literal for a Partition Column Value'.

It should be
{code:java}
INSERT OVERWRITE students PARTITION (birthday = date'2019-01-02') VALUES('Jason Wang', '908 Bird St, Saratoga'); {code}
Doc link: https://spark.apache.org/docs/latest/sql-ref-syntax-dml-insert-table.html#insert-using-a-typed-date-literal-for-a-partition-column-value-1
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Jun 16 03:51:38 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ildc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 16/Jun/23 03:08;Qin Yao;Issue resolved by pull request 41619
[https://github.com/apache/spark/pull/41619];;;, 16/Jun/23 03:51;snoot;User 'Yohahaha' has created a pull request for this issue:
https://github.com/apache/spark/pull/41619;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 16/Jun/23 03:51;snoot;User 'Yohahaha' has created a pull request for this issue:
https://github.com/apache/spark/pull/41619;;;

Summary: Update ORC to 1.8.4
Issue key: SPARK-44053
Issue id: 13540006
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: Guiyankuang
Reporter: Guiyankuang
Creator: Guiyankuang
Created: 6/14/23 8:25
Updated: 6/14/23 17:56
Last Viewed: 7/17/24 20:45
Resolved: 6/14/23 16:37
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 3.4.1, 3.5.0
Component/s: Build
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Jun 14 17:56:09 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ijl4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 14/Jun/23 08:43;Guiyankuang;Our plan is to
spark 3.4.1 upgrade to ORC 1.8.4
spark 3.5.0 upgrade to ORC 1.9.0
So I set the affected version to 3.4.1

[~yumwang]  :);;;, 14/Jun/23 16:37;dongjoon;Issue resolved by pull request 41593
[https://github.com/apache/spark/pull/41593];;;, 14/Jun/23 17:56;dongjoon;Apache ORC 1.9.0 PR will arrive soon in this month.;;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 14/Jun/23 16:37;dongjoon;Issue resolved by pull request 41593
[https://github.com/apache/spark/pull/41593];;;

Summary: SerializerHelper.deserializeFromChunkedBuffer leaks deserialization streams
Issue key: SPARK-43378
Issue id: 13534986
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: eejbyfeldt
Reporter: eejbyfeldt
Creator: eejbyfeldt
Created: 5/4/23 12:59
Updated: 6/6/23 7:04
Last Viewed: 7/17/24 20:45
Resolved: 5/5/23 0:34
Affects Version/s: 3.4.0, 3.4.1, 3.5.0
Fix Version/s: 3.4.1, 3.5.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: The method SerializerHelper.deserializeFromChunkedBuffer leaks serializations stream. This can lead to huge performance regressions when using kryo serializer as the spark application can become bottlenecked on the driver creating expensive kryo objects that are then leaked as part of the deserialization stream
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri May 05 00:34:57 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1hots:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 05/May/23 00:34;srowen;Resolved by https://github.com/apache/spark/pull/41049;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Document for unbase64 behavior change
Issue key: SPARK-43751
Issue id: 13537344
Parent id: 
Issue Type: Documentation
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: chengpan
Reporter: chengpan
Creator: chengpan
Created: 5/23/23 13:54
Updated: 5/26/23 3:34
Last Viewed: 7/17/24 20:45
Resolved: 5/26/23 3:34
Affects Version/s: 3.3.3, 3.4.1, 3.5.0
Fix Version/s: 3.3.3, 3.4.1, 3.5.0
Component/s: Documentation, SQL
Due Date: 
Votes: 0
Labels: 
Description: Document behavior change caused by https://issues.apache.org/jira/browse/SPARK-37820
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri May 26 03:34:55 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1i36w:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 26/May/23 03:34;Qin Yao;Issue resolved by pull request 41280
[https://github.com/apache/spark/pull/41280];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Avoid allocation of unwritten ColumnVector in VectorizedReader
Issue key: SPARK-43264
Issue id: 13533864
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: majdyz
Creator: majdyz
Created: 4/24/23 14:40
Updated: 5/23/23 16:50
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 
Component/s: Spark Core, SQL
Due Date: 
Votes: 0
Labels: 
Description: Spark Vectorized Reader allocates the array for every fields for each value count even the array is ended up empty. This causes a high memory consumption when reading a table with large struct+array or many columns with sparse value. One way to fix this is by lazily allocating the column vector and only allocates the array only when it is needed (array is written).
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue May 23 16:50:46 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1hhxk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 23/May/23 16:50;ggintegration;User 'majdyz' has created a pull request for this issue:
https://github.com/apache/spark/pull/40929;;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Support the minimum number of range shuffle partitions
Issue key: SPARK-43593
Issue id: 13536876
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: wankun
Creator: wankun
Created: 5/19/23 14:28
Updated: 5/19/23 14:28
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: If there are few distinct values in the RangePartitioner, there will be very few partitions that could be very large. We can append a random expression to increase the number of partitions.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 28:27.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1i0aw:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Improve the error messages for INVALID_CONNECT_URL
Issue key: SPARK-43375
Issue id: 13534918
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: allisonwang-db
Reporter: allisonwang-db
Creator: allisonwang-db
Created: 5/4/23 6:51
Updated: 5/5/23 2:00
Last Viewed: 7/17/24 20:45
Resolved: 5/5/23 2:00
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 3.5.0
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: Make the INVALID_CONNECT_URL error messages more user-friendly.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri May 05 02:00:39 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1hoeo:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 05/May/23 02:00;podongfeng;Issue resolved by pull request 41044
[https://github.com/apache/spark/pull/41044];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Casting between Timestamp and TimestampNTZ requires timezone
Issue key: SPARK-43336
Issue id: 13534643
Parent id: 13382384
Issue Type: Sub-task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: Gengliang.Wang
Reporter: Gengliang.Wang
Creator: Gengliang.Wang
Created: 5/2/23 4:43
Updated: 5/2/23 20:10
Last Viewed: 7/17/24 20:45
Resolved: 5/2/23 20:10
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 3.4.1, 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue May 02 20:10:10 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1hmps:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 02/May/23 20:10;Gengliang.Wang;Issue resolved by pull request 41010
[https://github.com/apache/spark/pull/41010];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Ignore generated Java files in checkstyle
Issue key: SPARK-43141
Issue id: 13532652
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: gurwls223
Reporter: gurwls223
Creator: gurwls223
Created: 4/14/23 11:36
Updated: 4/17/23 2:57
Last Viewed: 7/17/24 20:45
Resolved: 4/16/23 10:47
Affects Version/s: 3.4.1
Fix Version/s: 3.4.1, 3.5.0
Component/s: Build
Due Date: 
Votes: 0
Labels: 
Description: Files such as {{.../spark/core/target/scala-2.12/src_managed/main/org/apache/spark/status/protobuf/StoreTypes.java}} are checked in checkstyle. We shouldn't check them in the linter.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sun Apr 16 10:47:41 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1haig:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 16/Apr/23 10:47;gurwls223;Issue resolved by pull request 40792
[https://github.com/apache/spark/pull/40792];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Redact debug string in UI
Issue key: SPARK-43089
Issue id: 13532111
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: gurwls223
Reporter: gurwls223
Creator: gurwls223
Created: 4/11/23 1:40
Updated: 4/11/23 3:23
Last Viewed: 7/17/24 20:45
Resolved: 4/11/23 3:22
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Connect, PySpark
Due Date: 
Votes: 0
Labels: 
Description: https://github.com/apache/spark/pull/40603 exposes all data without redaction. We should redact it.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Apr 11 03:23:34 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1h76o:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 11/Apr/23 03:22;gurwls223;Issue resolved by pull request 40733
[https://github.com/apache/spark/pull/40733];;;, 11/Apr/23 03:23;snoot;User 'HyukjinKwon' has created a pull request for this issue:
https://github.com/apache/spark/pull/40733;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 11/Apr/23 03:23;snoot;User 'HyukjinKwon' has created a pull request for this issue:
https://github.com/apache/spark/pull/40733;;;

Summary: Support SELECT DEFAULT with ORDER BY, LIMIT, OFFSET for INSERT source relation
Issue key: SPARK-43071
Issue id: 13531913
Parent id: 13430784
Issue Type: Sub-task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: dtenedor
Reporter: dtenedor
Creator: dtenedor
Created: 4/7/23 22:16
Updated: 4/10/23 23:09
Last Viewed: 7/17/24 20:45
Resolved: 4/10/23 23:09
Affects Version/s: 3.4.1
Fix Version/s: 3.4.1
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Apr 10 23:09:46 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1h5yo:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 10/Apr/23 23:09;Gengliang.Wang;Issue resolved by pull request 40710
[https://github.com/apache/spark/pull/40710];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: TableOutputResolver must use correct column paths in error messages for arrays and maps
Issue key: SPARK-42997
Issue id: 13531021
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: aokolnychyi
Reporter: aokolnychyi
Creator: aokolnychyi
Created: 3/31/23 19:04
Updated: 4/3/23 22:21
Last Viewed: 7/17/24 20:45
Resolved: 4/3/23 22:21
Affects Version/s: 3.3.0, 3.3.1, 3.3.2, 3.3.3, 3.4.0, 3.4.1, 3.5.0
Fix Version/s: 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: TableOutputResolver must use correct column paths in error messages for arrays and maps.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Apr 03 22:21:27 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1h0h4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 03/Apr/23 22:21;dongjoon;Issue resolved by pull request 40630
[https://github.com/apache/spark/pull/40630];;;
Affects Version/s.1: 3.3.1
Affects Version/s.2: 3.3.2
Affects Version/s.3: 3.3.3
Affects Version/s.4: 3.4.0
Comment.1:

Summary: Support TimestampNTZ in Cached Batch
Issue key: SPARK-42796
Issue id: 13528517
Parent id: 13382384
Issue Type: Sub-task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: Gengliang.Wang
Reporter: Gengliang.Wang
Creator: Gengliang.Wang
Created: 3/14/23 22:40
Updated: 3/15/23 23:23
Last Viewed: 7/17/24 20:45
Resolved: 3/15/23 23:23
Affects Version/s: 3.4.1
Fix Version/s: 3.4.1
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Mar 14 22:47:48 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1gl1k:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 14/Mar/23 22:47;apachespark;User 'gengliangwang' has created a pull request for this issue:
https://github.com/apache/spark/pull/40426;;;, 14/Mar/23 22:47;apachespark;User 'gengliangwang' has created a pull request for this issue:
https://github.com/apache/spark/pull/40426;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 14/Mar/23 22:47;apachespark;User 'gengliangwang' has created a pull request for this issue:
https://github.com/apache/spark/pull/40426;;;

Summary: Infer filters for Join produced by IN and EXISTS clause (RewritePredicateSubquery rule)
Issue key: SPARK-42660
Issue id: 13526947
Parent id: 
Issue Type: Improvement
Status: In Progress
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: 
Assignee: 
Reporter: kapilks_ms
Creator: kapilks_ms
Created: 3/3/23 7:05
Updated: 3/3/23 7:36
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Mar 03 07:36:16 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1gbcw:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 03/Mar/23 07:36;apachespark;User 'mskapilks' has created a pull request for this issue:
https://github.com/apache/spark/pull/40266;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Track state store provider load time and log warning if it exceeds a threshold
Issue key: SPARK-42567
Issue id: 13526119
Parent id: 
Issue Type: Task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Major
Resolution: Fixed
Assignee: anishshri-db
Reporter: anishshri-db
Creator: anishshri-db
Created: 2/24/23 20:04
Updated: 2/25/23 9:41
Last Viewed: 7/17/24 20:45
Resolved: 2/25/23 9:41
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Structured Streaming
Due Date: 
Votes: 0
Labels: 
Description: Track state store provider load time and log warning if it exceeds a threshold

 

In some cases, we see that the filesystem initialization might take time for the first time that we create the provider and initialize it. This change will log the time taken if it exceeds a certain threshold
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sat Feb 25 09:41:06 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1g69s:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 24/Feb/23 20:05;anishshri-db;I will send the fix out soon

 

cc - [~kabhwan] 

 ;;;, 24/Feb/23 21:28;apachespark;User 'anishshri-db' has created a pull request for this issue:
https://github.com/apache/spark/pull/40163;;;, 24/Feb/23 21:29;anishshri-db;Sent the PR here: https://github.com/apache/spark/pull/40163;;;, 25/Feb/23 09:41;kabhwan;Issue resolved by pull request 40163
[https://github.com/apache/spark/pull/40163];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 24/Feb/23 21:28;apachespark;User 'anishshri-db' has created a pull request for this issue:
https://github.com/apache/spark/pull/40163;;;

Summary: Refactor SparkConnect Service to extracted error handling functions to trait
Issue key: SPARK-48674
Issue id: 13583336
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: asethia
Creator: asethia
Created: 6/20/24 14:25
Updated: 6/20/24 17:04
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.0, 3.4.1, 3.4.2, 3.4.3
Fix Version/s: 
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: Since SparkConnect gRPC server can have multiple services (addService function on NettyServerBuilder) and these functions can be reused across services, specially when we would like to extend sparkconnect with various services.

We can extract error handling functions from SparkConnectService to a trait, that will increase code reusability. By doing this we can reuse these functions across multiple service implementations. Since we can add multiple Bindable service handlers to SparkConnect gRPC server it will be easy to use such common functions to handle errors and exceptions.
Environment: 
Log Work: 
Original Estimate: 7200
Remaining Estimate: 7200
Time Spent: 
Work Ratio: 0%
Σ Original Estimate: 7200
Σ Remaining Estimate: 7200
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Jun 20 17:04:54 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1px20:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 20/Jun/24 17:04;asethia;I think we can do cherry picking from 3.5 (ErrorUtils).;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.4.2
Affects Version/s.3: 3.4.3
Affects Version/s.4: 
Comment.1:

Summary: Executor decommission causes stage failure
Issue key: SPARK-44478
Issue id: 13544013
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: dhuett
Creator: dhuett
Created: 7/18/23 18:05
Updated: 4/24/24 13:31
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.0, 3.4.1
Fix Version/s: 
Component/s: Scheduler
Due Date: 
Votes: 0
Labels: 
Description: During spark execution, save fails due to executor decommissioning. Issue not present in 3.3.0

Sample error:

 
{code:java}
An error occurred while calling o8948.save.
: org.apache.spark.SparkException: Job aborted due to stage failure: Authorized committer (attemptNumber=0, stage=170, partition=233) failed; but task commit success, data duplication may happen. reason=ExecutorLostFailure(1,false,Some(Executor decommission: Executor 1 is decommissioned.))
        at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)
        at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)
        at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)
        at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
        at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
        at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)
        at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleStageFailed$1(DAGScheduler.scala:1199)
        at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleStageFailed$1$adapted(DAGScheduler.scala:1199)
        at scala.Option.foreach(Option.scala:407)
        at org.apache.spark.scheduler.DAGScheduler.handleStageFailed(DAGScheduler.scala:1199)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2981)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)
        at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
        at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:971)
        at org.apache.spark.SparkContext.runJob(SparkContext.scala:2263)
        at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$4(FileFormatWriter.scala:307)
        at org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:271)
        at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:304)
        at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:190)
        at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:190)
        at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)
        at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)
        at org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)
        at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)
        at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)
        at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)
        at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)
        at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)
        at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)
        at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
        at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)
        at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)
        at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)
        at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)
        at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
        at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)
        at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)
        at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)
        at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)
        at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)
        at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)
        at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)
        at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)
        at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)
        at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)
        at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)
        at jdk.internal.reflect.GeneratedMethodAccessor497.invoke(Unknown Source)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.base/java.lang.reflect.Method.invoke(Unknown Source)
        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
        at py4j.Gateway.invoke(Gateway.java:282)
        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
        at py4j.commands.CallCommand.execute(CallCommand.java:79)
        at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
        at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
        at java.base/java.lang.Thread.run(Unknown Source)
{code}
 

 

This occurred while running our production k8s spark jobs (spark 3.3.0) in a duplicate test environment, with the only change being the image used was spark 3.4.0 and 3.4.1, and the only changes in jar versions were the requisite dependencies. 

Current workaround is to retry the job, but this can cause substantial slowdowns if it occurs during a longer job.  Possibly related to https://issues.apache.org/jira/browse/SPARK-44389 ?
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Apr 24 13:31:53 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j86w:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 27/Feb/24 18:49;dongjoon;Do you still see this issue with Apache Spark 3.4.2 or 3.5.1, [~dhuett]?;;;, 10/Apr/24 11:48;juhai;I am seeing this with Spark 3.5.0 for Spark k8s workloads. We use spot instances for executors but recently seen failures of full jobs when a large number of spot instances are lost at once. The error and stack trace is identical. We have a pending upgrade to 3.5.1 due to another issue with 3.5.0, I will report back soon. The incidence of this problem totally depends on how well we get to keep spot instances so isn't easy to reproduce.;;;, 24/Apr/24 13:31;juhai;Just a short update. This is clearly related to evictions/lost nodes/etc. I've now retried with spark 3.5.1 and 3.4.3 with a cluster configuration that caused excessive pod evictions (by Karpenter). I had a handful of different tasks that all consistently failed during the execution with this error. But, not all tasks were equal; while having a pipeline of tasks, the map tasks mostly succeeded but those doing shuffles (join, sort, groupby) were the ones that mostly failed. I suppose decommissioning has an impact to resolving lost shuffle data so issue may lie somewhere there.

Our SRE team then fixed the eviction issue and suddenly all tasks with the above spark versions as well as 3.5.0 work normally. Conclusion: No evictions => no failures. I don't know what the mechanism of triggering this is but it is related to pods decommissioned by k8s. I am going to follow with this ticket in case I see any more issues.;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 10/Apr/24 11:48;juhai;I am seeing this with Spark 3.5.0 for Spark k8s workloads. We use spot instances for executors but recently seen failures of full jobs when a large number of spot instances are lost at once. The error and stack trace is identical. We have a pending upgrade to 3.5.1 due to another issue with 3.5.0, I will report back soon. The incidence of this problem totally depends on how well we get to keep spot instances so isn't easy to reproduce.;;;

Summary: Official Spark Docker Container images are available from DockerHub in 2 locations
Issue key: SPARK-47837
Issue id: 13575654
Parent id: 
Issue Type: Documentation
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: mkandes
Creator: mkandes
Created: 4/12/24 14:57
Updated: 4/12/24 14:57
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1, 3.5.0, 3.5.1
Fix Version/s: 
Component/s: Documentation
Due Date: 
Votes: 0
Labels: containers, docker, Docker, dockerhub, DockerHub, documentation, Documentation, documentation-update
Description: The downloads section of the project's website [1] provides a link [2] to an official set of Docker containers hosted on DockerHub [3]. However, most of these containers are quite outdated now and it appears as if there is now a new location where the lateset offical containers are maintained and distributed on DockerHub [4]. It would be nice to fix/update the documentation to guide users to the new / recommendation location of the official containers maintained or endorsed by the project and/or community.

[1] [https://spark.apache.org/downloads.html]

[2] [https://hub.docker.com/r/apache/spark-py/tags]

[3] [https://hub.docker.com/r/apache/spark]

[4] [https://hub.docker.com/_/spark]
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 57:33.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1olrs:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.5.0
Affects Version/s.2: 3.5.1
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Upgrade optionator to ^0.9.3
Issue key: SPARK-44279
Issue id: 13542334
Parent id: 
Issue Type: Dependency upgrade
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: bjornjorgensen
Reporter: bjornjorgensen
Creator: bjornjorgensen
Created: 7/3/23 18:23
Updated: 4/5/24 15:23
Last Viewed: 7/17/24 20:45
Resolved: 7/13/23 18:34
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 3.5.0
Component/s: Build
Due Date: 
Votes: 0
Labels: pull-request-available
Description: [Regular Expression Denial of Service (ReDoS) - CVE-2023-26115|https://github.com/jonschlinkert/word-wrap/issues/32]
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Jul 13 18:34:18 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ixw0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 3.5.0
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 11/Jul/23 17:53;srowen;Is this a library that's used in spark? I couldn't find it;;;, 11/Jul/23 18:52;bjornjorgensen;[~srowen] https://github.com/apache/spark/blob/37aa62f629e652ed70505620473530cd9611018e/dev/package-lock.json#L2226 

[word-wrap vulnerable to Regular Expression Denial of Service|https://github.com/jonschlinkert/word-wrap/issues/40]
;;;, 11/Jul/23 18:57;srowen;This is a dumb question, but what is that file? packages that what part of Spark uses? I have never seen it;;;, 11/Jul/23 19:17;bjornjorgensen;have a look at https://github.com/apache/spark/pull/35628 and https://github.com/apache/spark/pull/39143;;;, 13/Jul/23 18:34;sarutak;Issue resolved in https://github.com/apache/spark/pull/41955;;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 11/Jul/23 18:52;bjornjorgensen;[~srowen] https://github.com/apache/spark/blob/37aa62f629e652ed70505620473530cd9611018e/dev/package-lock.json#L2226 

[word-wrap vulnerable to Regular Expression Denial of Service|https://github.com/jonschlinkert/word-wrap/issues/40]
;;;

Summary: count_distinct ignores null values
Issue key: SPARK-47397
Issue id: 13571910
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: martinitus
Creator: martinitus
Created: 3/14/24 15:12
Updated: 4/2/24 9:01
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Documentation, Spark Core
Due Date: 
Votes: 0
Labels: 
Description: The documentation states, that in group by and count statements, null values will not be ignored / form their own groups.

!image-2024-03-14-16-13-03-107.png|width=491,height=373!
However, the behavior of count_distinct does not account for nulls. 
Either the documentation or the implementation is wrong here...

!image-2024-03-14-16-12-35-267.png!
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 14/Mar/24 15:12;martinitus;image-2024-03-14-16-12-35-267.png;https://issues.apache.org/jira/secure/attachment/13067450/image-2024-03-14-16-12-35-267.png, 14/Mar/24 15:13;martinitus;image-2024-03-14-16-13-03-107.png;https://issues.apache.org/jira/secure/attachment/13067451/image-2024-03-14-16-13-03-107.png, 02/Apr/24 08:32;martinitus;image-2024-04-02-10-32-44-461.png;https://issues.apache.org/jira/secure/attachment/13067796/image-2024-04-02-10-32-44-461.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 3
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Apr 02 08:52:23 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1nz2o:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 28/Mar/24 13:55;pspengler;This behavior is in line with the SQL standard. COUNT(column_name) is different from COUNT(*) (or COUNT(1))  in that in does not count null values. See the different output of
{code:java}
SELECT value, count(value) from test GROUP BY value
{code}
and
{code:java}
SELECT value, count(*) from test GROUP BY value
{code}
A nested distinct clause in COUNT does not change it's behavior - nulls will not be counted.;;;, 02/Apr/24 08:52;martinitus;Hi Phillip, 

thanks for your reply!

I was told that this is inline with the SQL standard by a colleague :) I am not necessarily suggesting to change the behavior.

However, looking at the respective documentation again, the first part

[https://spark.apache.org/docs/latest/sql-ref-null-semantics.html#built-in-aggregate]

explains what you wrote above (except of your extra side note that 'distinct' does not change that). 

The second relevant part of the docs then lures the unaware user (like me) more into a wrong direction. 
[https://spark.apache.org/docs/latest/sql-ref-null-semantics.html#aggregate-operator-group-by-distinct-]

After reading both those parts, I would 100% expect the null to be counted.
Maybe this exact example should be added to the docs? I can prepare a PR for that - If i can figure out where the docs are..;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 02/Apr/24 08:52;martinitus;Hi Phillip, 

thanks for your reply!

I was told that this is inline with the SQL standard by a colleague :) I am not necessarily suggesting to change the behavior.

However, looking at the respective documentation again, the first part

[https://spark.apache.org/docs/latest/sql-ref-null-semantics.html#built-in-aggregate]

explains what you wrote above (except of your extra side note that 'distinct' does not change that). 

The second relevant part of the docs then lures the unaware user (like me) more into a wrong direction. 
[https://spark.apache.org/docs/latest/sql-ref-null-semantics.html#aggregate-operator-group-by-distinct-]

After reading both those parts, I would 100% expect the null to be counted.
Maybe this exact example should be added to the docs? I can prepare a PR for that - If i can figure out where the docs are..;;;

Summary: Streaming Statistics link redirect causing 302 error
Issue key: SPARK-47434
Issue id: 13572173
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: hcampbell
Reporter: hcampbell
Creator: hcampbell
Created: 3/17/24 22:16
Updated: 3/18/24 14:40
Last Viewed: 7/17/24 20:45
Resolved: 3/18/24 14:38
Affects Version/s: 3.4.1, 3.5.1
Fix Version/s: 3.4.3, 3.5.2, 4.0.0
Component/s: Web UI
Due Date: 
Votes: 0
Labels: pull-request-available
Description: When using a reverse proxy, links to streaming statistics page are missing a trailing slash, which causes a redirect (302) to an incorrect path.

Essentially the same issue as https://issues.apache.org/jira/browse/SPARK-24553 but for a different link.

.../StreamingQuery/statistics?id=abcd -> .../StreamingQuery/statistics/?id=abcd

Linked PR [https://github.com/apache/spark/pull/45527/files]
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): SPARK-24553
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Mar 18 14:38:56 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1o0ps:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 18/Mar/24 14:38;dongjoon;Issue resolved by pull request 45527
[https://github.com/apache/spark/pull/45527];;;
Affects Version/s.1: 3.5.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Spark Connect can not be started because of missing user home dir in Docker container
Issue key: SPARK-45557
Issue id: 13554279
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: zrlpar
Creator: zrlpar
Created: 10/16/23 17:21
Updated: 2/20/24 18:46
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.0, 3.4.1, 3.5.0
Fix Version/s: 
Component/s: Spark Docker
Due Date: 
Votes: 0
Labels: 
Description: I was trying to start Spark Connect within a container using the Spark Docker container images and ran into an issue where Ivy could not pull the Spark Connect JAR since the user home /home/spark does not exist.

Steps to reproduce:

1. Start the Spark container with `/bin/bash` as the command:
{code:java}
docker run -it --rm apache/spark:3.5.0 /bin/bash {code}
2. Try to start Spark Connect within the container:

 
{code:java}
/opt/spark/sbin/start-connect-server.sh --packages org.apache.spark:spark-connect_2.12:3.5.0 {code}
which lead to this output:

 

 
{code:java}
starting org.apache.spark.sql.connect.service.SparkConnectServer, logging to /opt/spark/logs/spark--org.apache.spark.sql.connect.service.SparkConnectServer-1-d8470a71dbd7.out
failed to launch: nice -n 0 bash /opt/spark/bin/spark-submit --class org.apache.spark.sql.connect.service.SparkConnectServer --name Spark Connect server --packages org.apache.spark:spark-connect_2.12:3.5.0
  	at org.apache.spark.deploy.SparkSubmitUtils$.resolveMavenCoordinates(SparkSubmit.scala:1535)
  	at org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:185)
  	at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:334)
  	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:964)
  	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)
  	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)
  	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
  	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)
  	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)
  	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
full log in /opt/spark/logs/spark--org.apache.spark.sql.connect.service.SparkConnectServer-1-d8470a71dbd7.out {code}
where then the full log file looks like this:
{code:java}
Spark Command: /opt/java/openjdk/bin/java -cp /opt/spark/conf:/opt/spark/jars/* -Xmx1g -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false org.apache.spark.deploy.SparkSubmit --class org.apache.spark.sql.connect.service.SparkConnectServer --name Spark Connect server --packages org.apache.spark:spark-connect_2.12:3.5.0 spark-internal
========================================
:: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /home/spark/.ivy2/cache
The jars for the packages stored in: /home/spark/.ivy2/jars
org.apache.spark#spark-connect_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-f8a04936-e8af-4f37-bdb0-e4026a8a3be5;1.0
	confs: [default]
Exception in thread "main" java.io.FileNotFoundException: /home/spark/.ivy2/cache/resolved-org.apache.spark-spark-submit-parent-f8a04936-e8af-4f37-bdb0-e4026a8a3be5-1.0.xml (No such file or directory)
	at java.base/java.io.FileOutputStream.open0(Native Method)
	at java.base/java.io.FileOutputStream.open(Unknown Source)
	at java.base/java.io.FileOutputStream.<init>(Unknown Source)
	at java.base/java.io.FileOutputStream.<init>(Unknown Source)
	at org.apache.ivy.plugins.parser.xml.XmlModuleDescriptorWriter.write(XmlModuleDescriptorWriter.java:71)
	at org.apache.ivy.plugins.parser.xml.XmlModuleDescriptorWriter.write(XmlModuleDescriptorWriter.java:63)
	at org.apache.ivy.core.module.descriptor.DefaultModuleDescriptor.toIvyFile(DefaultModuleDescriptor.java:553)
	at org.apache.ivy.core.cache.DefaultResolutionCacheManager.saveResolvedModuleDescriptor(DefaultResolutionCacheManager.java:184)
	at org.apache.ivy.core.resolve.ResolveEngine.resolve(ResolveEngine.java:259)
	at org.apache.ivy.Ivy.resolve(Ivy.java:522)
	at org.apache.spark.deploy.SparkSubmitUtils$.resolveMavenCoordinates(SparkSubmit.scala:1535)
	at org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:185)
	at org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:334)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:964)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala) {code}
 

The issue is that the user home /home/spark directory does not exist.
{code:java}
$ ls -l /home
total 0 
$
{code}
It seems there is an easy fix: simply switching from useradd to adduser in the Dockerfile should get the user home directory created.

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Feb 20 18:46:36 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kz4o:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 20/Feb/24 18:46;albertatcelerdata;Related https://issues.apache.org/jira/browse/SPARK-47105;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: K8s will not allocate more execs if there are any pending execs until next snapshot
Issue key: SPARK-42261
Issue id: 13522285
Parent id: 
Issue Type: Bug
Status: In Progress
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: holden
Creator: holden
Created: 1/31/23 18:51
Updated: 2/3/24 0:18
Last Viewed: 7/17/24 20:39
Resolved: 
Affects Version/s: 3.3.0, 3.3.1, 3.3.2, 3.4.0, 3.4.1, 3.5.0
Fix Version/s: 
Component/s: Kubernetes
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Feb 01 03:42:30 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1fiog:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 4.0.0
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 31/Jan/23 19:00;apachespark;User 'holdenk' has created a pull request for this issue:
https://github.com/apache/spark/pull/39825;;;, 01/Feb/23 03:42;dongjoon;I'm -1 because this is a feature to prevent pending resource (pod and dependent resources like PVCs) explosions which results EKS control plane congestion and a waste of money.;;;
Affects Version/s.1: 3.3.1
Affects Version/s.2: 3.3.2
Affects Version/s.3: 3.4.0
Affects Version/s.4: 3.4.1
Comment.1: 01/Feb/23 03:42;dongjoon;I'm -1 because this is a feature to prevent pending resource (pod and dependent resources like PVCs) explosions which results EKS control plane congestion and a waste of money.;;;

Summary: Reuse `OrcTail` when enable vectorizedReader
Issue key: SPARK-44556
Issue id: 13544948
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: dzcxzl
Reporter: dzcxzl
Creator: dzcxzl
Created: 7/26/23 10:43
Updated: 1/4/24 7:12
Last Viewed: 7/17/24 20:45
Resolved: 1/3/24 22:29
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Jan 03 22:29:13 UTC 2024
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jdyg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 01/Dec/23 09:20;gag.teorver;User 'cxzl25' has created a pull request for this issue:
https://github.com/apache/spark/pull/42168;;;, 03/Jan/24 22:29;dongjoon;Issue resolved by pull request 42168
[https://github.com/apache/spark/pull/42168];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 03/Jan/24 22:29;dongjoon;Issue resolved by pull request 42168
[https://github.com/apache/spark/pull/42168];;;

Summary: Add left-inclusive Param to Bucketizer
Issue key: SPARK-45152
Issue id: 13550515
Parent id: 
Issue Type: New Feature
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: taosiyuan163@163.com
Creator: taosiyuan163@163.com
Created: 9/13/23 11:42
Updated: 12/27/23 0:18
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: ML
Due Date: 
Votes: 0
Labels: pull-request-available
Description: This parameter is used to control the range of values for the bucket.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 42:40.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kbxk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: session_window doesn't identify sessions with provided gap when used as a window function
Issue key: SPARK-46450
Issue id: 13562259
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: jipumarino
Creator: jipumarino
Created: 12/18/23 22:18
Updated: 12/20/23 19:12
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 1
Labels: 
Description: {{PARTITION BY session_window}} doesn't produce the expected results. Here's an example:
{code:sql}
SELECT 
  id,
  ts,
  collect_list(id) OVER (PARTITION BY session_window(ts, '1 hour')) as window_ids

FROM VALUES
  (1, "2023-12-11 01:10"),
  (2, "2023-12-11 01:15"),
  (3, "2023-12-11 01:40"),
  (4, "2023-12-11 02:05"),
  (5, "2023-12-11 03:15"),
  (6, "2023-12-11 03:20"),
  (7, "2023-12-11 04:10"),
  (8, "2023-12-11 05:05")
  AS tab(id, ts)
{code}
Actual result:
{code:java}
+---+----------------+----------+
|id |ts              |window_ids|
+---+----------------+----------+
|1  |2023-12-11 01:10|[1]       |
|2  |2023-12-11 01:15|[2]       |
|3  |2023-12-11 01:40|[3]       |
|4  |2023-12-11 02:05|[4]       |
|5  |2023-12-11 03:15|[5]       |
|6  |2023-12-11 03:20|[6]       |
|7  |2023-12-11 04:10|[7]       |
|8  |2023-12-11 05:05|[8]       |
+---+----------------+----------+
{code}
Expected result, assigning rows to two sessions with 1-hour gap:
{code:java}
+---+----------------+------------+
|id |ts              |window_ids  |
+---+----------------+------------+
|1  |2023-12-11 01:10|[1, 2, 3, 4]|
|2  |2023-12-11 01:15|[1, 2, 3, 4]|
|3  |2023-12-11 01:40|[1, 2, 3, 4]|
|4  |2023-12-11 02:05|[1, 2, 3, 4]|
|5  |2023-12-11 03:15|[5, 6, 7, 8]|
|6  |2023-12-11 03:20|[5, 6, 7, 8]|
|7  |2023-12-11 04:10|[5, 6, 7, 8]|
|8  |2023-12-11 05:05|[5, 6, 7, 8]|
+---+----------------+------------+
{code}
I compared its behavior with the results as a grouping function and with how {{window()}} behaves in both cases, which seems to confirm that the result is inconsistent. Here are the other examples:

*{{group by window()}}*
{code:sql}
SELECT 
  collect_list(id) AS ids,
  collect_list(ts) AS tss,
  window

FROM VALUES
  (1, "2023-12-11 01:10"),
  (2, "2023-12-11 01:15"),
  (3, "2023-12-11 01:40"),
  (4, "2023-12-11 02:05"),
  (5, "2023-12-11 03:15"),
  (6, "2023-12-11 03:20"),
  (7, "2023-12-11 04:10"),
  (8, "2023-12-11 05:05")
  AS tab(id, ts)

GROUP by window(ts, '1 hour')
{code}
Correctly assigns rows to 1-hour windows:
{code:java}
+---------+------------------------------------------------------+------------------------------------------+
|ids      |tss                                                   |window                                    |
+---------+------------------------------------------------------+------------------------------------------+
|[1, 2, 3]|[2023-12-11 01:10, 2023-12-11 01:15, 2023-12-11 01:40]|{2023-12-11 01:00:00, 2023-12-11 02:00:00}|
|[4]      |[2023-12-11 02:05]                                    |{2023-12-11 02:00:00, 2023-12-11 03:00:00}|
|[5, 6]   |[2023-12-11 03:15, 2023-12-11 03:20]                  |{2023-12-11 03:00:00, 2023-12-11 04:00:00}|
|[7]      |[2023-12-11 04:10]                                    |{2023-12-11 04:00:00, 2023-12-11 05:00:00}|
|[8]      |[2023-12-11 05:05]                                    |{2023-12-11 05:00:00, 2023-12-11 06:00:00}|
+---------+------------------------------------------------------+------------------------------------------+
{code}
 

*{{group by session_window()}}*
{code:sql}
SELECT 
  collect_list(id) AS ids,
  collect_list(ts) AS tss,
  session_window

FROM VALUES
  (1, "2023-12-11 01:10"),
  (2, "2023-12-11 01:15"),
  (3, "2023-12-11 01:40"),
  (4, "2023-12-11 02:05"),
  (5, "2023-12-11 03:15"),
  (6, "2023-12-11 03:20"),
  (7, "2023-12-11 04:10"),
  (8, "2023-12-11 05:05")
  AS tab(id, ts)

GROUP by session_window(ts, '1 hour')
{code}
Correctly assigns rows to two sessions with 1-hour gap:
{code:java}
+------------+------------------------------------------------------------------------+------------------------------------------+
|ids         |tss                                                                     |session_window                            |
+------------+------------------------------------------------------------------------+------------------------------------------+
|[1, 2, 3, 4]|[2023-12-11 01:10, 2023-12-11 01:15, 2023-12-11 01:40, 2023-12-11 02:05]|{2023-12-11 01:10:00, 2023-12-11 03:05:00}|
|[5, 6, 7, 8]|[2023-12-11 03:15, 2023-12-11 03:20, 2023-12-11 04:10, 2023-12-11 05:05]|{2023-12-11 03:15:00, 2023-12-11 06:05:00}|
+------------+------------------------------------------------------------------------+------------------------------------------+
{code}
 

*{{partition by window()}}*
{code:sql}
SELECT 
  id,
  ts,
  collect_list(id) OVER (PARTITION BY window(ts, '1 hour')) as window_ids

FROM VALUES
  (1, "2023-12-11 01:10"),
  (2, "2023-12-11 01:15"),
  (3, "2023-12-11 01:40"),
  (4, "2023-12-11 02:05"),
  (5, "2023-12-11 03:15"),
  (6, "2023-12-11 03:20"),
  (7, "2023-12-11 04:10"),
  (8, "2023-12-11 05:05")
  AS tab(id, ts)
{code}
Correctly assigns rows to 1-hour windows:
{code:java}
+---+----------------+----------+
|id |ts              |window_ids|
+---+----------------+----------+
|1  |2023-12-11 01:10|[1, 2, 3] |
|2  |2023-12-11 01:15|[1, 2, 3] |
|3  |2023-12-11 01:40|[1, 2, 3] |
|4  |2023-12-11 02:05|[4]       |
|5  |2023-12-11 03:15|[5, 6]    |
|6  |2023-12-11 03:20|[5, 6]    |
|7  |2023-12-11 04:10|[7]       |
|8  |2023-12-11 05:05|[8]       |
+---+----------------+----------+
{code}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Dec 20 19:12:22 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1mc0w:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 18/Dec/23 23:37;kabhwan;It's a missing one and maybe we will have to document - session window is only working properly with batch/streaming aggregation. (Because it requires custom logic to merge sessions.) If you use it as normal function and not ingesting the value to aggregation, merging sessions is never triggered.;;;, 20/Dec/23 19:12;jipumarino;[~kabhwan] thanks for the explanation; I learned a bit more about how Spark internals work.;;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 20/Dec/23 19:12;jipumarino;[~kabhwan] thanks for the explanation; I learned a bit more about how Spark internals work.;;;

Summary: ArrowConverters.createEmptyArrowBatch may cause memory leak
Issue key: SPARK-45814
Issue id: 13556967
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: xieshuaihu
Reporter: xieshuaihu
Creator: xieshuaihu
Created: 11/7/23 1:43
Updated: 12/20/23 10:03
Last Viewed: 7/17/24 20:45
Resolved: 11/10/23 4:33
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 3.4.2, 3.5.1, 4.0.0
Component/s: Connect, SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: ArrowConverters.createEmptyArrowBatch don't call hasNext, if TaskContext.get is None, then memory leak happens
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Nov 10 04:33:46 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lfpk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 09/Nov/23 08:00;LuciferYang;Resolved by https://github.com/apache/spark/pull/43691;;;, 10/Nov/23 04:33;LuciferYang;Issue resolved by pull request 43728
[https://github.com/apache/spark/pull/43728];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 10/Nov/23 04:33;LuciferYang;Issue resolved by pull request 43728
[https://github.com/apache/spark/pull/43728];;;

Summary: No need to retry parsing event log path again when FileNotFoundException occurs
Issue key: SPARK-44998
Issue id: 13548905
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: wforget
Creator: wforget
Created: 8/29/23 2:46
Updated: 12/10/23 0:20
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: I found a lot of retry parsing inprogress event log records in history server log. The application is already done while parsing, so we don't need to retry parsing it again when FileNotFoundException occurs.

 

!image-2023-08-29-10-47-08-027.png!

!image-2023-08-29-10-47-43-567.png!
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 29/Aug/23 02:47;wforget;image-2023-08-29-10-47-08-027.png;https://issues.apache.org/jira/secure/attachment/13062535/image-2023-08-29-10-47-08-027.png, 29/Aug/23 02:47;wforget;image-2023-08-29-10-47-43-567.png;https://issues.apache.org/jira/secure/attachment/13062536/image-2023-08-29-10-47-43-567.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 2
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 46:16.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k200:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: If Hadoop is not installed and configured, can the Spark cluster read and write OBS in standalone mode?
Issue key: SPARK-46314
Issue id: 13561075
Parent id: 
Issue Type: IT Help
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: xueice
Creator: xueice
Created: 12/8/23 1:40
Updated: 12/8/23 1:49
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Connect, Input/Output, PySpark
Due Date: 
Votes: 0
Labels: 
Description: If Hadoop is not deployed, PySpark APIs read data from OBS buckets and convert the data to RDD. How can I achieve it?

The following code reports an error: No FileSystem for scheme "obs",Can Spark read and write OBS without Hadoop installation and configuration?

And I'm not familiar with pyspark. Is the code wrong?
{code:java}
// code placeholder
from pyspark import SparkConf
from pyspark.sql import SparkSession

conf = SparkConf()
conf.set("spark.app.name", "read and write OBS")
conf.set("spark.security.credentials.hbase.enabled", "true")
conf.set("spark.hadoop.fs.obs.access.key", ak)
conf.set("spark.hadoop.fs.obs.secret.key", sk)
conf.set("spark.hadoop.fs.obs.endpoint", "http://xxx")
spark = SparkSession.builder.config(conf=conf).getOrCreate()

df = spark.read.json('obs://bucket_name/xxx.json')
df.coalesce(2).write.json("obs://bucket_name/", "overwrite") {code}
Environment: Python3.8

pyspark 3.4.1

operating system:Ubuntu 20.04
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): Python
Custom field (Last public comment date): 40:06.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1m4q0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Align streaming statistics link format with other page links
Issue key: SPARK-44864
Issue id: 13547826
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: xleesf
Creator: xleesf
Created: 8/18/23 6:04
Updated: 12/1/23 0:21
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Structured Streaming
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Align the streaming query statistics link format with other link like Stages Page `/stages/stage/?id=xxx` , SQL Page `SQL/execution/?id`

`
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Aug 21 03:21:52 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jvcg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 21/Aug/23 03:21;snoot;User 'leesf' has created a pull request for this issue:
https://github.com/apache/spark/pull/42553;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Support memory limit configurable
Issue key: SPARK-44758
Issue id: 13546802
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: zhuml
Creator: zhuml
Created: 8/10/23 9:20
Updated: 11/21/23 0:19
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Kubernetes
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Currently the memory request and limit are set by summing the values of spark.\{driver,executor}.memory and spark.\{driver,executor}.memoryOverhead. Supporting memory limits configurable can bring some benefits. For example, use unfixed memory to use page cache, reduce disk IO of shuffle read to improve performance.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 20:42.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jpe0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Cleanup shuffle files from host node after migration due to graceful decommissioning
Issue key: SPARK-44704
Issue id: 13546358
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: deependra
Creator: deependra
Created: 8/7/23 12:24
Updated: 11/18/23 0:18
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Block Manager
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Although these files will be deleted at the end of the application by the external shuffle service, doing this early can free up resources and can help in long running applications running out of disk space.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Aug 07 12:24:59 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jmnc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 3.4.2
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 07/Aug/23 12:24;deependra;I will create for this soon.;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Fix RST files link substitutions error
Issue key: SPARK-45935
Issue id: 13558057
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: panbingkun
Reporter: panbingkun
Creator: panbingkun
Created: 11/15/23 10:38
Updated: 11/16/23 9:02
Last Viewed: 7/17/24 20:45
Resolved: 11/16/23 9:02
Affects Version/s: 3.3.3, 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.3.4, 3.4.2, 3.5.1, 4.0.0
Component/s: Documentation, PySpark
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Nov 16 09:02:06 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lmfk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 16/Nov/23 09:02;gurwls223;Issue resolved by pull request 43815
[https://github.com/apache/spark/pull/43815];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 4.0.0
Affects Version/s.4: 
Comment.1:

Summary: The obtainDelegationTokens method of HiveDelegationTokenProvider should return nextRenewalDate instead of None
Issue key: SPARK-44203
Issue id: 13541494
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: jiaoqb
Creator: jiaoqb
Created: 6/27/23 2:57
Updated: 11/14/23 0:18
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 57:56.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1isq8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: ObjectSerializerPruning fails to align null types in custom serializer 'If' expressions.
Issue key: SPARK-45766
Issue id: 13556456
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: piotrszul
Creator: piotrszul
Created: 11/1/23 23:58
Updated: 11/1/23 23:59
Last Viewed: 7/17/24 20:41
Resolved: 
Affects Version/s: 3.3.3, 3.4.1, 3.5.0
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: We have a custom encoder for union like objects. 

The our custom serializer uses an expression like:

{{If(IsNull(If(.....)), Literal(null), NamedStruct(....)))}}

Using this encoder in a SQL expression that applies the 

`org.apache.spark.sql.catalyst.optimizer.ObjectSerializerPruning`  rule  results in the exception below.

It's because the expression it transformed by `PushFoldableIntoBranches' rule prior to `ObjectSerializerPruning`, which changes the expression to:

{{If(If(.....), Literal(null), NamedStruct(....)))}}

which no longer matches the expressions for which null type alignment is performed.

See the attached scala repl code for the demonstration of this issue.

 

The exception:

 

java.lang.IllegalArgumentException: requirement failed: All input types must be the same except nullable, containsNull, valueContainsNull flags. The expression is: if (if (assertnotnull(input[0, UnionType, true]).hasValue) isnull(assertnotnull(input[0, UnionType, true]).value) else true) null else named_struct(given, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(knownnotnull(assertnotnull(input[0, UnionType, true])).value).given, true, false, true)). The input types found are

StructType(StructField(given,StringType,true),StructField(family,StringType,true))

StructType(StructField(given,StringType,true)).

  at scala.Predef$.require(Predef.scala:281)

  at org.apache.spark.sql.catalyst.expressions.ComplexTypeMergingExpression.dataTypeCheck(Expression.scala:1304)

  at org.apache.spark.sql.catalyst.expressions.ComplexTypeMergingExpression.dataTypeCheck$(Expression.scala:1297)

  at org.apache.spark.sql.catalyst.expressions.If.dataTypeCheck(conditionalExpressions.scala:41)

  at org.apache.spark.sql.catalyst.expressions.ComplexTypeMergingExpression.org$apache$spark$sql$catalyst$expressions$ComplexTypeMergingExpression$$internalDataType(Expression.scala:1309)

  at org.apache.spark.sql.catalyst.expressions.ComplexTypeMergingExpression.org$apache$spark$sql$catalyst$expressions$ComplexTypeMergingExpression$$internalDataType$(Expression.scala:1308)

  at org.apache.spark.sql.catalyst.expressions.If.org$apache$spark$sql$catalyst$expressions$ComplexTypeMergingExpression$$internalDataType$lzycompute(conditionalExpressions.scala:41)

  at org.apache.spark.sql.catalyst.expressions.If.org$apache$spark$sql$catalyst$expressions$ComplexTypeMergingExpression$$internalDataType(conditionalExpressions.scala:41)

  at org.apache.spark.sql.catalyst.expressions.ComplexTypeMergingExpression.dataType(Expression.scala:1313)

  at org.apache.spark.sql.catalyst.expressions.ComplexTypeMergingExpression.dataType$(Expression.scala:1313)

  at org.apache.spark.sql.catalyst.expressions.If.dataType(conditionalExpressions.scala:41)

  at org.apache.spark.sql.catalyst.expressions.Alias.dataType(namedExpressions.scala:166)

  at org.apache.spark.sql.catalyst.optimizer.ObjectSerializerPruning$.pruneSerializer(objects.scala:209)

  at org.apache.spark.sql.catalyst.optimizer.ObjectSerializerPruning$$anonfun$apply$8.$anonfun$applyOrElse$3(objects.scala:230)

  at scala.collection.immutable.List.map(List.scala:293)

  at org.apache.spark.sql.catalyst.optimizer.ObjectSerializerPruning$$anonfun$apply$8.applyOrElse(objects.scala:229)

  at org.apache.spark.sql.catalyst.optimizer.ObjectSerializerPruning$$anonfun$apply$8.applyOrElse(objects.scala:217)

  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)

  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)

  at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)

  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)

  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)

  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)

  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)

  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)

  at org.apache.spark.sql.catalyst.trees.TreeNode.transformWithPruning(TreeNode.scala:427)

  at org.apache.spark.sql.catalyst.optimizer.ObjectSerializerPruning$.apply(objects.scala:217)

  at org.apache.spark.sql.catalyst.optimizer.ObjectSerializerPruning$.apply(objects.scala:125)

  at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 01/Nov/23 23:58;piotrszul;prunning_bug.scala;https://issues.apache.org/jira/secure/attachment/13064092/prunning_bug.scala
Custom field (Affects version (Component)): 
Custom field (Attachment count): 1
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 58:10.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lck8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Custom metrics should be updated after commit too
Issue key: SPARK-45759
Issue id: 13556387
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: ali-ince
Creator: ali-ince
Created: 11/1/23 12:57
Updated: 11/1/23 13:01
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 2
Labels: 
Description: We have a DataWriter component, which processes records in configurable batches, which are accumulated in {{write(T record)}} implementation and sent to the persistent store when the configured batch size is reached. Within this approach, last batch is handled during {{commit()}} call, as there is no other mechanism of knowing if there are more records or not.

We are now adding support for custom metrics, by implementing the {{supportedCustomMetrics()}} and {{currentMetricsValues()}} in the {{Write}} and {{DataWriter}} implementations. The problem we see is, since {{CustomMetrics.updateMetrics}} is only called [during|https://github.com/apache/spark/blob/af8907a0873f5ca192b150f28a0c112107594722/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/v2/WriteToDataSourceV2Exec.scala#L443-L443] and [just after|https://github.com/apache/spark/blob/af8907a0873f5ca192b150f28a0c112107594722/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/v2/WriteToDataSourceV2Exec.scala#L451-L451] record processing, we do not observe the complete metrics since the last batch that is handled during {{commit()}} call is not collected/updated.

We propose to also to add {{CustomMetrics.updateMetrics}} call after {{commit()}} is processed successfully, ideally just before {{run}} function exits (maybe just above [https://github.com/apache/spark/blob/af8907a0873f5ca192b150f28a0c112107594722/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/v2/WriteToDataSourceV2Exec.scala#L473-L473]).
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 57:26.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1lc4w:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Scala-specific improvements in Dataset[T] API 
Issue key: SPARK-45170
Issue id: 13550709
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: salamahin
Creator: salamahin
Created: 9/14/23 15:13
Updated: 10/28/23 16:00
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: SPIP
Description: *Q1.* What are you trying to do? 

The main idea is to use the power of scala's macrosses to give developers more convenient and typesafe API to use in join conditions. 

 

*Q2.* What problem is this proposal NOT designed to solve?

R/Java/Python/DataFrame API is out of scope. The solution is not affecting plan generation too. 

 

*Q3.* How is it done today, and what are the limits of current practice?

Currently the join condition is specified via strings, which might lead to silly mistakes (typos, incompatible column types etc) and sometimes hard to read (in case when several joins are made and the final type is tuple of tuple of tuples...)

 

*Q4.* What is new in your approach and why do you think it will be successful?

Scala macroses can be used to extract the column name directly from lambda (extractor). As a side effect its possible to check the column type and prohibit to build inconsistent join expression (like boolean-timestamp comparison)

 

*Q5.* Who cares? If you are successful, what difference will it make?

Mainly scala developers who prefers typesafe code - they would have a more clean and nice API that will make the codebase a bit clearer, especially in case when several chained joins is used

 

*Q6.* What are the risks?

The overusage of macrosses may slow down the compilation speed. In additional macrosses are hard to maintain

 

*Q7.* How long will it take?

Currently the approach is already implemented as a separate [lib|https://github.com/Salamahin/joinwiz] that makes a bit more than just gives alternative API (for example abstracts Dataset[T] to F[T] which allows to run some spark-specific code without spark session for testing purposes)

Adaptation of it won't be a hard job, matter of several weeks

 

*Q8.* What are the mid-term and final “exams” to check for success?

API convenience is very hard to estimate as its more or less a question of taste

 

*Appendix A*

You may find the examples of such 'cleaner' API [here|https://github.com/Salamahin/joinwiz/blob/master/joinwiz_core/src/test/scala/joinwiz/ComputationEngineTest.scala]

Note that backward and forward compatibility is achieved by introducing a brand-new API without modifying an old one

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): Scala
Custom field (Last public comment date): Sat Oct 28 16:00:02 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kd4o:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 28/Oct/23 15:37;psun520;What is the difference between this and the [https://typelevel.org/frameless/FeatureOverview.html] ?;;;, 28/Oct/23 16:00;salamahin;Good question!

The proposed solution have a better integration with IDEs (symbols can't be suggested via intellisense or similar), which might be helpful when doing a chain of a complex joins. In addition, joinwiz allows speed up a unit-testing of spark-specific code because in some cases one doesn't need to initiate a spark session;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 28/Oct/23 16:00;salamahin;Good question!

The proposed solution have a better integration with IDEs (symbols can't be suggested via intellisense or similar), which might be helpful when doing a chain of a complex joins. In addition, joinwiz allows speed up a unit-testing of spark-specific code because in some cases one doesn't need to initiate a spark session;;;

Summary: Cover BufferReleasingInputStream.available under tryOrFetchFailedException
Issue key: SPARK-45678
Issue id: 13555735
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: viirya
Reporter: viirya
Creator: viirya
Created: 10/26/23 21:00
Updated: 10/28/23 4:15
Last Viewed: 7/17/24 20:45
Resolved: 10/28/23 2:21
Affects Version/s: 3.4.1, 3.5.0, 4.0.0
Fix Version/s: 3.4.2, 3.5.1, 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: pull-request-available
Description: We have encountered shuffle data corruption issue:

```
Caused by: java.io.IOException: FAILED_TO_UNCOMPRESS(5)
	at org.xerial.snappy.SnappyNative.throw_error(SnappyNative.java:112)
	at org.xerial.snappy.SnappyNative.rawUncompress(Native Method)
	at org.xerial.snappy.Snappy.rawUncompress(Snappy.java:504)
	at org.xerial.snappy.Snappy.uncompress(Snappy.java:543)
	at org.xerial.snappy.SnappyInputStream.hasNextChunk(SnappyInputStream.java:450)
	at org.xerial.snappy.SnappyInputStream.available(SnappyInputStream.java:497)
	at org.apache.spark.storage.BufferReleasingInputStream.available(ShuffleBlockFetcherIterator.scala:1356)
 ```

Spark shuffle has capacity to detect corruption for a few stream op like `read` and `skip`, such `IOException` in the stack trace will be rethrown as `FetchFailedException` that will re-try the failed shuffle task. But in the stack trace it is `available` that is not covered by the mechanism. So no-retry has been happened and the Spark application just failed.

As the `available` op will also involve data decompression, we should be able to check it like `read` and `skip` do.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sat Oct 28 02:21:18 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1l840:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 28/Oct/23 02:21;csun;Issue resolved by pull request 43543
[https://github.com/apache/spark/pull/43543];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 4.0.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Improve error message for ALTER TABLE ALTER COLUMN on partition columns in non-delta tables
Issue key: SPARK-44837
Issue id: 13547634
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: m.zhang
Reporter: m.zhang
Creator: m.zhang
Created: 8/16/23 22:18
Updated: 10/20/23 5:56
Last Viewed: 7/17/24 20:45
Resolved: 10/20/23 5:56
Affects Version/s: 3.0.3, 3.1.3, 3.2.4, 3.3.2, 3.4.1, 4.0.0
Fix Version/s: 4.0.0
Component/s: SQL
Due Date: 
Votes: 1
Labels: pull-request-available
Description:  
{code:java}
-- hive table
sql("create table some_table (x int, y int, z int) using parquet PARTITIONED BY (x, y) " +
"location '/Users/someone/runtime/tmp-data/some_table'")
sql("alter table some_table alter column x comment 'some-comment'").collect()
Can't find column `x` given table data columns [`z`].{code}
Improve error message to indicate to users that the command is not supported on partition columns in non-delta tables.

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Oct 20 05:56:04 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ju5s:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 20/Oct/23 05:56;maxgekk;Issue resolved by pull request 42524
[https://github.com/apache/spark/pull/42524];;;
Affects Version/s.1: 3.1.3
Affects Version/s.2: 3.2.4
Affects Version/s.3: 3.3.2
Affects Version/s.4: 3.4.1
Comment.1:

Summary: cleanSource problem on FileStreamSource for Windows env
Issue key: SPARK-45519
Issue id: 13553867
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: yemregurses
Creator: yemregurses
Created: 10/12/23 12:52
Updated: 10/12/23 12:52
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Structured Streaming
Due Date: 
Votes: 0
Labels: 
Description: We are using Spark with Scala in Windows environment. While streaming using Spark, I give the *{{cleanSource}}* option as "archive" and the *{{sourceArchiveDir}}* option as "archived" as in the code below.
{code:java}
spark.readStream
  .option("cleanSource", "archive")
  .option("sourceArchiveDir", "archived"){code}
When I tried this in a Linux environment, I realized that the problem was with the paths. Because when I set archive mode to "delete", it works on both Linux and Windows. But for the archive mode, it does not work on Windows. 

The problem is related to appending paths in Windows. There is a method

 
{code:java}
override protected def cleanTask(entry: FileEntry): Unit{code}
in the FileStreamSource.scala file in the org.apache.spark.sql.execution.streaming package. On line 569, the !fileSystem.rename(curPath, newPath) code supposed to move source file to archive folder. However, when I debugged, I noticed that the curPath and newPath values were as follows in windows:

 
{code:java}
curPath: file:/C:/dev/be/data-integration-suite/test-data/streaming-folder/patients/patients-success.csv{code}
{code:java}
newPath: file:/C:/dev/be/data-integration-suite/archived/C:/dev/be/data-integration-suite/test-data/streaming-folder/patients/patients-success.csv{code}
It seems that absolute path of csv file were appended when creating newPath because there are two *C:/dev/be/data-integration-suite* in the newPath. This is the reason probably spark archiving does not work. Instead, newPath should be: file:/C:/dev/be/data-integration-suite/archived/test-data/streaming-folder/patients/patients-success.csv
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 52:16.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kwl4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Incorrect error message for RoundBase
Issue key: SPARK-45473
Issue id: 13553442
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: viirya
Reporter: viirya
Creator: viirya
Created: 10/9/23 22:16
Updated: 10/11/23 2:51
Last Viewed: 7/17/24 20:45
Resolved: 10/11/23 2:50
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 3.4.2, 3.5.1, 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Oct 11 02:50:31 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ktyo:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 11/Oct/23 02:50;dongjoon;Issue resolved by pull request 43316
[https://github.com/apache/spark/pull/43316];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: download krb5.conf from remote storage in spark-submit on k8s
Issue key: SPARK-45175
Issue id: 13550778
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: dcoliversun
Creator: dcoliversun
Created: 9/15/23 3:17
Updated: 9/22/23 16:57
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Kubernetes
Due Date: 
Votes: 0
Labels: pull-request-available
Description: krb5.conf currently only supports the local file format. Tenants would like to save this file on their own servers and download it during the spark-submit phase for better implementation of multi-tenant scenarios. The proposed solution is to use the *downloadFile*  function[1], similar to the configuration of *spark.kubernetes.driver/executor.podTemplateFile*

 

[1]https://github.com/apache/spark/blob/822f58f0d26b7d760469151a65eaf9ee863a07a1/resource-managers/kubernetes/core/src/main/scala/org/apache/spark/deploy/k8s/features/PodTemplateConfigMapStep.scala#L82C24-L82C24
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Sep 22 08:59:30 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kdk0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 22/Sep/23 08:59;dcoliversun;In multi-tenant scenarios, I find Apache Spark provide *{{spark.kubernetes.kerberos.krb5.configMapName}}* to mount ConfigMap containing the {{*krb5.conf*}} file, we could manage these files by creating multiple configMaps for multi-tenants.;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Non-nullable schema is not effective in DF from JSON
Issue key: SPARK-45254
Issue id: 13551536
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: michele_rastelli
Creator: michele_rastelli
Created: 9/21/23 13:41
Updated: 9/21/23 13:41
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.3.3, 3.4.1
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: In Spark 3.3 and 3.4, when creating a DF with schema with non-nullable fields, the created DF ends up having schema with nullable fields.

 

 
{code:java}
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.types.{BooleanType, StructField, StructType}
object Foo extends App {
  val spark: SparkSession = SparkSession.builder()
    .appName("foo")
    .master("local[*]")
    .config("spark.driver.host", "127.0.0.1")
    .getOrCreate()
  val schema = StructType(Array(StructField("a", BooleanType, nullable = false)))
  import spark.implicits._
  val df = spark.read.schema(schema).json(Seq(
    """{"a":null}""",
    """{"a":true}""",
    """{"a":false}""",
  ).toDS)
  df.collect()
    .map(_.toString())
    .foreach(println(_))
  schema.printTreeString()
  df.schema.printTreeString()
}
 
{code}
 

 

Produces:

 
{code:java}
[null]
[true]
[false]
root
 |-- a: boolean (nullable = false)
root
 |-- a: boolean (nullable = true)
{code}
 

 

 

 

 

 

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 41:58.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ki8g:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: SortMergeExec with Outer using join forgets sort information
Issue key: SPARK-45099
Issue id: 13549919
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: hcampbell
Creator: hcampbell
Created: 9/7/23 11:18
Updated: 9/7/23 11:22
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: When performing a 'using' join with a sort hint in a full outer, the ResolveNaturalAndUsingJoin will kick in and build a new join with Equality conditions and a Projection like this:
{quote}val joinedCols = joinPairs.map \{ case (l, r) => Alias(Coalesce(Seq(l, r)), l.name)() }
{quote}
There's nothing wrong with this per se, but, SortMergeJoinExec has it's output ordering for a full outer join as empty, even though these join pairs in their final coalesced form actually are ordered.

This means that code like this:
{quote}frames.reduceLeft(case (l, r) => l.join(r.hint("merge"), usingColumns = Seq("a", "b"), joinType = "outer"))
{quote}
Given a non empty list of frames, will not 'stream' without a shuffle step, as each join forgets its sort order.

Ideally this whole operation wouldn't require any shuffles if all the frames are grouped and sorted by the keys.

(Forgive the parens instead of brackets the code snippet please, Jira was inferring macros)
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 18:25.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k89c:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Cache results of simple udfs on executors if same arguments are passed.
Issue key: SPARK-44979
Issue id: 13548750
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: dineshdharme
Creator: dineshdharme
Created: 8/27/23 13:02
Updated: 8/29/23 14:01
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: Consider two dataframes :

{{keyword_given = [
["green pstr",],
["greenpstr",],
["wlmrt", ],
["walmart",],
["walmart super",]
]}}

{{variations = [
("type green pstr", "ABC", 100),
("type green pstr","PQR",200),
("type green pstr", "NZSD", 2999),
("wlmrt payment","walmart",200),
("wlmrt solutions", "walmart", 200),
("nppssdwlmrt", "walmart", 2000)
]}}

{{Imagine I have a task to do fuzzy substring matching between keyword and variation[0] using in built levenstein function. It is possible to optimize this futher in the code itself where we extract out the uniques and then do fuzzy matching on the uniques and join back with the original tables. }}

{{But it could be possible as an optimization to cache the results of the already computed udfs till now and do a lookup on each executor separately.}}

Just a thought. Not sure if it makes any sense. This behaviour could be behind a config.

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 02:30.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k11k:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): _deepakgoyal
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Show task partition id in Task table
Issue key: SPARK-44497
Issue id: 13544264
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: dzcxzl
Reporter: dzcxzl
Creator: dzcxzl
Created: 7/20/23 9:15
Updated: 8/27/23 5:29
Last Viewed: 7/17/24 20:45
Resolved: 8/27/23 5:29
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: Web UI
Due Date: 
Votes: 0
Labels: 
Description: In SPARK-37831, the partition id is added in taskinfo, and the task partition id cannot be directly seen in the ui.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sun Aug 27 05:29:21 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j9qo:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 20/Jul/23 09:21;githubbot;User 'cxzl25' has created a pull request for this issue:
https://github.com/apache/spark/pull/42093;;;, 27/Aug/23 05:29;Qin Yao;Issue resolved by pull request 42093
[https://github.com/apache/spark/pull/42093];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 27/Aug/23 05:29;Qin Yao;Issue resolved by pull request 42093
[https://github.com/apache/spark/pull/42093];;;

Summary: PushdownPredicatesAndPruneColumnsForCTEDef creates invalid plan when called over CTE with duplicate attributes
Issue key: SPARK-44934
Issue id: 13548434
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: wenyuen-db
Reporter: wenyuen-db
Creator: wenyuen-db
Created: 8/23/23 20:47
Updated: 8/24/23 17:57
Last Viewed: 7/17/24 20:45
Resolved: 8/24/23 15:06
Affects Version/s: 3.3.3, 3.4.1
Fix Version/s: 3.5.0, 4.0.0
Component/s: Optimizer
Due Date: 
Votes: 0
Labels: 
Description: When running the query
{code:java}
with cte as (
 select c1, c1, c2, c3 from t where random() > 0
)
select cte.c1, cte2.c1, cte.c2, cte2.c3 from
 (select c1, c2 from cte) cte
 inner join
 (select c1, c3 from cte) cte2
 on cte.c1 = cte2.c1 {code}
 
The query fails with the error
{code:java}
org.apache.spark.scheduler.DAGScheduler: Failed to update accumulator 9523 (Unknown class) for task 1
org.apache.spark.SparkException: attempted to access non-existent accumulator 9523{code}
Further investigation shows that the rule PushdownPredicatesAndPruneColumnsForCTEDef creates an invalid plan when the output of a CTE contains duplicate expression IDs.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Aug 24 15:06:56 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jz3c:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 24/Aug/23 15:06;ptoth;Issue resolved by pull request 42635
[https://github.com/apache/spark/pull/42635];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Fix incorrect property name `asyncProgressCheckpointingInterval` in structured streaming doc
Issue key: SPARK-44859
Issue id: 13547792
Parent id: 
Issue Type: Documentation
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: viirya
Reporter: viirya
Creator: viirya
Created: 8/17/23 22:21
Updated: 8/17/23 22:52
Last Viewed: 7/17/24 20:45
Resolved: 8/17/23 22:52
Affects Version/s: 3.4.1
Fix Version/s: 3.4.2, 3.5.0, 4.0.0
Component/s: Structured Streaming
Due Date: 
Votes: 0
Labels: 
Description: We found that one structured streaming property `asyncProgressCheckpointingInterval` for asynchronous progress tracking is not correct when comparing with codebase.


Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Aug 17 22:52:52 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jv4w:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 17/Aug/23 22:52;dongjoon;Issue resolved by pull request 42544
[https://github.com/apache/spark/pull/42544];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Log when the K8s Exec Pods Allocator Stalls
Issue key: SPARK-42260
Issue id: 13522284
Parent id: 
Issue Type: Improvement
Status: In Progress
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: holden
Reporter: holden
Creator: holden
Created: 1/31/23 18:34
Updated: 8/9/23 19:15
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.0, 3.4.1
Fix Version/s: 
Component/s: Kubernetes
Due Date: 
Votes: 0
Labels: 
Description: Sometimes if the K8s APIs are being slow the ExecutorPods allocator can stall and it would be good for us to log this (and how long we've stalled for) so folks can tell more clearly why Spark is unable to reach the desired target number of executors.

 

This is _somewhat_ related to SPARK-36664 which logs the time spent waiting for executor allocation but goes a step further for K8s and logs when we've stalled because we have too many pending pods.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Jun 27 10:05:09 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1fio8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 4.0.0
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 31/Jan/23 19:01;apachespark;User 'holdenk' has created a pull request for this issue:
https://github.com/apache/spark/pull/39825;;;, 27/Jun/23 10:05;yumwang;Remove the target version since 3.4.1 is released.;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 27/Jun/23 10:05;yumwang;Remove the target version since 3.4.1 is released.;;;

Summary: ShutdownHookManager get wrong hadoop user group information
Issue key: SPARK-44581
Issue id: 13545256
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: ylllllllll
Reporter: ylllllllll
Creator: ylllllllll
Created: 7/28/23 9:18
Updated: 8/9/23 5:58
Last Viewed: 7/17/24 20:45
Resolved: 8/9/23 5:58
Affects Version/s: 3.2.1, 3.3.2, 3.4.1
Fix Version/s: 3.3.4, 3.4.2, 3.5.0
Component/s: Deploy, YARN
Due Date: 
Votes: 1
Labels: 
Description:  I use spark 3.2.1 to run a job on yarn in cluster mode. 

when the job is finished, there is an exception that:
{code:java}
2023-07-28 10:57:16,324 ERROR yarn.ApplicationMaster: Failed to cleanup staging dir hdfs://dmp/user/ubd_dmp_test/.sparkStaging/application_1689318995305_0290 org.apache.hadoop.security.AccessControlException: Permission denied: user=yarn, access=WRITE, inode="/user/ubd_dmp_test/.sparkStaging":ubd_dmp_test:ubd_dmp_test:drwxr-xr-x at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:506) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:349) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermissionWithContext(FSPermissionChecker.java:370) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:240) at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1943) at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:105) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3266) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1128) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:725) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121) at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88) at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1656) at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:991) at org.apache.hadoop.hdfs.DistributedFileSystem$19.doCall(DistributedFileSystem.java:988) at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) at org.apache.hadoop.hdfs.DistributedFileSystem.delete(DistributedFileSystem.java:998) at org.apache.spark.deploy.yarn.ApplicationMaster.cleanupStagingDir(ApplicationMaster.scala:686) at org.apache.spark.deploy.yarn.ApplicationMaster.$anonfun$run$3(ApplicationMaster.scala:268) at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214) at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188) at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2019) at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188) at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) at scala.util.Try$.apply(Try.scala:213) at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188) at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=yarn, access=WRITE, inode="/user/ubd_dmp_test/.sparkStaging":ubd_dmp_test:ubd_dmp_test:drwxr-xr-x at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:506) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:349) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermissionWithContext(FSPermissionChecker.java:370) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:240) at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1943) at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:105) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3266) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1128) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:725) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1573) at org.apache.hadoop.ipc.Client.call(Client.java:1519) at org.apache.hadoop.ipc.Client.call(Client.java:1416) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129) at com.sun.proxy.$Proxy15.delete(Unknown Source) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.delete(ClientNamenodeProtocolTranslatorPB.java:655) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422) at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165) at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157) at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95) at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359) at com.sun.proxy.$Proxy16.delete(Unknown Source) at org.apache.hadoop.hdfs.DFSClient.delete(DFSClient.java:1654) ... 20 more
 
  {code}
I used user ubd_dmp_test to run the job, but the program used user yarn to delete the staging file, this never happens before when I use spark2.4.

 

So I print some log about the current user when it tries to delete the staging file, turns out to be user yarn. Then I print the log about the current user when it execute the run method of ApplicationMaster object, turns out to be ubd_dmp_test.

 

I'm really confused about how this happened.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Aug 09 05:58:39 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jfuo:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 02/Aug/23 10:22;ylllllllll;I found that the ShutDownHook Manager will start a new Thread when the JVM exists, so the UserGroupInformation will not be inherited from the SparkContext, then this hook will create a new ugi with user "yarn", which caused the exception.;;;, 03/Aug/23 09:16;githubbot;User 'liangyu-1' has created a pull request for this issue:
https://github.com/apache/spark/pull/42295;;;, 09/Aug/23 05:58;yao;Issue resolved by  [https://github.com/apache/spark/pull/42295];;;
Affects Version/s.1: 3.3.2
Affects Version/s.2: 3.4.1
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 03/Aug/23 09:16;githubbot;User 'liangyu-1' has created a pull request for this issue:
https://github.com/apache/spark/pull/42295;;;

Summary: INSET hash hset set to None when plan exported into JSON
Issue key: SPARK-44724
Issue id: 13546575
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: minterlandi
Creator: minterlandi
Created: 8/8/23 18:45
Updated: 8/8/23 18:45
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: PySpark
Due Date: 
Votes: 0
Labels: 
Description: I am exporting optimized plans using `_jdf.queryExecution().optimizedPlan().toJSON()`. I noticed that when the plan contains a `INSET` operator the `hset` attribute is None (instead of containing the set elements).

 

When printing directly `_jdf.queryExecution().optimizedPlan()` the `INSET` operator has all the elements so I guess that the problem is with the `toJSON` method.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 45:16.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jnzk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Logging level isn't passed to RocksDB state store provider correctly
Issue key: SPARK-44683
Issue id: 13546200
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: siying
Reporter: siying
Creator: siying
Created: 8/4/23 23:57
Updated: 8/8/23 2:16
Last Viewed: 7/17/24 20:45
Resolved: 8/8/23 2:12
Affects Version/s: 3.4.1
Fix Version/s: 3.5.1, 4.0.0
Component/s: Structured Streaming
Due Date: 
Votes: 0
Labels: 
Description: We pass log4j's log level to RocksDB so that RocksDB debug log can go to log4j. However, we pass in log level after we create the logger. However, the way it is set isn't effective. This has two impacts: (1) setting DEBUG level don't make RocksDB generate DEBUG level logs; (2) setting WARN or ERROR level does prevent INFO level logging, but RocksDB still makes JNI calls to Scala, which is an unnecessary overhead.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Aug 08 02:12:49 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jlo8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 08/Aug/23 02:12;kabhwan;Issue resolved by pull request 42354
[https://github.com/apache/spark/pull/42354];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: `spark.executor.defaultJavaOptions` Check illegal java options
Issue key: SPARK-44650
Issue id: 13545942
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: dzcxzl
Reporter: dzcxzl
Creator: dzcxzl
Created: 8/3/23 4:41
Updated: 8/6/23 13:25
Last Viewed: 7/17/24 20:45
Resolved: 8/6/23 13:24
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sun Aug 06 13:24:57 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jk2w:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 06/Aug/23 13:24;srowen;Issue resolved by pull request 42313
[https://github.com/apache/spark/pull/42313];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Fix the `test_to_excel` tests for python3.7
Issue key: SPARK-44670
Issue id: 13546088
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: madhukar1118
Reporter: madhukar1118
Creator: madhukar1118
Created: 8/4/23 4:12
Updated: 8/6/23 1:24
Last Viewed: 7/17/24 20:45
Resolved: 8/6/23 1:24
Affects Version/s: 3.4.1
Fix Version/s: 3.4.2
Component/s: Pandas API on Spark
Due Date: 
Votes: 0
Labels: 
Description: With python3.7 and openpyxl installed got error:

======================================================================

ERROR: test_to_excel (pyspark.pandas.tests.test_dataframe_conversion.DataFrameConversionTest)

Traceback (most recent call last):

  File "/workspace/apache-spark/python/pyspark/pandas/tests/test_dataframe_conversion.py", line 102, in test_to_excel

    dataframes = self.get_excel_dfs(pandas_on_spark_location, pandas_location)

  File "/workspace/apache-spark/python/pyspark/pandas/tests/test_dataframe_conversion.py", line 89, in get_excel_dfs

    "got": pd.read_excel(pandas_on_spark_location, index_col=0),

  File "/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py", line 296, in wrapper

    return func(*args, **kwargs)

  File "/opt/conda/lib/python3.7/site-packages/pandas/io/excel/_base.py", line 304, in read_excel

    io = ExcelFile(io, engine=engine)

  File "/opt/conda/lib/python3.7/site-packages/pandas/io/excel/_base.py", line 867, in __init__

    self._reader = self._engines[engine](self._io)

  File "/opt/conda/lib/python3.7/site-packages/pandas/io/excel/_xlrd.py", line 21, in __init__

    import_optional_dependency("xlrd", extra=err_msg)

  File "/opt/conda/lib/python3.7/site-packages/pandas/compat/_optional.py", line 110, in import_optional_dependency

    raise ImportError(msg) from None

ImportError: Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd.

----------------------------------------------------------------------

 

 

 

But with xlrd 2.0.1 installed getting error

======================================================================

ERROR: test_to_excel (pyspark.pandas.tests.test_dataframe_conversion.DataFrameConversionTest)

----------------------------------------------------------------------

Traceback (most recent call last):

  File "/workspace/apache-spark/python/pyspark/pandas/tests/test_dataframe_conversion.py", line 102, in test_to_excel

    dataframes = self.get_excel_dfs(pandas_on_spark_location, pandas_location)

  File "/workspace/apache-spark/python/pyspark/pandas/tests/test_dataframe_conversion.py", line 89, in get_excel_dfs

    "got": pd.read_excel(pandas_on_spark_location, index_col=0),

  File "/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py", line 296, in wrapper

    return func(*args, **kwargs)

  File "/opt/conda/lib/python3.7/site-packages/pandas/io/excel/_base.py", line 304, in read_excel

    io = ExcelFile(io, engine=engine)

  File "/opt/conda/lib/python3.7/site-packages/pandas/io/excel/_base.py", line 867, in __init__

    self._reader = self._engines[engine](self._io)

  File "/opt/conda/lib/python3.7/site-packages/pandas/io/excel/_xlrd.py", line 22, in __init__

    super().__init__(filepath_or_buffer)

  File "/opt/conda/lib/python3.7/site-packages/pandas/io/excel/_base.py", line 353, in __init__

    self.book = self.load_workbook(filepath_or_buffer)

  File "/opt/conda/lib/python3.7/site-packages/pandas/io/excel/_xlrd.py", line 37, in load_workbook

    return open_workbook(filepath_or_buffer)

  File "/opt/conda/lib/python3.7/site-packages/xlrd/__init__.py", line 170, in open_workbook

    raise XLRDError(FILE_FORMAT_DESCRIPTIONS[file_format]+'; not supported')

xlrd.biffh.XLRDError: Excel xlsx file; not supported

----------------------------------------------------------------------

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): SPARK-40353
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sun Aug 06 01:24:20 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jkzc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 04/Aug/23 05:38;madhukar1118;Raised a PR for using openpyxl instead of xlrd - [https://github.com/apache/spark/pull/42339] ;;;, 06/Aug/23 01:24;gurwls223;Issue resolved by pull request 42339
[https://github.com/apache/spark/pull/42339];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 06/Aug/23 01:24;gurwls223;Issue resolved by pull request 42339
[https://github.com/apache/spark/pull/42339];;;

Summary: getMapOutputLocation should not throw NPE
Issue key: SPARK-44661
Issue id: 13546051
Parent id: 
Issue Type: Test
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: dongjoon
Reporter: dongjoon
Creator: dongjoon
Created: 8/3/23 19:41
Updated: 8/3/23 21:57
Last Viewed: 7/17/24 20:45
Resolved: 8/3/23 21:52
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 3.4.2, 3.5.0, 4.0.0
Component/s: Spark Core, Tests
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Aug 03 21:52:01 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jkr4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 03/Aug/23 21:52;dongjoon;Issue resolved by pull request 42326
[https://github.com/apache/spark/pull/42326];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Remove TaskPagedTable in StagePage
Issue key: SPARK-44490
Issue id: 13544211
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: dzcxzl
Reporter: dzcxzl
Creator: dzcxzl
Created: 7/20/23 4:21
Updated: 8/1/23 6:42
Last Viewed: 7/17/24 20:45
Resolved: 8/1/23 6:42
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: Web UI
Due Date: 
Votes: 0
Labels: 
Description: In [SPARK-21809|https://issues.apache.org/jira/browse/SPARK-21809], we introduced stagespage-template.html to show the running status of Stage. TaskPagedTable is no longer effective, but there are still many PRs updating related codes.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Aug 01 06:42:02 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j9ew:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 01/Aug/23 06:42;sarutak;Issue resolved in https://github.com/apache/spark/pull/42085;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: `spark.*.io.connectionCreationTimeout` parameter documentation
Issue key: SPARK-44583
Issue id: 13545273
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: dzcxzl
Reporter: dzcxzl
Creator: dzcxzl
Created: 7/28/23 10:23
Updated: 8/1/23 2:55
Last Viewed: 7/17/24 20:45
Resolved: 8/1/23 2:55
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0, 4.0.0
Component/s: Documentation
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Aug 01 02:55:34 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jfyg:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 01/Aug/23 02:55;Qin Yao;Issue resolved by pull request 42205
[https://github.com/apache/spark/pull/42205];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Fix warning condition in MLLib RankingMetrics ndcgAk
Issue key: SPARK-44585
Issue id: 13545300
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: gvuillier
Reporter: gvuillier
Creator: gvuillier
Created: 7/28/23 13:23
Updated: 7/28/23 22:30
Last Viewed: 7/17/24 20:45
Resolved: 7/28/23 22:30
Affects Version/s: 3.4.1
Fix Version/s: 3.4.2, 3.5.0, 4.0.0
Component/s: MLlib
Due Date: 
Votes: 0
Labels: 
Description: The implementation of nDCG evaluation in MLLib with relevance score (added in 3.4.0, see https://issues.apache.org/jira/browse/SPARK-39446 and [pull request|https://github.com/apache/spark/pull/36843]) implements the following warning when the input data isn't correct: "# of ground truth set and # of relevance value set should be equal, check input data"

 

The logic for raising warnings is faulty at the moment: it raises a warning when the following conditions are both true:
 # {{rel}} is empty
 # {{lab.size}} and {{rel.size}} are not equal.

 

With the current logic, RankingMetrics will:
 * raise incorrect warning when a user is using it in the "binary" mode (i.e. no relevance values in the input)
 * not raise warning (that could be necessary) when the user is using it in the "non-binary" model (i.e. with relevance values in the input)

 

The logic should be to raise a warning should be:
 # {{rel}} is *not empty*
 # {{lab.size}} and {{rel.size}} are not equal.

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Jul 28 22:30:38 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jg48:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 28/Jul/23 22:30;srowen;Issue resolved by pull request 42207
[https://github.com/apache/spark/pull/42207];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Export Pyspark's Spark Connect Log Level
Issue key: SPARK-44558
Issue id: 13545002
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: cdkrot
Reporter: cdkrot
Creator: cdkrot
Created: 7/26/23 20:50
Updated: 7/28/23 2:34
Last Viewed: 7/17/24 20:45
Resolved: 7/28/23 2:34
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0, 4.0.0
Component/s: PySpark
Due Date: 
Votes: 0
Labels: 
Description: Export spark connect log level as API function
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Jul 28 02:34:35 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jeag:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 3.5.0
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 28/Jul/23 02:34;gurwls223;Issue resolved by pull request 42175
[https://github.com/apache/spark/pull/42175];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: HiveShim getTablesByType support fallback
Issue key: SPARK-44454
Issue id: 13543716
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: dzcxzl
Reporter: dzcxzl
Creator: dzcxzl
Created: 7/17/23 4:54
Updated: 7/27/23 10:23
Last Viewed: 7/17/24 20:45
Resolved: 7/27/23 10:23
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: When we use a high version of Hive Client to communicate with a low version of Hive meta store, we may encounter Invalid method name: 'get_tables_by_type'.

 
{code:java}
23/07/17 12:45:24,391 [main] DEBUG SparkSqlParser: Parsing command: show views
23/07/17 12:45:24,489 [main] ERROR log: Got exception: org.apache.thrift.TApplicationException Invalid method name: 'get_tables_by_type'
org.apache.thrift.TApplicationException: Invalid method name: 'get_tables_by_type'
    at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:79)
    at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_tables_by_type(ThriftHiveMetastore.java:1433)
    at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_tables_by_type(ThriftHiveMetastore.java:1418)
    at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTables(HiveMetaStoreClient.java:1411)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:173)
    at com.sun.proxy.$Proxy23.getTables(Unknown Source)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:2344)
    at com.sun.proxy.$Proxy23.getTables(Unknown Source)
    at org.apache.hadoop.hive.ql.metadata.Hive.getTablesByType(Hive.java:1427)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at org.apache.spark.sql.hive.client.Shim_v2_3.getTablesByType(HiveShim.scala:1408)
    at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$listTablesByType$1(HiveClientImpl.scala:789)
    at org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:294)
    at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:225)
    at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:224)
    at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:274)
    at org.apache.spark.sql.hive.client.HiveClientImpl.listTablesByType(HiveClientImpl.scala:785)
    at org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$listViews$1(HiveExternalCatalog.scala:895)
    at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:108)
    at org.apache.spark.sql.hive.HiveExternalCatalog.listViews(HiveExternalCatalog.scala:893)
    at org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.listViews(ExternalCatalogWithListener.scala:158)
    at org.apache.spark.sql.catalyst.catalog.SessionCatalog.listViews(SessionCatalog.scala:1040)
    at org.apache.spark.sql.execution.command.ShowViewsCommand.$anonfun$run$5(views.scala:407)
    at scala.Option.getOrElse(Option.scala:189)
    at org.apache.spark.sql.execution.command.ShowViewsCommand.run(views.scala:407) {code}
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Thu Jul 27 10:23:48 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j6cw:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 25/Jul/23 03:46;ci-cassandra.apache.org;User 'cxzl25' has created a pull request for this issue:
https://github.com/apache/spark/pull/42033;;;, 27/Jul/23 10:23;yumwang;Issue resolved by pull request 42033
[https://github.com/apache/spark/pull/42033];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 27/Jul/23 10:23;yumwang;Issue resolved by pull request 42033
[https://github.com/apache/spark/pull/42033];;;

Summary: Utils.getOrCreateLocalRootDirs will never take effect after the first call fails, even if the exception is recovered
Issue key: SPARK-44469
Issue id: 13543877
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: toujours33
Creator: toujours33
Created: 7/18/23 3:22
Updated: 7/18/23 3:24
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: {code:java}
private[spark] def getOrCreateLocalRootDirs(conf: SparkConf): Array[String] = {
  if (localRootDirs == null || localRootDirs.isEmpty) {
    this.synchronized {
      if (localRootDirs == null) {
        localRootDirs = getOrCreateLocalRootDirsImpl(conf)
      }
    }
  }
  localRootDirs
}{code}
localRootDirs is only initialized once in the Executor/Driver life cycle. If it fails due to a FileSystem exception (such as a full disk) during the first initialization, localRootDirs will be assigned a value of None instead of null.

Even if the FileSystem exception recovered, the localRootDirs won't re-apply from FileSystem, causing the task on the Executor to continue to fail (tasks relay on fetchFiles locally)
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Jul 18 03:24:00 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j7co:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 18/Jul/23 03:24;toujours33;I'll work on it.;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Add Python inbuilt functions to DataFrame for ease of use for Python developers
Issue key: SPARK-44336
Issue id: 13542842
Parent id: 
Issue Type: New Feature
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: soffer
Creator: soffer
Created: 7/7/23 19:50
Updated: 7/7/23 19:50
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: PySpark
Due Date: 
Votes: 0
Labels: 
Description: Python developers are used to common inbuilt functions when developing but PySpark doesn't support any of the most used inbuilt functionality for DataFrames. PySpark already has this functionality for columns but not for the DataFrame itself. Adding this support for DataFrames would simplify some parts of development. For example:


{code:java}
if df == df1:       # DataFrame Equality 
if df != df2:       # DataFrame Inequality

df_large = df * 100 # Quickly make a larger dataframe through union of copies
                    # Very useful for performance testing

df_sub = df1 - df2  # Simple DataFrame subtraction
                    # Equivalent to df1.subtract(df2)

df4 = df + df1      # Equivalent to df.union(df1)

len(df)             # Equivalent to df.count()

for row in df:      # Equivalent to `for row in df.collect():`
    some_work(row)

if "company_name" in df: # Check if item is in the DataFrame

{code}
 

There is an ongoing DataFrame equality function effort in PR: 41833, I've also built my own.


These are suggestions, any other functions to be added or removed from this list can be discussed.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 50:25.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1j0zc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Upgrade Avro to version 1.11.2
Issue key: SPARK-44277
Issue id: 13542303
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: iemejia
Reporter: iemejia
Creator: iemejia
Created: 7/3/23 12:57
Updated: 7/5/23 7:11
Last Viewed: 7/17/24 20:45
Resolved: 7/5/23 7:11
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Build
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Jul 05 07:11:44 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ixp4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 05/Jul/23 07:11;gurwls223;Issue resolved by pull request 41830
[https://github.com/apache/spark/pull/41830];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: pyspark.sql.dataframe doctests can behave differently
Issue key: SPARK-44245
Issue id: 13541919
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: cdkrot
Reporter: cdkrot
Creator: cdkrot
Created: 6/29/23 9:57
Updated: 7/4/23 23:49
Last Viewed: 7/17/24 20:45
Resolved: 7/4/23 23:49
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: PySpark
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Jul 04 23:49:10 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ivbs:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 04/Jul/23 23:49;gurwls223;Issue resolved by pull request 41787
[https://github.com/apache/spark/pull/41787];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Remove useless code `resetAllPartitions` in ActiveJob
Issue key: SPARK-44188
Issue id: 13541353
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: fanjia
Reporter: fanjia
Creator: fanjia
Created: 6/26/23 7:14
Updated: 6/26/23 17:06
Last Viewed: 7/17/24 20:45
Resolved: 6/26/23 17:06
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: In class ActiveJob have useless method `resetAllPartitions`. We should remove it.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Jun 26 17:06:22 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1iruw:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 26/Jun/23 17:06;dongjoon;Issue resolved by pull request 41737
[https://github.com/apache/spark/pull/41737];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Enable dynamicPartitionOverwrite in SaveAsHiveFile for insert overwrite
Issue key: SPARK-44166
Issue id: 13541243
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: pralabhkumar
Creator: pralabhkumar
Created: 6/24/23 11:53
Updated: 6/24/23 12:08
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: Currently in InsertIntoHiveTable.scala , there is no way to pass dynamicPartitionOverwrite to true , when calling  saveAsHiveFile . When dynamicPartitioOverwrite is true , spark will use  built-in FileCommitProtocol instead of Hadoop FileOutputCommitter , which is more performant. 

 

Here is the solution . 

When inserting overwrite into Hive table

 

Current code 

 
{code:java}
val writtenParts = saveAsHiveFile(
  sparkSession = sparkSession,
  plan = child,
  hadoopConf = hadoopConf,
  fileFormat = fileFormat,
  outputLocation = tmpLocation.toString,
  partitionAttributes = partitionColumns,
  bucketSpec = bucketSpec,
  options = options)
       {code}
 

 

Proposed code.  

enableDynamicPartitionOverwrite 
{code:java}
val USE_FILECOMMITPROTOCOL_DYNAMIC_PARTITION_OVERWRITE =
    buildConf("spark.sql.hive.filecommit.dynamicPartitionOverwrite"){code}
 
{code:java}
 val enableDynamicPartitionOverwrite =
      SQLConf.get.getConf(HiveUtils.USE_FILECOMMITPROTOCOL_DYNAMIC_PARTITION_OVERWRITE)
    logWarning(s"enableDynamicPartitionOverwrite: $enableDynamicPartitionOverwrite"){code}
 

 

Now if enableDynamicPartitionOverwrite is true and numDynamicPartitions > 0 and overwrite is true , pass dynamicPartitionOverwrite true. 

 
{code:java}
val writtenParts = saveAsHiveFile( sparkSession = sparkSession, plan = child, hadoopConf = hadoopConf, fileFormat = fileFormat, outputLocation = tmpLocation.toString, partitionAttributes = partitionColumns, bucketSpec = bucketSpec, options = options, dynamicPartitionOverwrite =
        enableDynamicPartitionOverwrite && numDynamicPartitions > 0 && overwrite)       {code}
 

 

In saveAs File 
{code:java}
val committer = FileCommitProtocol.instantiate(
      sparkSession.sessionState.conf.fileCommitProtocolClass,
      jobId = java.util.UUID.randomUUID().toString,
      outputPath = outputLocation,
      dynamicPartitionOverwrite = dynamicPartitionOverwrite) {code}
This will internal call  with dynamicPartitionOverwrite value true. 

 
{code:java}
class SQLHadoopMapReduceCommitProtocol(
    jobId: String,
    path: String,
    dynamicPartitionOverwrite: Boolean = false)
  extends HadoopMapReduceCommitProtocol(jobId, path, dynamicPartitionOverwrite) {code}
 

 

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 53:16.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1ir6g:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Remove unused `spark.kubernetes.executor.lostCheck.maxAttempts`
Issue key: SPARK-44158
Issue id: 13541205
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: dongjoon
Reporter: dongjoon
Creator: dongjoon
Created: 6/23/23 18:08
Updated: 6/23/23 20:49
Last Viewed: 7/17/24 20:45
Resolved: 6/23/23 20:49
Affects Version/s: 2.4.8, 3.0.3, 3.1.3, 3.2.4, 3.3.3, 3.4.1
Fix Version/s: 3.3.3, 3.4.2, 3.5.0
Component/s: Kubernetes
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): SPARK-24248
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Jun 23 20:49:57 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1iqy8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 23/Jun/23 20:49;dongjoon;Issue resolved by pull request 41713
[https://github.com/apache/spark/pull/41713];;;
Affects Version/s.1: 3.0.3
Affects Version/s.2: 3.1.3
Affects Version/s.3: 3.2.4
Affects Version/s.4: 3.3.3
Comment.1:

Summary: Outdated JARs in PySpark package
Issue key: SPARK-44157
Issue id: 13541187
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: 
Assignee: 
Reporter: adriangonz
Creator: adriangonz
Created: 6/23/23 15:03
Updated: 6/23/23 15:03
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Build, PySpark
Due Date: 
Votes: 0
Labels: pyspark
Description: The JARs which ship embedded within PySpark's package in PyPi don't seem aligned with the deps specified in Spark's own `pom.xml`.

For example, in Spark's `pom.xml`, `protobuf-java` is set to `3.21.12`:

[https://github.com/apache/spark/blob/6b1ff22dde1ead51cbf370be6e48a802daae58b6/pom.xml#L127]

However, if we look at the JARs embedded within PySpark tarball, the version of `protobuf-java` is `2.5.0` (i.e. `..../site-packages/pyspark/jars/protobuf-java-2.5.0.jar`). Same seems to apply to all other dependencies.

This introduces a set of CVEs which are fixed on upstream Spark, but are still present in PySpark (e.g. `CVE-2022-3509`, `CVE-2021-22569`, ` CVE-2015-5237` and a few others). As well as potentially introduce a source of conflict whenever there's a breaking change on these deps.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 03:32.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1iqu8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Update YuniKorn docs with v1.3
Issue key: SPARK-44038
Issue id: 13539822
Parent id: 
Issue Type: Documentation
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: dongjoon
Reporter: dongjoon
Creator: dongjoon
Created: 6/13/23 10:05
Updated: 6/13/23 10:37
Last Viewed: 7/17/24 20:45
Resolved: 6/13/23 10:37
Affects Version/s: 3.4.1, 3.5.0
Fix Version/s: 3.4.1, 3.5.0
Component/s: Documentation, Kubernetes
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Jun 13 10:37:34 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1iig8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 13/Jun/23 10:37;dongjoon;Issue resolved by pull request 41571
[https://github.com/apache/spark/pull/41571];;;
Affects Version/s.1: 3.5.0
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Upgrade buf to v1.18.0
Issue key: SPARK-43401
Issue id: 13535317
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: panbingkun
Reporter: panbingkun
Creator: panbingkun
Created: 5/8/23 2:18
Updated: 5/9/23 1:06
Last Viewed: 7/17/24 20:45
Resolved: 5/9/23 1:06
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Build, Connect
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue May 09 01:06:34 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1hqvc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 09/May/23 01:06;dongjoon;Issue resolved by pull request 41087
[https://github.com/apache/spark/pull/41087];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Upgrade scalafmt from 3.7.2 to 3.7.3
Issue key: SPARK-43350
Issue id: 13534766
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: panbingkun
Reporter: panbingkun
Creator: panbingkun
Created: 5/3/23 1:34
Updated: 5/3/23 15:46
Last Viewed: 7/17/24 20:45
Resolved: 5/3/23 15:46
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Build
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed May 03 15:46:39 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1hnh4:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 03/May/23 15:46;dongjoon;Issue resolved by pull request 41029
[https://github.com/apache/spark/pull/41029];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Generalize handling of metadata attributes in FileSourceStrategy
Issue key: SPARK-42918
Issue id: 13529963
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: johanl-db
Reporter: johanl-db
Creator: johanl-db
Created: 3/24/23 11:38
Updated: 3/31/23 12:53
Last Viewed: 7/17/24 20:45
Resolved: 3/31/23 12:51
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: Optimizer
Due Date: 
Votes: 0
Labels: 
Description: A first step towards allowing file format implementations to inject custom metadata fields into plans is to make the handling of metadata attributes in `FileSourceStrategy` more generic.

Today in `FileSourceStrategy` , the lists of constant and generated metadata fields are created manually, checking for known generated fields on one hand and considering the remaining fields as constant metadata fields. We need instead to introduce a way of declaring metadata fields as generated or constant directly in `FileFormat` and propagate that information to `FileSourceStrategy`.

 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Fri Mar 31 12:51:56 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1gtyo:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 31/Mar/23 12:51;cloud_fan;Issue resolved by pull request 40545
[https://github.com/apache/spark/pull/40545];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: Remove duplicated rule CombineFilters in Optimizer
Issue key: SPARK-42850
Issue id: 13529031
Parent id: 
Issue Type: Task
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: Gengliang.Wang
Reporter: Gengliang.Wang
Creator: Gengliang.Wang
Created: 3/17/23 23:02
Updated: 3/20/23 0:49
Last Viewed: 7/17/24 20:45
Resolved: 3/20/23 0:49
Affects Version/s: 3.4.1
Fix Version/s: 3.5.0
Component/s: SQL
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Mar 20 00:49:02 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1go7s:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 17/Mar/23 23:24;apachespark;User 'gengliangwang' has created a pull request for this issue:
https://github.com/apache/spark/pull/40471;;;, 20/Mar/23 00:49;gurwls223;Issue resolved by pull request 40471
[https://github.com/apache/spark/pull/40471];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 20/Mar/23 00:49;gurwls223;Issue resolved by pull request 40471
[https://github.com/apache/spark/pull/40471];;;

Summary: Implement textFile for DataFrameReader
Issue key: SPARK-42757
Issue id: 13528068
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Minor
Resolution: Fixed
Assignee: panbingkun
Reporter: panbingkun
Creator: panbingkun
Created: 3/11/23 11:13
Updated: 3/15/23 7:43
Last Viewed: 7/17/24 20:45
Resolved: 3/14/23 23:41
Affects Version/s: 3.4.1
Fix Version/s: 3.4.1
Component/s: Connect
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): SPARK-42554
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Tue Mar 14 23:41:46 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1gi9s:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 11/Mar/23 11:16;apachespark;User 'panbingkun' has created a pull request for this issue:
https://github.com/apache/spark/pull/40377;;;, 11/Mar/23 11:17;apachespark;User 'panbingkun' has created a pull request for this issue:
https://github.com/apache/spark/pull/40377;;;, 14/Mar/23 23:41;gurwls223;Issue resolved by pull request 40377
[https://github.com/apache/spark/pull/40377];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 11/Mar/23 11:17;apachespark;User 'panbingkun' has created a pull request for this issue:
https://github.com/apache/spark/pull/40377;;;

Summary: Expose amount of shuffle data available on the node
Issue key: SPARK-44209
Issue id: 13541552
Parent id: 
Issue Type: New Feature
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Trivial
Resolution: 
Assignee: 
Reporter: deependra
Creator: deependra
Created: 6/27/23 11:41
Updated: 11/27/23 0:19
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Shuffle
Due Date: 
Votes: 0
Labels: pull-request-available
Description: [ShuffleMetrics|https://github.com/apache/spark/blob/43f7a86a05ad8c7ec7060607e43d9ca4d0fe4166/common/network-shuffle/src/main/java/org/apache/spark/network/shuffle/ExternalBlockHandler.java#L318] doesn't have metrics like 
"totalShuffleDataBytes" and "numAppsWithShuffleData", these metrics are per node published by External Shuffle Service.
 
Adding these metrics would help in - 
1. Deciding if we can decommission the node if no shuffle data present
2. Better live monitoring of customer's workload to see if there is skewed shuffle data present on the node
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): Java
Custom field (Last public comment date): Wed Jul 19 09:23:02 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1it2o:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): abmodi
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 27/Jun/23 11:49;deependra;I will create a pull request for this soon;;;, 19/Jul/23 09:22;githubbot;User 'Deependra-Patel' has created a pull request for this issue:
https://github.com/apache/spark/pull/42071;;;, 19/Jul/23 09:23;githubbot;User 'Deependra-Patel' has created a pull request for this issue:
https://github.com/apache/spark/pull/42071;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 19/Jul/23 09:22;githubbot;User 'Deependra-Patel' has created a pull request for this issue:
https://github.com/apache/spark/pull/42071;;;

Summary: Add Support for TPCH Micro Benchmark
Issue key: SPARK-44301
Issue id: 13542442
Parent id: 
Issue Type: Improvement
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Trivial
Resolution: 
Assignee: 
Reporter: Suraj Naik
Creator: Suraj Naik
Created: 7/4/23 16:54
Updated: 10/31/23 0:17
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: SQL
Due Date: 
Votes: 0
Labels: pull-request-available
Description: I am proposing this Jira to add support for benchmark for TPCH. I see that there is currently support for TPCDS, but couldn't find one for TPCH. I will add support for it.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sat Jul 08 04:07:36 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1iyk0:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 04/Jul/23 16:57;Suraj Naik;I have raised the PR here - https://github.com/apache/spark/pull/41856;;;, 08/Jul/23 04:07;snoot;User 'oss-maker' has created a pull request for this issue:
https://github.com/apache/spark/pull/41856;;;, 08/Jul/23 04:07;snoot;User 'oss-maker' has created a pull request for this issue:
https://github.com/apache/spark/pull/41856;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 08/Jul/23 04:07;snoot;User 'oss-maker' has created a pull request for this issue:
https://github.com/apache/spark/pull/41856;;;

Summary: problem using broadcast join with parquet/iceberg tables
Issue key: SPARK-45198
Issue id: 13551034
Parent id: 
Issue Type: Bug
Status: Open
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Trivial
Resolution: 
Assignee: 
Reporter: tonyuwarov
Creator: tonyuwarov
Created: 9/18/23 8:38
Updated: 9/18/23 8:45
Last Viewed: 7/17/24 20:45
Resolved: 
Affects Version/s: 3.4.1
Fix Version/s: 
Component/s: Build
Due Date: 
Votes: 0
Labels: 
Description: We have 2 Parquet tables: load_test_full_warehouse.gen_document_type and load_test_full_warehouse.generation_document_part.
Trying to make a left join of these two tables onto each other gives a strange result. In the case where on the left side of the join we use a large table load_test_full_warehouse.generation_document_part, the optimizer uses a broadcast join.
However, in the case when on the left in the join we use a small reference table, the optimizer chooses to execute the query using the merge sort. Although it would seem that the small table on the left in a left join should initiate a broadcast join.
  An attempt to use hints and collect statistics did not yield results. The following queries were used:

spark.sql(f"""create table iceberg_warehouse.t1 using iceberg 
              as SELECT /*+ BROADCAST(doc_tp) */
                doc.DOCUMENT_DATE
                , doc_tp.NAME as DOCUMENT_TYPE
                , COUNT(*) as DOC_QTY
              FROM load_test_full_warehouse.generation_document_part doc
              LEFT JOIN load_test_full_warehouse.gen_document_type doc_tp ON doc.DOCUMENT_TYPE_ID_INT = doc_tp.DOCUMENT_TYPE_ID_INT
              GROUP BY doc.DOCUMENT_DATE, doc_tp.NAME""")

== Physical Plan ==
AtomicCreateTableAsSelect (25)
+- AdaptiveSparkPlan (24)
   +- == Final Plan ==
      * HashAggregate (15)
      +- AQEShuffleRead (14)
         +- ShuffleQueryStage (13), Statistics(sizeInBytes=16.7 MiB, rowCount=3.12E+5)
            +- Exchange (12)
               +- * HashAggregate (11)
                  +- * Project (10)
                     +- * BroadcastHashJoin LeftOuter BuildRight (9)
                        :- * Project (3)
                        :  +- * ColumnarToRow (2)
                        :     +- Scan parquet spark_catalog.load_test_full_warehouse.generation_document_part (1)
                        +- BroadcastQueryStage (8), Statistics(sizeInBytes=1031.8 KiB, rowCount=1.00E+3)
                           +- BroadcastExchange (7)
                              +- * Filter (6)
                                 +- * ColumnarToRow (5)
                                    +- Scan parquet spark_catalog.load_test_full_warehouse.gen_document_type (4)
   +- == Initial Plan ==
      HashAggregate (23)
      +- Exchange (22)
         +- HashAggregate (21)
            +- Project (20)
               +- BroadcastHashJoin LeftOuter BuildRight (19)
                  :- Project (16)
                  :  +- Scan parquet spark_catalog.load_test_full_warehouse.generation_document_part (1)
                  +- BroadcastExchange (18)
                     +- Filter (17)
                        +- Scan parquet spark_catalog.load_test_full_warehouse.gen_document_type (4)

 

spark.sql(f"""create table iceberg_warehouse.t2 using iceberg 
              as SELECT /*+ BROADCAST(doc_tp) */
                doc.DOCUMENT_DATE
                , doc_tp.NAME as DOCUMENT_TYPE
                , COUNT(*) as DOC_QTY
              FROM load_test_full_warehouse.gen_document_type doc_tp
              LEFT JOIN load_test_full_warehouse.generation_document_part doc ON doc.DOCUMENT_TYPE_ID_INT = doc_tp.DOCUMENT_TYPE_ID_INT
              GROUP BY doc.DOCUMENT_DATE, doc_tp.NAME""")

== Physical Plan ==
AtomicCreateTableAsSelect (34)
+- AdaptiveSparkPlan (33)
   +- == Final Plan ==
      * HashAggregate (21)
      +- AQEShuffleRead (20)
         +- ShuffleQueryStage (19), Statistics(sizeInBytes=1695.3 KiB, rowCount=3.10E+4)
            +- Exchange (18)
               +- * HashAggregate (17)
                  +- * Project (16)
                     +- * SortMergeJoin LeftOuter (15)
                        :- * Sort (6)
                        :  +- AQEShuffleRead (5)
                        :     +- ShuffleQueryStage (4), Statistics(sizeInBytes=46.9 KiB, rowCount=1.00E+3)
                        :        +- Exchange (3)
                        :           +- * ColumnarToRow (2)
                        :              +- Scan parquet spark_catalog.load_test_full_warehouse.gen_document_type (1)
                        +- * Sort (14)
                           +- AQEShuffleRead (13)
                              +- ShuffleQueryStage (12), Statistics(sizeInBytes=234.7 GiB, rowCount=1.05E+10)
                                 +- Exchange (11)
                                    +- * Project (10)
                                       +- * Filter (9)
                                          +- * ColumnarToRow (8)
                                             +- Scan parquet spark_catalog.load_test_full_warehouse.generation_document_part (7)
   +- == Initial Plan ==
      HashAggregate (32)
      +- Exchange (31)
         +- HashAggregate (30)
            +- Project (29)
               +- SortMergeJoin LeftOuter (28)
                  :- Sort (23)
                  :  +- Exchange (22)
                  :     +- Scan parquet spark_catalog.load_test_full_warehouse.gen_document_type (1)
                  +- Sort (27)
                     +- Exchange (26)
                        +- Project (25)
                           +- Filter (24)
                              +- Scan parquet spark_catalog.load_test_full_warehouse.generation_document_part (7)
Environment: 
Log Work: 
Original Estimate: 2203200
Remaining Estimate: 2203200
Time Spent: 
Work Ratio: 0%
Σ Original Estimate: 2203200
Σ Remaining Estimate: 2203200
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 18/Sep/23 08:45;tonyuwarov;T1-Details-for-Query.png;https://issues.apache.org/jira/secure/attachment/13062984/T1-Details-for-Query.png, 18/Sep/23 08:45;tonyuwarov;T2-Details-for-Query.png;https://issues.apache.org/jira/secure/attachment/13062983/T2-Details-for-Query.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 2
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): 38:06.0
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kf4w:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: The default value of ‘spark.executor.logs.rolling.strategy’ on the official website is incorrect
Issue key: SPARK-45160
Issue id: 13550609
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Trivial
Resolution: Fixed
Assignee: chenyu-opensource
Reporter: chenyu-opensource
Creator: chenyu-opensource
Created: 9/14/23 2:27
Updated: 9/18/23 2:35
Last Viewed: 7/17/24 20:45
Resolved: 9/18/23 2:35
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: Documentation
Due Date: 
Votes: 0
Labels: pull-request-available
Description: Empty string and (none) are different. the default value of '

spark.executor.logs.rolling.strategy' is ""
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 14/Sep/23 02:34;chenyu-opensource;execute different logic.png;https://issues.apache.org/jira/secure/attachment/13062895/execute+different+logic.png, 14/Sep/23 02:33;chenyu-opensource;the default value.png;https://issues.apache.org/jira/secure/attachment/13062894/the+default+value.png, 14/Sep/23 02:31;chenyu-opensource;the value on the official website.png;https://issues.apache.org/jira/secure/attachment/13062893/the+value+on+the+official+website.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 3
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Sep 18 02:35:33 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kcig:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 14/Sep/23 06:22;chenyu-opensource;I had sumbit a pr

https://github.com/apache/spark/pull/42919;;;, 18/Sep/23 02:35;srowen;Resolved by github.com/apache/spark/pull/42919;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 18/Sep/23 02:35;srowen;Resolved by github.com/apache/spark/pull/42919;;;

Summary: The default value of ‘spark. submit. deployMode’ on the official website is incorrect
Issue key: SPARK-45146
Issue id: 13550452
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Trivial
Resolution: Fixed
Assignee: chenyu-opensource
Reporter: chenyu-opensource
Creator: chenyu-opensource
Created: 9/13/23 6:57
Updated: 9/16/23 13:18
Last Viewed: 7/17/24 20:45
Resolved: 9/13/23 13:49
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: Documentation
Due Date: 
Votes: 0
Labels: pull-request-available
Description: The deploy mode of Spark driver program has default value,but the value on the official website is incorrect.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 13/Sep/23 06:58;chenyu-opensource;the default value.png;https://issues.apache.org/jira/secure/attachment/13062864/the+default+value.png, 13/Sep/23 06:58;chenyu-opensource;the value on the official website.png;https://issues.apache.org/jira/secure/attachment/13062863/the+value+on+the+official+website.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 2
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Sep 13 13:49:10 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1kbjk:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 13/Sep/23 07:18;chenyu-opensource;I had submit a pr to resolve this question.

https://github.com/apache/spark/pull/42902;;;, 13/Sep/23 13:49;srowen;Issue resolved by pull request 42902
[https://github.com/apache/spark/pull/42902];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 13/Sep/23 13:49;srowen;Issue resolved by pull request 42902
[https://github.com/apache/spark/pull/42902];;;

Summary: Miswritten remarks in pom file
Issue key: SPARK-44890
Issue id: 13548042
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Trivial
Resolution: Fixed
Assignee: chenyu-opensource
Reporter: chenyu-opensource
Creator: chenyu-opensource
Created: 8/21/23 8:22
Updated: 9/4/23 14:13
Last Viewed: 7/17/24 20:45
Resolved: 9/4/23 14:13
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: Build
Due Date: 
Votes: 0
Labels: 
Description: Spelling issues in pom files affect understanding which uses 'dont update'.

It needs to maintain the same writing style as other places
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 21/Aug/23 08:23;chenyu-opensource;screenshot-1.png;https://issues.apache.org/jira/secure/attachment/13062311/screenshot-1.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 1
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Sep 04 14:13:41 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jwog:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 21/Aug/23 08:30;chenyu-opensource;I had submit a patch 

[https://github.com/apache/spark/pull/42598|https://github.com/apache/spark/pull/42583]

 ;;;, 04/Sep/23 03:43;snoot;User 'chenyu-opensource' has created a pull request for this issue:
https://github.com/apache/spark/pull/42598;;;, 04/Sep/23 14:12;srowen;This is too trivial for a JIRA;;;, 04/Sep/23 14:13;srowen;Resolved by https://github.com/apache/spark/pull/42598;;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 04/Sep/23 03:43;snoot;User 'chenyu-opensource' has created a pull request for this issue:
https://github.com/apache/spark/pull/42598;;;

Summary: Improve python version mismatch logging
Issue key: SPARK-45053
Issue id: 13549435
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Trivial
Resolution: Fixed
Assignee: WweiL
Reporter: WweiL
Creator: WweiL
Created: 9/1/23 17:37
Updated: 9/4/23 0:51
Last Viewed: 7/17/24 20:45
Resolved: 9/4/23 0:51
Affects Version/s: 3.4.1
Fix Version/s: 4.0.0
Component/s: PySpark
Due Date: 
Votes: 0
Labels: 
Description: Currently the syntax of the python version mismatching is a little bit confusing, it uses (3,9) to represent python version 3.9. Just a minor update to make it more straightforward 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Sep 04 00:51:07 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1k59s:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 02/Sep/23 03:54;srowen;[~WweiL] Please fill out this JIRA. It is also not "Major";;;, 02/Sep/23 03:54;snoot;User 'WweiL' has created a pull request for this issue:
https://github.com/apache/spark/pull/42776;;;, 02/Sep/23 03:54;snoot;User 'WweiL' has created a pull request for this issue:
https://github.com/apache/spark/pull/42776;;;, 04/Sep/23 00:51;gurwls223;Issue resolved by pull request 42776
[https://github.com/apache/spark/pull/42776];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 02/Sep/23 03:54;snoot;User 'WweiL' has created a pull request for this issue:
https://github.com/apache/spark/pull/42776;;;

Summary: Adjust Pull Request Template to incorporate the ASF Generative Tooling Guidance recommendations
Issue key: SPARK-44782
Issue id: 13547033
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Trivial
Resolution: Fixed
Assignee: zero323
Reporter: zero323
Creator: zero323
Created: 8/12/23 10:18
Updated: 8/19/23 2:14
Last Viewed: 7/17/24 20:45
Resolved: 8/19/23 2:14
Affects Version/s: 3.3.2, 3.4.1
Fix Version/s: 4.0.0
Component/s: Project Infra
Due Date: 
Votes: 0
Labels: 
Description: Recently releases [ASF Generative Tooling Guidance|https://www.apache.org/legal/generative-tooling.html] recommends keeping track of the generative AI tools used to author patches

??When providing contributions authored using generative AI tooling, a recommended practice is for contributors to indicate the tooling used to create the contribution. This should be included as a token in the source control commit message, for example including the phrase “Generated-by: ”. This allows for future release tooling to be considered that pulls this content into a machine parsable Tooling-Provenance file.??

We should adjust PR template accordingly.

Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Sat Aug 19 02:14:38 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jqtc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 15/Aug/23 06:14;smilegator;+1 We should update the PR template. ;;;, 15/Aug/23 08:24;zero323;Created a pull request for this issue:
https://github.com/apache/spark/pull/42469;;;, 15/Aug/23 09:20;githubbot;User 'zero323' has created a pull request for this issue:
https://github.com/apache/spark/pull/42469;;;, 19/Aug/23 02:14;srowen;Issue resolved by pull request 42469
[https://github.com/apache/spark/pull/42469];;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 15/Aug/23 08:24;zero323;Created a pull request for this issue:
https://github.com/apache/spark/pull/42469;;;

Summary: Document spark.network.timeoutInterval
Issue key: SPARK-44725
Issue id: 13546588
Parent id: 
Issue Type: Documentation
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Trivial
Resolution: Fixed
Assignee: dongjoon
Reporter: dongjoon
Creator: dongjoon
Created: 8/8/23 20:49
Updated: 8/9/23 4:46
Last Viewed: 7/17/24 20:45
Resolved: 8/8/23 23:04
Affects Version/s: 3.3.2, 3.4.1, 3.5.0
Fix Version/s: 3.3.4, 3.4.2, 3.5.1, 4.0.0
Component/s: Documentation
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Wed Aug 09 04:46:47 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jo2g:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 08/Aug/23 23:04;dongjoon;Issue resolved by pull request 42402
[https://github.com/apache/spark/pull/42402];;;, 09/Aug/23 04:45;snoot;User 'dongjoon-hyun' has created a pull request for this issue:
https://github.com/apache/spark/pull/42402;;;, 09/Aug/23 04:46;snoot;User 'dongjoon-hyun' has created a pull request for this issue:
https://github.com/apache/spark/pull/42402;;;
Affects Version/s.1: 3.4.1
Affects Version/s.2: 3.5.0
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1: 09/Aug/23 04:45;snoot;User 'dongjoon-hyun' has created a pull request for this issue:
https://github.com/apache/spark/pull/42402;;;

Summary: Upgrade snappy-java to 1.1.10.3
Issue key: SPARK-44513
Issue id: 13544550
Parent id: 
Issue Type: Bug
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Trivial
Resolution: Fixed
Assignee: panbingkun
Reporter: panbingkun
Creator: panbingkun
Created: 7/23/23 12:56
Updated: 7/31/23 16:08
Last Viewed: 7/17/24 20:45
Resolved: 7/24/23 3:04
Affects Version/s: 3.4.1
Fix Version/s: 3.4.2, 3.5.0
Component/s: Build
Due Date: 
Votes: 0
Labels: 
Description: 
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 
Custom field (Affects version (Component)): 
Custom field (Attachment count): 0
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Jul 24 03:04:12 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jbi8:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 24/Jul/23 03:04;Qin Yao;Issue resolved by pull request 42113
[https://github.com/apache/spark/pull/42113];;;
Affects Version/s.1: 
Affects Version/s.2: 
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

Summary: eagerly load SparkExitCode class in SparkUncaughtExceptionHandler
Issue key: SPARK-44542
Issue id: 13544762
Parent id: 
Issue Type: Improvement
Status: Resolved
Project key: SPARK
Project name: Spark
Project type: software
Project lead: matei
Project description: <div>

<b><i>Apache Spark</i></b> is a fast and general cluster computing system.
It provides high-level APIs in 
Scala, Java, Python and R, and an optimized engine that supports general computation graphs.
It also supports a rich set of higher-level tools including 
<a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> for SQL and structured data processing, 
<a href="http://spark.apache.org/docs/latest/mllib-guide.html">MLLib</a> for machine learning, 
<a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html">GraphX</a> for graph processing, and 
<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">Spark Streaming</a>.


<table style="border: 0px; width: 100%;">
<tr>
<td>
For more information, see:
<br><a href="http://spark.apache.org/">The Spark Homepage</a>
<br>
<a href="https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage">The Spark Wiki</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">How to Contribute to Spark</a>
<br>
<a href="https://github.com/apache/spark">Spark's Github Repository</a>
</td>
<td style="text-align: center;">
<a href="http://spark.apache.org/"><img src="http://spark.apache.org/images/spark-logo.png" width="180px"></a>
</td>

</tr>
</table>

</div>
Project url: http://spark.apache.org
Priority: Trivial
Resolution: Fixed
Assignee: advancedxy
Reporter: advancedxy
Creator: advancedxy
Created: 7/25/23 8:44
Updated: 7/31/23 3:13
Last Viewed: 7/17/24 20:45
Resolved: 7/31/23 3:13
Affects Version/s: 3.1.3, 3.3.2, 3.4.1
Fix Version/s: 3.5.0
Component/s: Spark Core
Due Date: 
Votes: 0
Labels: 
Description: There are two background for this improvement proposal:

1. When running spark on yarn, the disk might be corrupted during application running. The corrupted disk might contain the spark jars(cache archive from spark.yarn.archive). In that case , the executor JVM cannot load any spark related classes any more.

2. Spark leverages the OutputCommitCoordinator to avoid data race between speculate tasks so that no tasks could commit the same partition in the same time. In other words, once a task's commit request is allowed, other commit requests would be denied until the committing task is failed.

 

We encountered a corner case combined the above two cases, which makes the spark hangs.  A short timeline could be described as below:
 # task 5372(tid: 21662) starts running in 21:55
 # the disk contains the spark archive for that task/executor is corrupted, thus making the archive inaccessible from executor's JVM perspective, it happened around 22:00
 # the task continues running, at 22:05, it requests commit from coordinator and performs the commit. 
 # however due the corrupted disk, some exception raised in the executor JVM.
 # The SparkUncaughtExceptionHandler kicks in, however as the jar/disk is corrupted, the handler itself throws an exception, and the halt process throws an exception too.
 # The executor is hanging there, no more tasks are running. However the authorized commit request is still valid in the driver side
 # Speculate tasks start to click in, due to no commit permission, all speculate tasks are killed/denied.
 # The job is hanging until our SRE killed the container from outside.

Some screenshot are provided below.

!image-2023-07-25-16-46-03-989.png!

!image-2023-07-25-16-46-28-158.png!

!image-2023-07-25-16-46-42-522.png!

For this specific case: I'd like to the propose to eagerly load SparkExitCode class in the 
SparkUncaughtExceptionHandler, so that the halt process could be executed rather than throws an exception as SparkExitCode is not loadable during the previous scenario.
Environment: 
Log Work: 
Original Estimate: 
Remaining Estimate: 
Time Spent: 
Work Ratio: 
Σ Original Estimate: 
Σ Remaining Estimate: 
Σ Time Spent: 
Security Level: 
Inward issue link (Blocked): 
Outward issue link (Blocked): 
Inward issue link (Blocker): 
Outward issue link (Blocker): 
Inward issue link (Cloners): 
Outward issue link (Cloners): 
Inward issue link (Completes): 
Inward issue link (Duplicate): 
Outward issue link (Duplicate): 
Inward issue link (Problem/Incident): 
Outward issue link (Problem/Incident): 
Inward issue link (Reference): 
Outward issue link (Reference): 
Inward issue link (Regression): 
Attachment: 25/Jul/23 08:46;advancedxy;image-2023-07-25-16-46-03-989.png;https://issues.apache.org/jira/secure/attachment/13061599/image-2023-07-25-16-46-03-989.png, 25/Jul/23 08:46;advancedxy;image-2023-07-25-16-46-28-158.png;https://issues.apache.org/jira/secure/attachment/13061600/image-2023-07-25-16-46-28-158.png, 25/Jul/23 08:46;advancedxy;image-2023-07-25-16-46-42-522.png;https://issues.apache.org/jira/secure/attachment/13061601/image-2023-07-25-16-46-42-522.png
Custom field (Affects version (Component)): 
Custom field (Attachment count): 3
Custom field (Blog - New Blog Administrators): 
Custom field (Blog - New Blog PMC): 
Custom field (Blog - Write access): 
Custom field (Blog Administrator?): 
Custom field (Blogs - Admin for blog): 
Custom field (Blogs - Email Address): 
Custom field (Blogs - Existing Blog Access Level): 
Custom field (Blogs - Existing Blog Name): 
Custom field (Blogs - New Blog Write Access): 
Custom field (Blogs - Username): 
Custom field (Bug Category): 
Custom field (Bugzilla - Email Notification Address): 
Custom field (Bugzilla - List of usernames): 
Custom field (Bugzilla - PMC Name): 
Custom field (Bugzilla - Project Name): 
Custom field (Bugzilla Id): 
Custom field (Bugzilla Id).1: 
Custom field (Change Category): 
Custom field (Complexity): 
Custom field (Discovered By): 
Custom field (Docs Text): 
Custom field (Enable Automatic Patch Review): FALSE
Custom field (Epic Colour): 
Custom field (Epic Link): 
Custom field (Epic Name): 
Custom field (Epic Status): 
Custom field (Estimated Complexity): 
Custom field (Evidence Of Open Source Adoption): 
Custom field (Evidence Of Registration): 
Custom field (Evidence Of Use On World Wide Web): 
Custom field (Existing GitBox Approval): 
Custom field (External issue ID): 
Custom field (External issue URL): 
Custom field (Fix version (Component)): 
Custom field (Flags): 
Custom field (Git Notification Mailing List): 
Custom field (Git Repository Import Path): 
Custom field (Git Repository Name): 
Custom field (Git Repository Type): 
Custom field (GitHub Options): 
Custom field (Github Integration): 
Custom field (Github Integrations - Other): 
Custom field (Global Rank): 9223372036854775807
Custom field (INFRA - Subversion Repository Path): 
Custom field (Initial Confluence Contributors): 
Custom field (Language): 
Custom field (Last public comment date): Mon Jul 31 03:13:08 UTC 2023
Custom field (Level of effort): 
Custom field (Machine Readable Info): 
Custom field (Mentor): 
Custom field (New-TLP-TLPName): 
Custom field (Original story points): 
Custom field (Parent Link): 
Custom field (Priority): 
Custom field (Project): 
Custom field (Protected Branch): 
Custom field (Rank): 0|z1jctc:
Custom field (Rank (Obsolete)): 9223372036854775807
Custom field (Review Date): 
Custom field (Reviewer): 
Custom field (Severity): 
Custom field (Severity).1: 
Custom field (Shepherd): 
Custom field (Skill Level): 
Custom field (Source Control Link): 
Custom field (Space Description): 
Custom field (Space Key): 
Custom field (Space Name): 
Custom field (Start Date): 
Custom field (Tags): 
Custom field (Target Version/s): 
Custom field (Target end): 
Custom field (Target start): 
Custom field (Team): 
Custom field (Test and Documentation Plan): 
Custom field (Testcase included): 
Custom field (Tester): 
Custom field (Workaround): 
Comment: 31/Jul/23 03:13;srowen;Issue resolved by pull request 42195
[https://github.com/apache/spark/pull/42195];;;
Affects Version/s.1: 3.3.2
Affects Version/s.2: 3.4.1
Affects Version/s.3: 
Affects Version/s.4: 
Comment.1:

